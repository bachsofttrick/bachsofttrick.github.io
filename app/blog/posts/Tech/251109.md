---
title: 'Getting Nvidia GPU to work in Docker container: A Cursed Experience'
publishedAt: '2025-11-09'
hidden: true
---
- Originally want to make llama-cpp python work in container. CPU only at the moment
- Install [toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html). Run demo:
```
sudo docker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi
```
Successful
- Get it working on docker compose. Follow [this](https://docs.docker.com/compose/how-tos/gpu-support/), but out of
date in `capabilities` part. llama-cpp couldn't find GPU.
- put intel gpu in /dev/dri. llama-cpp found GPU.
- toolkit already installed, nvidia-smi found gpu. but somehow llama-cpp cannot find
- vulkaninfo | vi - only found LLVM, not Nvidia. 
- Use ChatGPT: suggest `runtime: nvidia`. Previously after docker compose, recreate with that runtime. now auto from docker compose => not work
- [special config](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html)
show many things missing from Docker page. `capabilities` now is `[graphics]` to use Vulkan.
    - add `NVIDIA_VISIBLE_DEVICES=all`, `NVIDIA_DRIVER_CAPABILITIES=all`, not working
- ChatGPT suggested `vulkaninfo | grep "GPU id"`. Did that, said:
```
ERROR: [Loader Message] Code 0 : libXext.so.6: cannot open shared object file: No such file or directory
ERROR: [Loader Message] Code 0 : loader_icd_scan: Failed loading library associated with ICD JSON libGLX_nvidia.so.0. Ignoring this JSON
ERROR: [Loader Message] Code 0 : libXext.so.6: cannot open shared object file: No such file or directory
ERROR: [Loader Message] Code 0 : loader_icd_scan: Failed loading library associated with ICD JSON libGLX_nvidia.so.0. Ignoring this JSON 'DISPLAY' environment variable not set... skipping surface info error: XDG_RUNTIME_DIR is invalid or not set in the environment. GPU id = 0 (llvmpipe (LLVM 20.1.2, 256 bits)) GPU id = 0 (llvmpipe (LLVM 20.1.2, 256 bits)) GPU id = 0 (llvmpipe (LLVM 20.1.2, 256 bits)) GPU id = 0 (llvmpipe (LLVM 20.1.2, 256 bits))
```
For `libXext.so.6`, it is missing `libxext6`. Installed that, now is
```
Code 0 : loader_scanned_icd_add: Could not get 'vkCreateInstance' via 'vk_icdGetInstanceProcAddr' for ICD libGLX_nvidia.so.0
```
- Some reason, nvidia toolkit don't just have `/usr/share/vulkan/icd.d/nvidia_icd.json` in container
- mapped it in container (readonly). Still same error. Copying the content, ChatGPT said is not Vulkan, OpenGL. Keep
referencing `libnvidia-vulkan.so.1` even if I combed through my host machine. It didn't exist, but ran Vulkan fine.
- Searching `libnvidia-vulkan.so.1` on Google, found [this](https://stackoverflow.com/questions/74965945/vulkan-is-unable-to-detect-nvidia-gpu-from-within-a-docker-container-when-using). Led to [this](https://github.com/NVIDIA/nvidia-container-toolkit/issues/16).
No dice.
- `docker ERROR: [Loader Message] Code 0 : loader_scanned_icd_add: Could not get 'vkCreateInstance' via 'vk_icdGetInstanceProcAddr' for ICD libGLX_nvidia.so.0`.
Then there was a Github issue about [this](https://github.com/NVIDIA/nvidia-container-toolkit/issues/191). Missing `libegl1`. Perfect, it recognized Nvidia GPU.
From the [mod](https://forums.developer.nvidia.com/t/minimal-docker-vulkan-offscreen-setup/242883).
```
For any kind of rendering, even headless or off-screen rendering, you will need to have a render context, which is provided for example by EGL, not GLX. GLX are just GL extensions to be able to use X11 at all.
- MarkusHoHo
```
Should have paid more attention in Graphics class.

=> ChatGPT not enough, need Stack Overflow, Github issue, Google, too. But GPT good for brainstorming, first stage diagnostic first. *Trust, but verify*
=> Never mentioned in Nvidia official guide (libegl1). Stupid.
=> Intel/AMD GPU. /dev/dri + libvulkan1 = Profit ???
=> Now know why people hate Nvidia Closed-source driver