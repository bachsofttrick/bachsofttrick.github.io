2:I[5450,["972","static/chunks/972-d5884f09dde0387b.js","337","static/chunks/337-0220480c44daf22d.js","931","static/chunks/app/page-ba3b18a7620de09d.js"],"BlogPosts"]
3d:I[4888,["972","static/chunks/972-d5884f09dde0387b.js","185","static/chunks/app/layout-9c3ad277717235be.js"],"GoogleAnalytics"]
3e:I[2645,["972","static/chunks/972-d5884f09dde0387b.js","185","static/chunks/app/layout-9c3ad277717235be.js"],"Navbar"]
3f:I[4707,[],""]
40:I[6423,[],""]
3:Tb0c,[Link](https://github.com/bachsofttrick/ocr-web) to my OCR web project.

Today, I used Claude Code to write my frontend for my app, an OCR (Optical Character Recognition) using
a LLM. LLM might not be the best tool for doing OCR, but it gave me a chance to learn about
how OpenAI, llama.cpp and various other LLMs communicate with their frontends and tools.

To install and use Claude Code, follow this [guide](https://code.claude.com/docs/en/overview). Very quick
and easy. You need Claude Pro, though. With any Claude subscription, you [get](https://support.claude.com/en/articles/11647753-understanding-usage-and-length-limits) 200K tokens per context window. There is also
[usage limit](https://claude.ai/settings/usage) you have to watch out when using Claude. But I got 
Claude Code to make the frontend and burned through 80K tokens, which was around 35% limit. There is
plenty if your project is simple. 

I gotta admit. This thing did my frontend in 10 minutes what I would need a few days to do. I looked
through the code. It was good code, but I'm not the best developer to judge it. It just worked. 
It even wrote the README.md, the bash script for getting the OCR model and running llama.cpp, for goodness 
sake. I guess that's what everyone is up in arms about. The machine that do the work of many days to one
(with low price of $20/month).

Essentially, Claude Code is a LLM command line program that works like how llama-cli works, with additional 
function calling and ability to compress a conversation in the event of low context window. 
I asked what Claude Code is and how it [compresses](https://github.com/bachsofttrick/ocr-web/blob/main/compact.md) a conversation, it even came up with an [implementation](https://github.com/bachsofttrick/ocr-web/blob/main/claude-code-impl.md) using local LLM and function calling. I'm not sure if that is how 
Claude Code is made. But it was impressive it even gave me instructions to build something similar in 
abilities.

Note that Claude *only* did the frontend portion. The rest was written by me. That part doesn't work, 
though, because llama-cpp-python was kinda useless in models outside of its [recommendations](https://llama-cpp-python.readthedocs.io/en/latest/#multi-modal-models). I'm thinking of putting the part I did as 
"legacy", but who knows? I might come up with something else in mind.

But looking at it making my program, it made me sad. While it's impressive how far we've come in terms
of AI doing our works, I missed the ability to just do it myself. Sure, it takes longer. But using
LLM as a souped-up Google/StackOverflow to help me code is much better for me to learn the code. It makes me feel like I accomplish something, instead of directing someone to do it.

<br/>
<Quote 
	quote={"The joy is in the journey, not the destination."}
/>4:Tc93,For two weeks, I have been hard at work learning FastAPI and GraphQL. And I have some opinions
on them.

Firstly, I like FastAPI. It seems like Python is finally catching up to NodeJS a bit with
implementing async operations in this library. I think I have a soft spot for these lightweight
libraries: FastAPI, Flask, ExpressJS. They aren't used in large sites. Corporations prefer
big battle-tested frameworks more. But if I want to spin up a quick web server, these frameworks
are my jam. I wrote my home server hub page using ExpressJS with a custom web templating engine
(I didn't know that practice until later, go figure).

However, I don't like [FastAPI](https://fastapi.tiangolo.com/learn/)'s documentation. They focus too much on OpenAPI/Swagger and go in-depth on what each component does. I think that would be more helpful for newcomers to the web scene. But I've been for years, and I think OpenAPI should be the focus far
later in the documentation. I rather just make something by using my previous knowledge
about web development and applying them to FastAPI, resulting in this [project](https://github.com/bachsofttrick/fast-team-task/). For this, I held [ExpressJS](https://expressjs.com/en/guide/routing.html) documentation in higher regard. Maybe because it's quicker to get into it without OpenAPI part. But automatic doc
is nice, don't get me wrong.

Another thing I picked up while learning [FastAPI](https://fastapi.tiangolo.com/tutorial/dependencies/classes-as-dependencies/) is that it's much easier understanding [Dependency Injection](/blog/Tech/250707).
Much like [NestJS](https://docs.nestjs.com/fundamentals/custom-providers) except less verbose, they have
a way to make DI enjoyable. Of course, I have to implement my own IoC container, unlike NestJS. So
I recommend anyone wanting to learn DI, to start from FastAPI or NestJS. Starting from *.NET/C#* and
you see your blood on a wall from banging your head against it a lot.

While learning FastAPI, I picked up GraphQL as well. At first, I didn't quite understand the reason for its existence. By learning about Facebook being the creator of GraphQL, and many videos later, I can see their POV. Nowadays, for one page, we need to fetch a lot of data, so a lot of API calls, which increase latency
and loads on the backend server. Of all that APIs, some can get too much data (Over-fetching), some
not enough (Under-fetching). There are also versioning, changing schemas. What if there's a way
to call just once, and have it fetch everything you need, and nothing else? And also strongly typed schema. So, GraphQL was born.

In the CQRS design pattern (Controller → Service → Repository → Database), GraphQL would sit in the
Controller. GraphQL schema consists of \{ query, mutation \}. In each, there are resolvers, or functions
that perform specific actions. Think of it like a route in a controller.
For query, it's getting data. For mutation, it's changing them.
At least that's the general concept. Resolvers could do pretty much anything like a normal function,
as long as you return a type.

Here are two videos that I found helpful explaining GraphQL.

<DoubleYtEmbed vid1="eIQh02xuVw4" vid2="Zg4XIpnLWQg"></DoubleYtEmbed>5:T9f4,A major task I was given this week was to figure out why pgAdmin wasn't working.
So that task was on the high-priority list, because without it, our database
administrator wouldn't be able to work. While investigating the problem, I ran
into these errors:
```
File "/usr/lib64/python3.9/random.py", line 61, in <module>
from _sha512 import sha512 as _sha512
ModuleNotFoundError: No module named '_sha512'
```
<br/>
```
File "/usr/lib64/python3.9/random.py", line 64, in <module>
from hashlib import sha512 as _sha512
File "/usr/lib64/python3.9/hashlib.py", line 77, in <module>
import _hashlib
ImportError: /lib64/libcrypto.so.3: version `OPENSSL_3.4.0' not found (required by /usr/lib64/python3.9/lib-dynload/_hashlib.cpython-39-x86_64-linux-gnu.so)
```
There was something preventing mod_wsgi, which is an Apache module for running Python web apps,from
running. At first thought, it was incompatible OpenSSL version with the server. I checked, and we had
version 3.5. Maybe somebody updated it recently and it caused problems. But that can't be verified.
I also tried importing the library by hand using the command below. It was working fine.
```
python3 -c 'from hashlib import sha512 as _sha512;print("OK")'
```
Another way to test it was to run a test script through Apache, testssl.wsgi:
```
import sys
import platform
try:
    import ssl
    ssl_info = ssl.OPENSSL_VERSION
except Exception as e:
    ssl_info = f"FAILED: {e}"

def application(environ, start_response):
    start_response('200 OK', [('Content-Type','text/plain')])
    return [
        f"Python version: {platform.python_version()}\n".encode(),
        f"Python executable: {sys.executable}\n".encode(),
        f"SSL: {ssl_info}\n".encode(),
    ]
```
It also failed right at the ssl part. A check using `ldd /usr/lib64/python3.9/lib-dynload/_hashlib*.so`
revealed that it was using libcrypto.so.3, which linked to /lib64/libcrypto.so.3. *libcrypto* is
how Python gets its hash algorithms, and it is loading fine otherwise, but not inside Apache.

I was considering reinstalling Python 3. But it was too drastic as it would affect *everything*
inside the OS. A lot of services depends on Python and it is working fine, except for this
Apache incident. So I was left with two more options:
- Reinstall mod_wsgi
- Use Gunicorn to run pgAdmin, which is reversed proxy from Apache
I worked with the sysadmin to get a snapshot of the system before proceeding. I reinstalled mod_wsgi,
and wouldn't you know it? It worked flawlessly again. Lucky I didn't have to reinstall Python.6:T5c1,There is an advantage to living alone. I don't have to cook for anyone else to I can test new skill, new
recipe. But it is sad that nobody gets to enjoy my cooking.

Anyway, I have been doing a lot of frying. Pictured below are kimchi-jjigae, also known as kimchi
stew. I quite like the taste of kimchi, but it only serves as a flavor, not the main focus because
it's too salty and spicy. The first one, I fried some Spam and egg tofu. You have to try it, it's
delicious, fatty. But I had to use a nonstick pan because of the tofu. Fry the egg tofu long enough,
it became crunchy like an actual fried egg. Spam when fried gave out a savory, tasty new flavor.

The second one was the leftover stew with roasted drumsticks. I discovered that frying or roasting meat imparts that browned flavor to the protein, called the *Maillard reaction*. It tasted great, even as leftover. It's even better if you save some of the browned liquid from the roast for the soup.

<Gallery imgs={['/images/blog/Cooking/25/251211/jjigae2.jpg','/images/blog/Cooking/25/251211/jjigae1.jpg']} />

This one was the Hamburg steak I fried with my stainless steel. Turns out 20% fat inside a beef patty
is quite a lot of fat, so I didn't really need a lot of oil. Taste like browned steak but juicier, not as
tough. With a meat thermometer, I didn't have to worry about meat not cooking through, so I cooked it for
10 minutes at medium-low temperature.

![](/images/blog/Cooking/25/251211/hamburg.jpg)7:T950,This economy is hard. I applied to over 200 job applications, mostly through LinkedIn. Now I know
that LinkedIn is quite crap, but it is the one I used the most, and I had some luck before, mostly
with unpaid internship or volunteer (I wouldn't take it, though. I already have experience).
I also tried out Indeed, Glassdoor. Even Y Combinator for startups. I learned a fair bit about 
applying for jobs. Of course these are what I find useful for now, you may disagree:
- It is best to submit *as soon as the job post hits the board*. Apply as soon as possible.
Now, I didn't figure it out until late, but you can sort by date by finding this part under
"All filters". However, I find this not very useful, since it just gives you *any* job that is
the latest, sometimes not even relevant to your search.

![](/images/blog/Job-Search/2025/251128/screen01.jpg)

- As in [this](https://old.reddit.com/r/jobsearchhacks/comments/1jedoz0/linkedin_url_hacking_to_find_jobs_posted_less/) Reddit post, you can manipulate the search
parameter on your address so that it narrows the time window. For example:

```
https://www.linkedin.com/jobs/search/?currentJobId=4339810337
&distance=25&f_TPR=r3600&geoId=103644278&keywords=software%20developer
&origin=JOB_SEARCH_PAGE_JOB_FILTER&refresh=true
&start=25
```

with:
  - `distance=25`: Controls the job search radius in miles.
        Example: If you want to search within 50 miles, change it to distance=50.
  - `f_TPR=r3600`: Filters job postings by recency. r3600 means jobs posted within the last hour.\
    Common values:
      - r86400 (Last 24 hours)
      - r604800 (Last week)
      - r2592000 (Last month)
  - `geoId=103644278`: Specifies the geographic location.
  - `keywords=software%20developer`: Determines the job title or keywords being searched.
    %20 represents spaces, so this query searches for Software Developer”
  - `location=United%20States`: Defines the search location.
    Example: Searching in Florida? Change it to `location=Florida`.
  - `sortBy=R`: Sorts results by relevance (R).
    Options:
      - DD (Date posted)
      - R (Relevance)
- LinkedIn count the *number of people clicked apply* based on the number of clicks on the post.
It does not care whether you finish the application or not. This number, and the number of applicants
for Easy Apply, are rollovered to the reposted post.

Happy hunting.8:T438,I have tried frozen pizza before from Walmart. I remembered it was like 5 bucks. And it was super salty. I wondered if I threw at pizza away after first bite, or I tried to swallow the pizza because I'm a cheapskate.

Anyway, I am trying it again, this time 1.49-buck Roma pizza. It is a simple four-cheese pizza. I think
these frozen pizzas should be baked in a toaster oven instead of an air fryer, because an air fryer would dry the outer part of the pizza before it cooks the cheese.

<Gallery imgs={['/images/blog/Cooking/25/251126/pizza1.jpg','/images/blog/Cooking/25/251126/pizza2.jpg','/images/blog/Cooking/25/251126/pizza3.jpg']} />

This pizza baked pretty quickly, only took 10 minutes. And it tasted...alright. It was a thin curst, but I can clearly tasted the tomato sauce. But only a hint of cheese, despite tons of cheese on top.
The best part was that the pizza *was not* salty like Domino's pizza. So that's a big win for me.
Maybe if I'm craving for a pizza, a frozen one might be the fix. I might try out the pizza dough 
next time, since I have a toaster oven.9:T7b2,This is my first official recipe on this blog. It is a request from a good friend of mine.
He loves the chicken rice because it is rich, fragment. This is a dish often served during
special occasions in Vietnam, usually ancestor worship day every month. I want to write
this recipe with no precise measurement, like Uncle Roger often says: "Use feeling".

## Ingredients:
- Dried Jasmine rice
- Chicken broth
- Chicken fat
- Gingers (optional)
- Spring onions / Scallions (optional)

![](/images/blog/Cooking/25/251123/image.jpg)
<center>Chicken rice with stir-fried beef and spaghetti squash soup</center>

## Directions:
- Make enough rice for how many people going to eat the rice. Put the dried Jasmine rice in a bowl,
pot. Make sure it's a separate one from the rice cooker pot. The rice cooker pot usually has a
non-stick surface, and we don't want that surface to be scratched up from washing rice.
- Wash the dried rice 3 times. The water doesn't have to be completely clear.
- Put the washed rice in the rice cooker pot. No water in the rice pot for now.
- Put enough chicken broth to cover the rice up to **one** finger joint. The chicken broth can
be from canton or freshly made. For freshly made, boiling or steaming some chicken drumsticks
gives you chicken broth, and meat as well to go with that rice.
- Add a teaspoon of chicken fat. Chicken fat is a bit harder to get. I usually render the fat
from chicken thighs' skins beforehand. You wouldn't believe just how much fat there is in
those thighs here in the US. That's industrial chickens for you, 4 quarters yield enough fat
for me to use for two weeks.
- Add the aromatics. This one is optional. For today, I added some crushed gingers and spring onions.
- Cook the rice in the rice cooker normally.
- After 25 - 35 minutes, out comes the perfectly cooked chicken rice.

This recipe can be used to make delicious chicken sticky rice, too. We did that a lot in Vietnam.

Happy Thanksgiving, everybody.a:T551,Recently I got an assignment that needs to use Docker. Usually it can be done with command
line, but a lot of time, I use Portainer for the convenience. But today, I wasn't able
to access my local Docker environment. It kept saying "the environment named local is unreachable".
I discovered that an update to Docker version 29 introduced [breaking changes](https://docs.docker.com/engine/release-notes/29/):
```
The daemon now requires API version 1.44 or later (Docker v25.0+).
```
A user named *JoynalFrametOlimpo* at this Github [issue](https://github.com/portainer/portainer/issues/12925) showed me a way to downgrade the API version 1.41 by changing `/etc/docker/daemon.json`
```
{
    "min-api-version": "1.41",
    [Other settings down here...]
}
```
Afterwards, it just `systemctl restart docker.service` and Portainer worked again. Keep in mind
that I ran an older version of Portainer, 2.27.9 LTS, because I hate the UI change of the
[new versions](https://docs.portainer.io/release-notes#release-2.32.0-sts). Also, I don't want
to lose the "stacks" I deployed using Portainer.

In the future, I might have to migrate deploying "stacks" to actually using Docker Compose,
because everytime I change version on Portainer, I end up always re-deploying these Docker
Compose anyway, which is a giant waste of time. Seems like *reinventing the wheel* to me.b:T209f,After using ollama to run local LLMs on my computer, I recently switched to llama.cpp. That was because ollama,
when running a model, would use up a lot of CPU power, despite the entire model being on 100% GPU. The whole
laptop sounded like a plane taking off anytime it tried to create anything coherent. [llama.cpp](https://github.com/ggml-org/llama.cpp)
is faster (not using much CPU), use Vulkan as the backend for inference so cross compatible with the Intel
integrated GPU (although you can compile one with CUDA in mind).

I tested llama.cpp using various backends:

<Table data={{
    'headers': ['Backend','Tokens/s'],
    'rows': [
        ['CPU only (i7-9750H)', 5],
        ['Intel UHD Graphics 630 (Vulkan)', 2],
        ['Nvidia Geforce GTX 1660 Ti (Vulkan)', 32],
        ['Nvidia Geforce GTX 1660 Ti (CUDA)', 37],
    ]
}}></Table>

Looks like CUDA surpassed Vulkan. But good luck setting that up in Docker when the development environment
weighed over 9GB, need the exact version of [CUDA](https://hub.docker.com/r/nvidia/cuda) to the [CUDA](https://stackoverflow.com/questions/53422407/different-cuda-versions-shown-by-nvcc-and-nvidia-smi) on `nvidia-smi`,
AND have to compile for 20 minutes with `-j6` enabled. Just stick to Vulkan.

While toying with an OCR(Optical character recognition) model, [LightOnOCR](https://huggingface.co/noctrex/LightOnOCR-1B-1025-GGUF),
I came up with an idea. What if I can do my homework on paper, then have a model transcribe into text on the computer?
But taking pictures and passing through the chat window is a lot of work.Maybe if there exists a specific page
to do one thing. So I got to work for my idea, ocr-web. I whipped up a Dockerfile from ubuntu, got
[llama-cpp-python](https://github.com/abetlen/llama-cpp-python) to download a model in the container.
If I ran llama.cpp at this moment, it would only use CPU.

Following online guides on how to get Nvidia GPU working with Docker, I installed
[the container toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)
from Nvidia. and ran the demo:
```
sudo docker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi
```
Successful. It printed the graphics card and the percentage in use.

Next, I went to get it working on Docker Compose. I followed [this](https://docs.docker.com/compose/how-tos/gpu-support/)
guide, but it was out of date in `capabilities` part. Still I used it in the beginning. And llama.cpp couldn't find
any GPU. If I put
```
devices:
    - /dev/dri:/dev/dri
```
in, llama.cpp would find the Intel GPU. The Nvidia Container Toolkit was installed, nvidia-smi found the GPU, but
llama.cpp couldn't find the Nvidia GPU. This was after I already installed `libvulkan1`.

I installed `vulkan-tools` and used `vulkaninfo | vi -` to find out what happened. It only found LLVM as GPU0, which
is software-based Vulkan, but no Nvidia. ChatGPT suggested adding `runtime: nvidia` to the Compose yaml.
Previously after running the Docker Compose yaml, I would recreate the container with that runtime in
the setting. Now Docker Compose would deploy with `nvidia` runtime in mind, but still not work.

There was a part inside the container toolkit's page I hadn't read, [Specialized Configurations with Docker](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html).
The page showed many things missing from the Docker page. `capabilities` now is `[graphics]` to use Vulkan. I tried
`capabilities: all` but it just got an error from Docker Compose. I also added
`NVIDIA_VISIBLE_DEVICES=all`, `NVIDIA_DRIVER_CAPABILITIES=all`. Still not working as llama.cpp refused to see the
dedicated GPU (Nvidia).

Another suggestion from ChatGPT was using `vulkaninfo | grep "GPU id"`. So I did, and got this result:
```
ERROR: [Loader Message] Code 0 : libXext.so.6: cannot open shared object file: No such file or directory
ERROR: [Loader Message] Code 0 : loader_icd_scan: Failed loading library associated with ICD JSON libGLX_nvidia.so.0. Ignoring this JSON
ERROR: [Loader Message] Code 0 : libXext.so.6: cannot open shared object file: No such file or directory
ERROR: [Loader Message] Code 0 : loader_icd_scan: Failed loading library associated with ICD JSON libGLX_nvidia.so.0. Ignoring this JSON
'DISPLAY' environment variable not set... skipping surface info
error: XDG_RUNTIME_DIR is invalid or not set in the environment.
        GPU id = 0 (llvmpipe (LLVM 20.1.2, 256 bits))
        GPU id = 0 (llvmpipe (LLVM 20.1.2, 256 bits))
        GPU id = 0 (llvmpipe (LLVM 20.1.2, 256 bits))
        GPU id = 0 (llvmpipe (LLVM 20.1.2, 256 bits))
```
For `libXext.so.6`, it is missing `libxext6`. I added that library into the Docker Compose file. After that, this was the
new result:
```
ERROR: [Loader Message] Code 0 : loader_scanned_icd_add: Could not get 'vkCreateInstance' via 'vk_icdGetInstanceProcAddr' for ICD libGLX_nvidia.so.0
ERROR: [Loader Message] Code 0 : loader_scanned_icd_add: Could not get 'vkCreateInstance' via 'vk_icdGetInstanceProcAddr' for ICD libGLX_nvidia.so.0
'DISPLAY' environment variable not set... skipping surface info
error: XDG_RUNTIME_DIR is invalid or not set in the environment.
                GPU id = 0 (llvmpipe (LLVM 20.1.2, 256 bits))
                GPU id = 0 (llvmpipe (LLVM 20.1.2, 256 bits))
                GPU id = 0 (llvmpipe (LLVM 20.1.2, 256 bits))
                GPU id = 0 (llvmpipe (LLVM 20.1.2, 256 bits))
```
So, almost there. Just a bit more. For this error, ChatGPT suggested looking for `/usr/share/vulkan/icd.d/nvidia_icd.json`.
And for some stupid reason, it didn't exist in the container, so I had to map it from the host in readonly mode. Of course,
didn't work. This time, Chat said that file referenced OpenGL, not Vulkan. It kept calling out `libnvidia-vulkan.so.1`,
even if I combed through my host machine to find it. It didn't exist, but ran Vulkan fine. Typical **hallucination**.

Up to Google. Now, searching `libnvidia-vulkan.so.1`, I found this [article](https://stackoverflow.com/questions/74965945/vulkan-is-unable-to-detect-nvidia-gpu-from-within-a-docker-container-when-using)
on Stack Overflow. It led to [this](https://github.com/NVIDIA/nvidia-container-toolkit/issues/16) Github issue. Seems
to be a common problem. But there was no solution. Undaunted, I searched once more, this time `docker ERROR: [Loader Message] Code 0 : loader_scanned_icd_add: Could not get 'vkCreateInstance' via 'vk_icdGetInstanceProcAddr' for ICD libGLX_nvidia.so.0`.
Then there was a Github issue about [this problem](https://github.com/NVIDIA/nvidia-container-toolkit/issues/191).
We were once again getting somewhere. The container was missing `libegl1` library. 
After installing this library, perfecto. The container recognized Nvidia GPU.
```
'DISPLAY' environment variable not set... skipping surface info
error: XDG_RUNTIME_DIR is invalid or not set in the environment.
                GPU id = 0 (NVIDIA GeForce GTX 1660 Ti)
                GPU id = 1 (NVIDIA GeForce GTX 1660 Ti)
                GPU id = 2 (llvmpipe (LLVM 20.1.2, 256 bits))
```
Now why did the container need EGL? According to Nvidia forum [moderator](https://forums.developer.nvidia.com/t/minimal-docker-vulkan-offscreen-setup/242883):
```
For any kind of rendering, even headless or off-screen rendering, you will need to have a render context,
which is provided for example by EGL, not GLX. GLX are just GL extensions to be able to use X11 at all.
- MarkusHoHo
```
Ah. I should have paid more attention to my Graphics class.

While testing llama-cli inside Docker, I ran into another problem. Turns out llama-cpp uses OpenMP, even with using
Vulkan as the backend for inference. `ldd libggml-cpu-haswell.so` revealed that it need libgomp.so.1, which is in libgomp1
library, as in this [issue](https://github.com/ggml-org/llama.cpp/issues/14691).

In summary:
- ChatGPT is only your first diagnostic. It alone is not enough. You still need Stack Overflow, Github issue, Google, too.
But LLMs are good for brainstorming. *Trust, but verify*.
- This entire wild goose chase would have never happened if it was mentioned at all in Nvidia official guide (libegl1).
Stupid. While Intel/AMD GPU, I just imported /dev/dri + libvulkan1 = Worked deliciously.
- Now I know why people hate Nvidia Closed-source driver.c:Tb45,I have a dream. That I, one day, shall have my own ChatGPT. Because after being an avid user since 2023, it has
been so slow and laggy. Not like many people, I hold no emotional attachment to ChatGPT models, only its uses
and effectiveness. Despite its overtly cherry nature, ChatGPT 4 and 4o represented the best OpenAI has to offer
in terms of speed and accuracy. Those reasoning models have never been appealing to me. They are just models reiterating their
own answers over and over again. These are "souped up" chatbots, no reasoning capability. And sometimes I just
need a quick answer. Right or wrong, ChatGPT always gives me a starting point. They make great rubber ducks to iterate
ideas with. Even since OpenAI "upgrades" to version 5, ChatGPT has become sluggish. It is not more correct, nor faster
than previous models. They even disabled your ability to switch models. Like bro, I don't need a chatbot to spend
a minute coming up with an answer. Just give me something to start.

I looked at some ways to run LLMs locally before. But I was turned off by how much VRAM they need to run big models
like gpt-oss. And then, something randomly clicked yesterday. Pretty sure I just searched something randomly, as 
always. And I came across [ollama](https://ollama.com/library). There are models that are much smaller than the
big boy gpt-oss. Like the deepseek-r1:8b, or the gemma3:4b. The 8b stands for billion parameters. The bigger the number, 
the more accurate the output, but also the larger the size. So these two models fit perfectly in my 6GB GTX 1660 Ti.
And the ollama is easy to install and use. I chose the manual installation method: download an archive and run its binary.
Its interface is reminiscent of Docker. So just `ollama serve &` first to create a server. Then `ollama pull <model>`
and `ollama run <model>` and you are good.

I read some online posts on Reddit, [r/LocalLLaMA](https://old.reddit.com/r/LocalLLaMA/). There seems to be an all-out war
between these three applications:
- [llama.cpp](https://github.com/ggml-org/llama.cpp)
- [ollama](https://ollama.com/)
- [LM studio](https://lmstudio.ai/)

I won't go into details, because even I am at a loss myself. I use ollama because it's easy to get your feet wet, like Docker
before learning Kubernetes. ollama loses out to llama.cpp in terms of performance, functions. There are
[beefs](https://github.com/ollama/ollama/issues/11714#issuecomment-3172893576) between the two applications.
If I ever decided to get serious about this running local GPT seriously, I will consider llama.cpp. Or vllm like
[this guy](https://old.reddit.com/r/LocalLLaMA/comments/1opa6os/local_setup/).

Other than that, I am just happy to have my own DIY GPT.

<br/>
<Quote 
	quote={"This content was not written, nor helped written, by ChatGPT, Gemini, DeepSeek, or any of the LLMs. Viewer discretion is advised."}
/>d:T55d,I have been thinking. Let's say there are chicken drumsticks:
- If I marinate an entire drumstick, it will only penetrate the outer layer of the meat. The inside would still be
normal chicken flavor, unsalted.
- If I cut the drumsticks to many small pieces, the marinate can go through. But that is a lot of work, and not
easy to store in frozen bags. I usually store the drumsticks in whole, at least they stick as drumsticks, easy
to defrost later. If I store a bag of chicken pieces, they will clump together, making them hard to defrost,
especially in microwave as they can be cooked through before defrost.

So I came up with an idea. Studying Chinese cooking techniques, I saw that they cook meat, vegetables, anything
that takes a while to cook first. Then those are put aside to make the sauce. So I did just that. I cooked the meat
first, whether is cut or whole, in an air fryer. Separately, on the stovetop, I heated up a pan, made a sauce
out of oyster sauce, some chilli and paprika. Then I **basted** the sauce on top of cooked meat, as in putting
the meat in the pan, pouring the cooked sauce on with a spoon. This is like basting a steak. Then meat went back to the air fryer to finish cooking. Voila, no different than cooking everything on a pan. What's more, cooking in an air fryer feels less oily on food, food is less dried I think.

So give it a try.e:T4be,I have been eating a lot of Panda Express for lunch because it's cheap. $10, 1 chicken breast, 1 something saucy,
rice, vegetables. I also enjoy the Beijing beef and Orange chicken. But now I found a few references on how they
are made. It's literally "battered chicken in sugar sauce", so is the beef dish. But I do like their idea of
cutting AGAINST the grain, using a bit of baking soda for tenderness, using cornstarch (and maybe egg whites, too)
to prevent the meat from drying out in high-heat cooking. I also learned to utilize some vinegar for citrusy
flavor, because as I learned from [Chinese Cooking Demystified](https://www.youtube.com/@ChineseCookingDemystified)
and looking at a lot of sauce bottles, they all shared a lot of common ingredients: water, sugar for sweetness,
white vinegar for sourness, flavor (some fruit extract, tomato paste, oyster extract), salt (or soy sauce if Chinese
sauce), thickener (corn starch, xanthan gum).

[https://www.youtube.com/embed/nM1GQNJU6LQ](https://www.youtube.com/embed/nM1GQNJU6LQ)

[https://www.youtube.com/embed/i-fU6MCPZ2M](https://www.youtube.com/embed/i-fU6MCPZ2M)

[https://www.youtube.com/embed/zc63e7ZKUrg](https://www.youtube.com/embed/zc63e7ZKUrg)f:T1745,In recent times, I have a chance to collaborate on a major project that powers a major state. It is a great 
opportunity, because I can see how my skill once again be used in the real world. However, I didn't realize
that this was a PHP project. No worry, though. Just another language to pick up.

Working with this language, I came to some impressions of my own. 

Some positives:
- I like that this was created to look like C++. So anyone writing in C++ can feel at ease with the language.
- Any change to a php file can be reflected right back. There's no compiling, no reset needed. You just type
the same php file into the browser, or F5. And it will run with the new code.

Now on to the negatives. Don't worry, there are plenty:
- I HATE C++. I dabbled in both C and C++. While malloc, pointer-in-pointer are something we all tripped over 
ourselves, C is something I consider a beautiful language. Easy to grasp, understand, nice syntax. C++ came
around with dumb stuff like `::`, making it hard to read, which PHP then learned from. Java, annoying as it is
to write, uses `.` instead. I wish kids are taught C instead of Python, or Pascal in my days (close enough to C but
useless in real-life). They would understand more of how computer actually runs, data structures, memory management.
- It's hard to debug. Normally when you type `echo 'hi'`, it will print to the browser. What happens when I don't
want to print to the browser, then? There is no `printf` to the console. So later I found out about error_log,
which does something akin to printf or console.log on Javascript. So I guess it's bearable. But I have to dig
for it. `var_dump` can be used to dump the entire object, at least that is neat.
- PHP is similar to a scripting language. Not like scripting Python, Javascript. More like bash of Linux,
batch of Windows. Each php run, each access is a fresh start. It's stateless, so they have to import classes,
library, configuration again. Not like other long-lived languages, frameworks. That's why POST with input value
is important, as they have states to give the server.
- Most languages and frameworks I know connect to a database through a series of connections called a pool. These
are reusable, so any query doesn't have to re-establish a connection to a database. But since PHP is NOT 
a long-lived language, it has to do such a thing. So mysqli only has 1 connection. No connection pool so no multi query. It will block if query. Even with MYSQLI_ASYNC. **Once you start an async query on a connection, the connection is busy until you call reap_async_query().** So it's NOT EVEN truly asynchronous, because there's no second connection to use unless 
you make a new one.
- Any long query, you have to make sure there is still response back to the browser, otherwise the HTTP server (those are
Apache and Nginx for anyone speaking software) will drop the connection. Here something I do while branstorming ideas
on improving a long procedure:  

```
$this->conn->query($sql, MYSQLI_ASYNC);
$allconn = [$this->conn];
$errors = $reject = [];
// Poll the database every 30 seconds
while (!mysqli_poll($allconn, $errors, $reject, 0, 30)) {
	// Print something to prevent timeout
	echo ";";

	// Force PHP to send output immediately, or else if the server holds onto buffer, it timeouts
	if (ob_get_level()) ob_flush();
	flush();

	// Always reset this array, it will be empty once mysqli_poll returns []
	$allconn = [$this->conn];
}
```
I don't expect this to be completely correct. After all, I thought of this while brainstorming. It didn't work, of course.
I couldn't access any other pages of that site, unless I was on another device.  
I just wish any long process would just be turned into a worker/background job, with a table to monitor it. So it doesn't
hang the entire site like that.
- Someone thought it is good to COPY an entire object in a foreach loop. This is by [design](https://stackoverflow.com/questions/8769288/php-ampersand-before-the-variable-in-foreach-loop). How fun!
```
foreach ($objs as $obj) {
    $obj.a = 2; // Actual $objs[i].a is still the original value
}

foreach ($objs as &$obj) {
    $obj.a = 2; // Actual $objs[i].a is still now 2
}
var_dump($obj); // Important gotcha with this is that the loop variable is leaked outside the loop scope
// unset the reference afterward!
unset($obj);

```
There is one more thing I found but unrelated to PHP language as a whole. Someone would write a JSON into a
div's attribute and htmlspecialchars it. So they can JSON.parse the element's value. I failed to see the reason
behind this move. Just write the JSON normally the first time around would have been better.

Rants over. All in all, unless I use a cheap PHP hosting, like [infinityfree.com](https://www.infinityfree.com/) to
write backend or something, I wouldn't be using this language. Python, though slower, is still more maintainable 
than this language.

To be fair, as I learned from many posts such as [this](https://old.reddit.com/r/webdev/comments/1ekuzmt/cmv_languageframework_performance_doesnt_matter/), [this](https://old.reddit.com/r/AskProgramming/comments/1fnvavy/do_efficient_programming_languages_matter_for_web/), [this](https://old.reddit.com/r/webdev/comments/aaxjft/in_an_average_web_app_what_part_of_it_is_usually/), most performance issues from a website or web app are database
problems (lack of index, lousy queries), questionable design choices for frontend (UI), backend (logic), 
overloaded Javascript libraries... I like this approach, **avoid premature optimization**. All this talks about
building scalable services, I don't like. What if your service never reaches 1M users? Then you are left with
wasted time that could be better spent with more features built.

<br/>
<Quote 
	quote={"No matter how great the talent or efforts, some things just take time. You can’t produce a baby in one month by getting nine women pregnant."}
	author={"Warren Buffet"}
/>10:T6f9,This is an article written for a food event I registered for OSU Global Food and Culture Celebration.
<hr/>

![](/images/blog/Cooking/25/250822/canh-ga-chien-nuoc-mam.jpg)

#### Ingredients
- Chicken wings. If you are a vegetarian, use hard tofu.
- Fish sauce. If you are a vegetarian, use vegetarian fish sauce, or soy sauce.
- Oil
- Spices: garlic, sugar, salt, pepper

#### Instructions
- Separate the drumettes from the chicken wings, so when you marinate the wings, it is easier for the marinate to penetrate
and easier to fry.
- Marinate with some salt, pepper, a touch of fish sauce for 20 minutes.
- Preheat a pan. Then add some oil, enough to half cover the wings.
- Put the wings in to fry for 10 minutes, until golden brown. Another way is to bake/airfry the wings.
- In a bowl, mix 1:1 a mixture of fish sauce and sugar. You can adjust to see how salty, sweet you want the sauce to be.
- Remove oil from pan and leave just a bit to fry garlic. After the garlic is fragrant, add the fish sauce mixture and
stir until it is thickened. Then put the wings in and stir them a bit, let them coat in the sweet, savory sauce.
- Dish up. And enjoy with some rice or bread.

#### History
It's not certain when this dish first appeared. It's been around since my generation.

#### Cultural Significance
- Although simple, cánh gà chiên nước mắm is both an everyday dish and a celebratory food. Families serve it at home for casual meals, but it’s also common at parties, weddings, and gatherings, since fried chicken wings are perfect for sharing.
- Among Vietnamese communities, this dish has become a favorite way to introduce others to Vietnamese flavors. It’s approachable (everyone loves fried chicken) but distinct because of the deep, savory-sweet fish sauce glaze.11:Tf48,After two months since the first [post](./Cooking/25/250611), I managed to "tame" the beast that is the stainless steel
pan. Through buying a new [8 inch one](https://www.amazon.com/Cuisinart-722-20-Classic-Stainless-Skillet/dp/B00008CM6A?crid=2JL5NN8RWYXJ1&dib=eyJ2IjoiMSJ9.FNnQYNXfLoGcUwOk0xo75nzL2GhLyCcrAjytK1nk38c8Grt2KG5rYcAZogL6mQ7XaQ4I95WU0klurPzXou5_R_jCsjA8wSuUtYDOTvRt-I6mvax03wkqn2uYCHo6wA8HCQHRNg9WsXjZgaD-jvHFwoMRNnw0Rwse6B-jsNjYfXieWszDa6k4s6EVHV3atTXApwW2oSmXOw3k8wljFjDUDnncdsTBq6HVkGk-9GIVFFuhtpzEk7S4_vjVm4_B_SFJQ84OzscBRCMxrVLAVZbXtqGhwtzY6fBcsplwkrq6h4o.XUiOccuGHYWQMFYZVc94lKh_0KG77LjgICZu3Tt2f7E&dib_tag=se&keywords=8%2Binch%2Bpan&qid=1755802284&sprefix=8%2Binch%2Bpa%2Caps%2C196&sr=8-5&th=1), I have been frying sunny side up
eggs every single day. Each failure, each stuck egg, I learned a bit more:
- An 8 inch pan has its own benefits. It is smaller than the 10 inch saute pan, meaning if I want to fry something quick, I can just grab the 8 inch instead of 10 inch. One of the drawbacks of stainless steel is you need *quite a bit more oil* than non-stick to prevent sticking. So it's best to have two sizes of pan.
- Another things I discovered is the [stove](./Cooking/25/250712) would not heat evenly, especially at the center where the heat
sensor stays. If I cranked it to maximum, it would heat up fast in some spot, but not at the center. So it's not that
the stove is weak, or the sensor preventing it running. It was just the dumb design of the heating element.

The actual steps of frying anything on a stainless steel pan goes as follow:
- Heat up the pan on medium, medium high for 2-3 minutes. For electric, that is about 1000-1200 watts. Up until you can spray some water to the surface of the pan, and it bounces
around in little water blob without splitting. If it splits, the pan is too hot. If it forms into larger blobs, the 
pan is hot enough.
- Put some oil so it covers the entire pan's surface. This is where *it takes a bit more oil for stainless steel* comes from. Turn the gas/power down to low. Leave it for 10 seconds so it heats up the oil. Afterwards, hold the pan up and give it a gentle swirl so the oil coats the pan's side wall. This ensures the food won't stick to the side wall of the pan.
- Put the food in and start frying. **DO NOT** lift the food or touch it after putting it on the pan. Leave it. After about 1 minute, **then** lift it slowly. Because it has created a crisp, cooked layer underneath, the food will be easy
to be lifted up with a spatula. If not, leave it a bit longer.

This works for any food, *except* eggs. If I beat up the eggs to make scrambled eggs, or omelette, it's fine. If it's
sunny side eggs, then it *will* stick. So I learn another way from [Chef Joshy](https://www.youtube.com/@chefjoshyjin/):
- Put oil in pan, then heat the pan up until the oil smokes. You should put *just* enough oil to cover the pan, because later, we can dump the *seasoned* oil.
- Dump the old oil. Then apply some more oil to cool the pan a bit. Turn the gas/power down to low. This is the new oil to cook eggs with. Leave it for 10 seconds so it heats up the oil. Also afterwards, hold the pan up and give it a gentle swirl so the oil coats the pan's side wall.
- Then put an egg in. **DO NOT** lift the egg or touch it after putting it on the pan. After about 1 minute, **then** lift it slowly. It should not stick, at least it creates a crust below the egg.

![](/images/blog/Cooking/25/250821/20250815_143230.jpg)
<br/>
<center>References:</center>

[https://www.youtube.com/embed/Gs6DXZMKVZs?si=WGi70rdorTgWQ_RM](https://www.youtube.com/embed/Gs6DXZMKVZs?si=WGi70rdorTgWQ_RM)

[https://www.youtube.com/embed/4cSYhLbIA4I?si=KPBC0Xut6G0bRBmK](https://www.youtube.com/embed/4cSYhLbIA4I?si=KPBC0Xut6G0bRBmK)

[https://www.youtube.com/embed/qPtE2QEzvbo?si=77PxCyofTrJKcjK9](https://www.youtube.com/embed/qPtE2QEzvbo?si=77PxCyofTrJKcjK9)12:T498,I just finished my 1-week job at a vet school. I was to guide and supervise the next generation of would-be veterinarians,let's call them "ensigns" like in TNG. They got to see if they cut out to be a vet. It was an easy gig. Free room, 3 meals a day, hot shower, laundry, a piano downstair. Few dollars to take home as payment. A few surprises, mostly happiness and fun. Most surprises came from me showing up at random times, helping out other staff with keeping an eye on things, or showing new attendees around. Everyone was really hardworking, attentive, more than I could. One moment stood out to me.

It was when we finished eating dinner, heading back to the dorm. But seeing that a lot of "ensigns" were bored, we decided to go to the football field. A lot of them played, some just enjoyed the scenery, the grass, the air. I was pleasantly surprised. Normally, I would have loved to spend time indoor, I thought everyone would just stick their heads to their phones. But that goes to show that life can still surprise you. Shows that there is still hope for the future.

They even made thank-you cards for every one of the staff. Which was considerate, heartwarming.13:T6b3,As I lived in the US for a while, I noticed that people cook using electric stove. It is not much different from back home.
My family switched to electric a while back, because somehow it cooks faster. But something I realized a while back, only
made clearer recently. As I got my hands on a portable hot place of 1000W, I compared cooking my food using the range vs
the hob. And somehow the hob won, even though the electric stove was supposed to have much more (power)[https://www.geappliances.com/appliance/GE-ENERGY-STAR-30-Free-Standing-Electric-Range-JBS360RTSS]. It was 1000W vs 1250W and 2400W.
Then how come a hob can make 1L of soup in 3 minutes, while it took 10 minutes to do the same on the small burner of 
the big stove.

Looking at the specification of the stove, I noticed these words. Sensi-temp technology, Temp Limiting Coil. Turns out
the electric stove has these sensors in the middle of the burner to detect when a pan or pot is overheat. Main problem
is, as a LOT of people have brought up from [this post](https://old.reddit.com/r/Appliances/comments/bbgmi2/sensi_temp_coil_burner_is_messing_with_my_cooking/) and [this video](https://www.youtube.com/watch?v=84pYbdTi_IE),
it causes the burner to not work as well as intended. Food not getting hot fast enough, burner still causes danger
WHEN THERE IS NO POT on top. It got to the point where a mini hob of 1000 watts can beat it in its own game.

This is a function designed for people who either don't know how to cook, or careless when cooking to the point 
of leaving the burner running while distracting. Cater to the lowest denominator. This just ends up frustrating
actual cooks everywhere because of idiots ruining it for everybody.14:T7e2,Back at my early web dev years, I didn't like .NET Core. It was mainly because of the new things I have never heard of.
What was dependency injection? It felt like magic behind the framework. 

This is my effort to explain what dependency injection is, from .NET Core. So normally, to use a class, you would 
instantiate one using new.
```
public class ReportService {
    private readonly EmailSender _emailSender;

    public ReportService() {
        _emailSender = new EmailSender(); // hard-coded dependency
    }

    public void SendReport() {
        _emailSender.Send("report.pdf");
    }
}
```
By using DI, you don't have to instantiate a class everytime you need to use it. They will be instantiated once at the
beginning and passed along in a container.
```
services.AddScoped<IEmailSender, EmailSender>();
services.AddScoped<ReportService>();

// Then injected by the framework
public class ReportService {
    private readonly IEmailSender _emailSender;

    public ReportService(IEmailSender emailSender) {
        _emailSender = emailSender; // dependency is passed in (injected)
    }

    public void SendReport() {
        _emailSender.Send("report.pdf");
    }
}
```
This makes the code more modular, testable, flexible, and maintainable. The main case I found for this is for testing,
when you need to replace the service with a testing one. Another one is easier to maintain, since you don't run
around, make new classes anymore.

It makes things difficult in the beginning, because it creates a "Where is this coming from?" effect—harder to trace what's actually being used. DI often encourages interfaces, which adds complexities to code. But it's necessary to learn
as this is Inversion of Control (IoC), a fundamental design principle where the control flow of a program is inverted.
You don’t create dependencies yourself — they're provided to you by the framework. In this instance from .NET Core:
- You register dependencies in a container.
- The framework resolves and injects them.15:T66a,Today I'm attempting to cook rice "again" in a pot. The last time I tried this, it was mushy, sticky, impossible to clean
out of a nonstick pot (by the way, I realized slowly that nonstick pot is a stupid idea. Best setup is nonstick pan/ steel pot).
This time, I got a brand new idea. Most likely recycling from how rice cooker cooks rice. So a rice cooker cooks rice at a
constant heat source. For my Aroma rice cooker, it was 300 watts. So I tried cooking the rice at level 3 of my stove in
the apartment, because in an experiment I did earlier, level 3 was comparable to my rice cooker when both were boiling
water. After 25 minutes (cause the stove had to heat up a bit), it was done. I tasted some and it was a bit mushy, but
overall, solid. It was better than my previous attempt with the cooking method of the Internet: boil then steam at low
burner level.

With maybe less water, this could work. Of course, I could try with either boiling water, or doing a hybrid: boil, then smaller at level 3, so it boils off the water AND the rice absorps some of it. 

The pot is still a pain to clean, though. Maybe soaking it with warm water for a bit is better.

The second time I tried today, I cooked it with level 4 burner. I cooked the rice in 20 minutes, then let it sit
for 5 more minutes. The rice came out almost perfect, just a tad mushy, I guess need less water. But there was a
sense that it was a tad dry, not fully cooked. Maybe just my feeling, but a bit more water, 5 more minutes in heat
would have helped.

![gallery](/images/blog/Cooking/25/250701-2/20250701_112055.jpg,/images/blog/Cooking/25/250701-2/20250701_192855.jpg)16:T546,This is an update on my journey towards understanding stainless steel pans.

I got myself a steel pan last week. It was on sale at Ross for 14 bucks. Can you believe it? 14 dollars for 10 inch
sauce pan. So I can fry, stir fry, make stew, soup. It's like a perfect well-rounded "potpan" I can use for anything.
This thing reminded me so much of the pot I used when I first got to the US. It was a big electric pot I used for 
everything as well. I was living in the dorm, so cooking was limited. And I couldn't go downstair to use the kitchen
because it was too far. So I used a big and a small electric pot for everything. That means the big one was also a pan.
I fried eggs in that. Because there were only two heat settings, I had to be careful to not burn the eggs. Was a fun
time, and really pushing my creativity in terms of storage, resource management and making use of what you have.

But I digress. I fried eggs yesterday by trying the old method. It was just medium temperature, adding oil in, and
frying the eggs. Granted, using this way, I had to baby the eggs to make sure they don't stick and burn. And they get 
burned easily. But I still managed to make it look good.

I guess I need some more practice, more understanding. Cause the Leidenfrost trick is not working for me.

![](/images/blog/Cooking/25/250701-1/20250630_141224.jpg)17:T7df,Yesterday I was at Grocery Outlets. And catching my eyes was sets of vegan cheese. Now I am a cheese enthusiast myself,
but I have been having difficulty eating cheese, or milk, only yogurt. So vegan cheese sounds interesting enough to try.
Also because I watched a documentary in the past about this kind of cheese.

[https://www.youtube.com/embed/YUcI5d3Gp8Q?si=EoLE-30Ut45foPtL](https://www.youtube.com/embed/YUcI5d3Gp8Q?si=EoLE-30Ut45foPtL)

I bought a slice of Brie "cheese" by [Nuts for Cheese](https://nutsforcheese.com/pages/about-us). Pricing of 4.99 dollars for a 120g piece, this cheese was twice as expensive as a President Brie wheel of over 200g. First look was that the paper box was quite catchy and nice.

![gallery](/images/blog/Cooking/25/250620/20250624_134425.jpg,/images/blog/Cooking/25/250620/20250624_134431.jpg,/images/blog/Cooking/25/250620/20250624_134435.jpg,/images/blog/Cooking/25/250620/20250624_134444.jpg,/images/blog/Cooking/25/250620/20250624_134454.jpg)

Opening it up showed us that piece of cheese. Unlike a real piece of Brie, it did not have a rind and a middle creamy
cheese. Instead, it was a uniform gray cheese. Slicing a piece for testing, it tasted tangy, salty, had a hint of cheese
and fermentation smell. So of course it tasted nothing like Brie, it was more "Cheddar" clone because of how salty it is.
I guess the salt is to cover up the fact this is not a cheese. I tried various vegetarian dishes in the past. A lot
of those used lots of salt and spices to cover up the vegetable flavor, too. I would appreciate it if they just not
add so much salt.

![gallery](/images/blog/Cooking/25/250620/20250624_134528.jpg,/images/blog/Cooking/25/250620/20250624_135816.jpg)

Coming to the US, I realized there is a market for vegan dairy product like cheese. But most of them used modified food
starch and chemicals, so this is a step in the right direction. It has less chemicals, bit more natural. But too pricey
and too salty for my taste.

Better luck next time, then.18:T549,This article follows this [article](https://askubuntu.com/questions/740757/switch-between-multiple-java-versions)
at AskUbuntu.
So basically I have a software for my Theory of Comp class, JFLAP. It runs on Java. But I use Linux for most of
my work. On my current system, it is running OpenJDK 21. So when I ran this, it went like:
```
Exception in thread "main" java.awt.HeadlessException: 
No X11 DISPLAY variable was set,
or no headful library support was found,
but this program performed an operation which requires it,

        at java.desktop/java.awt.GraphicsEnvironment.checkHeadless(GraphicsEnvironment.java:164)
        at java.desktop/java.awt.Window.<init>(Window.java:553)
        at java.desktop/java.awt.Frame.<init>(Frame.java:428)
        at java.desktop/javax.swing.JFrame.<init>(JFrame.java:224)
        at gui.action.NewAction$NewDialog.<init>(NewAction.java:123)
        at gui.action.NewAction.showNew(NewAction.java:87)
        at gui.Main.main(Main.java:122)
```
The above article showed me a way to change to an older version of OpenJDK, hopefully it runs better without error.
There are 2 ways:
```
update-java-alternatives --list
then
sudo update-java-alternatives --set /path/to/java/version
```
OR to have more user interaction:
```
sudo update-alternatives --config java
```
Whichever way I choose, it works. No more error.19:Tb4c,I have been building a program that play Reversi using two algorithm: Minimax and Monte Carlo Tree Search (MCTS).
This program pits those algorithms against each other in various Reversi matches, each with different configurations
such as the Minimax depths, MCTS iterations, board size.

It's quite intriguing how a small program can grow slowly in complexity. First with about 600 lines of codes. Now,
it's big enough I have to spilt the functions and classes to libraries in order to make it clearer to see. I also
I also added multiprocessing support for this program, cause let me tell you, when one match could last up to 10
hours. So long, I later added a stop early flag to break the game, and that long game was with multiprocessing.
The multiprocessing is to distribute the games out to many cores, so each CPU core plays one game. The reason for
multiprocessing and not multithreading is because this program is written in Python, thus subjected to Global
Interpreter Lock (GIL). 

A bug my partner found was that Python could not find WEIGHTS in MinimaxPlayer, the class for the Minimax algorithm.
Now, this wouldn't be funny if my code didn't work on my side, but it did still work. There was no error. He said
it only happened when he used multiprocessing mode. I also knew that he used Windows and I used Linux. So I got to
work. The function to import json in as weights for MinimaxPlayer was supposed to import weights in a static
variable for MinimaxPlayer, so that those weights can be available to any MinimaxPlayer declared.

Normally, Python’s multiprocessing.Pool creates separate processes, which do not share memory or class-level state. In the main process, the child processes (used by starmap) won’t inherit that WEIGHTS value. But WEIGHTS is a static variable
in MinimaxPlayer, that should mean it sticks through new processes, right? I found out that on Windows, the
multiprocessing module uses **spawn**. This means:

- Each subprocess starts from scratch by re-importing the module.
- Nothing from global scope (like class variables, or initialized data) is automatically inherited.
- Class-level MinimaxPlayer.WEIGHTS doesn’t exist unless explicitly initialized in each subprocess.

By contrast, on Linux/macOS, multiprocessing uses **fork**, which copies memory from the parent process, including class-level state — that’s why it “just works” there.

Now understanding the issue, it is easy to fix. Make WEIGHTS global in the main file, then pass it in MinimaxPlayer
when creating a new object.

This bug **highlights** the difference in OS architecture between Windows and Unix. In **fork** in Unix, the child process 
is a copy of the parent process (using copy-on-write), while **spawn** in Windows means starting a fresh, clean process.
If my friend hadn't use Windows to test, we wouldn't have caught the bug, considering its elusiveness.1a:Ta4d,Lately, between trying to survive error-correcting class and feed myself without killing my digestion,
I didn't have as much time to write blog. Another reason could be lack of things to say. However, a great thing
is writing blog like this helped me write an interview paper, so there's the plus side of this. The paper
wasn't like a research paper, so it used a more informal language, similar to the blog posts.

Anyhoo, a few months ago, I went to the Asia-Pacific Cultural Center. There was this beautiful Sony stereo.
Giant, 5-disc sleek CD player. So I went to the reception, asking if I could use it to open some music.
They said I could, and they couldn't help me with turning on the stereo. I said okay. That response probably
stunned me a little. Like how could a bunch of 20-year-old something, and there are 3 of them, not know how to
operate a stereo. I remembered being told about my past of how I could turn on a radio when I was four.
I am still capable of quickly working with any media machine to this day. That stereo, 20 seconds. Like, it
is not even that difficult. You use one machine, you use all machines. Well, except for my digital clock at
home I got for a dollar at a thrift store. Seriously, who thought holding the TIME button, and press HOUR,
MINUTE to adjust the clock was a good idea. What's wrong with the usual holding down TIME for setting mode?

Reading online and I encountered similar stories. Young people nowadays can't even operate computer at a basic
level. And I'm not taking about actually fixing computers, or using Linux. I'm talking, not know how
files work, how the Internet works, how to use Word on a basic level, etc. I always thought that by my next
generation, everyone would be awesome with computers, better than I could. Not going so far back that they
lose out to their parents, who probably even know how to open a browser to go on the Internet. I guess, 
with the proliferation of apps, i.e. everything being made into an app, it turns any low-level concept
into an abstraction, like how Python displaced C as the first language taught to the kids, or new Computer
Science undergraduate. Same as BASIC to Assembly, or C to Assembly. But that was abstraction by 
programming language. This is like not knowing Computer 101 because the younger ones are so used to smartphones
that they expect everything to come out of an app.

I guess torrenting, finding software in the mysterious corner of the web remain a dark art. On the bright side,
that means I'll never be out of a job teaching these fools. But with AI replacing everything, and everyone's job,
what would be the point?1b:Tb36,I have been running Linux as my main OS for two years now. There have been ups and downs, like some softwares plain
not working on Linux but have to run on Windows. Games are the biggest offenders. However, thanks to the efforts of Valve
with [Proton](https://steamcommunity.com/games/221410/announcements/detail/1696055855739350561), 
the [Wine project](https://www.winehq.org/), [DXVK](https://github.com/doitsujin/dxvk), 
[VKD3D-Proton](https://github.com/HansKristian-Work/vkd3d-proton), 
I was able to get some games playing, namely God of War 2018 and The Plucky Squire.

#### Install Wine
First, you need Wine, a translation layer for running Windows applications on Linux. 
Follow [instructions](https://gitlab.winehq.org/wine/wine/-/wikis/Download) on their website on how to do that. 
I recommend installing the **development** branch to get the latest features *while* maintaining stabilities. 
Staging is newer, but prone to bugginess.

#### Getting the games running
The games I mentioned earlier require [DirectX](https://en.wikipedia.org/wiki/DirectX), which doesn't exist on Linux,
as Linux is an Open Source OS. So they use [Vulkan](https://en.wikipedia.org/wiki/Vulkan) instead. That's where DXVK
and VKD3D. These libraries translate API calls from DirectX to Vulkan, which helps games that can't run on Wine on
its default DirectX libraries.  

Just download the libraries from the links, then copy the DLL files d3d11.dll, dxgi.dll, d3d12.dll, d3d12_core.dll
to the *system32* folder of your *Wine* folder. For instance,
```
/home/ubuntu/.wine/drive_c/windows/system32
```
similar to Windows folder structure.  

After that, open the terminal and type *winecfg*. With the interface, add these files in the dialog to override
the default of *Wine*. With each file, edit it to have Native (Windows) order.

![](/images/blog/Tech/24/241221/winecfg.jpg)
![](/images/blog/Tech/24/241221/order.jpg)

When you are done, double-click on the executable of the game, it should work. It did for God of War 2018.
Not so much for The Plucky Squire

#### DirectX 12 with VKD3D issue
When I tried running the Squire game, it got me an error saying Fatal error. Switching d3d12 and d3d12core
to builtin Wine libraries didn't help. It just said it didn't support DirectX12. Switching every files
to builtin gave me this render.

![](/images/blog/Tech/24/241221/builtin_squire.jpg)

So how do you fix this? Well apparently, according to this [release of Proton](https://github.com/ValveSoftware/Proton/releases/tag/proton-9.0-4), I was supposed to match the version of DXVK with a right one on VKD3D. So I downloaded DXVK
2.5.1 with VKD3D-proton 2.13. It worked at last. I'm not sure how does that make any sense. Something new to
learn then. However, DirectX 12 requires the game to cache shaders to disk, so it takes a while to start the game.
Your mileage may vary.1c:T63e,Rate: 4/5

It's a really good film. Looks like Dreamwork has cooked it again. After Puss in Boot 2, I thought there
is no way they can top that. And then they *quietly* released this. While it's not groundbreaking IMO,
it felt like a passion project. There was so much warmth, joy, heart put into this one film.
I'm not fond of the talking animal, despite many people claiming it won't work otherwise. I think it could.
But the dialogues here are not cringey, well-written so that's alright by me. The animation, oh the a-ni-ma-tion.
It is just breathtaking. Wish I had seen it in theater. I saw the movie in my home theater and it still looked
amazing. Combined with the soundtrack, beautiful. The plot, on the other hand, maybe didn't gel with me. While
I liked the theme of motherhood, maybe the execution is not there. I'm reminded of **The Iron Giant**, a film 
with somewhat similar premise. I broke into tears when the giant robot decided to help the boy, the town by colliding
with the missle, becoming their *Superman*. So maybe I'm different.

About the talking animal, I like to raise awareness to the show I'm currently watching, *Star Trek: The Next Generation*,
specifically the episode *Darmok* from season 5 episode 2. In this episode, Captain Picard and Captain Darmok must communicate with each other in order to survive a harsh environment as a test. So most of the episode is Picard trying
to communicate with a species talking in metaphors specific to their culture. That's what I wish for in this movie. For
the robot to be the one doing the talking, every animal stays quiet.1d:T5b6,I recently got into a new hobby, which is photography. At first, I wasn't sure I would like it.
Everyone seems to like taking so many photos nowadays, while I'm not too keen on that. I did view
some guides on the Internet. It taught me a few things about aperture, ISO, shutter speed, though that's
still quite hard to memorize. There were *Rule of Thirds*, *Leading Lines and Curves*, *Symmetry and Balance*,
etc.

![](/images/blog/Photography/24/241111/iso_shutter_aperture.jpg)

Last Saturday, I went to District 2 Connecting Bridge and took some pictures for experimentation. The results
were staggering. They surprised me. They came out good. Maybe a more professional photographer might criticize
me but hey, I quite like this new venture. So now, I'm expanding my blog to include this category, and many more
to come if I'm interested.

![gallery](/images/blog/Photography/24/241111/20241109_180801.jpg,/images/blog/Photography/24/241111/20241109_180913_1.jpg,/images/blog/Photography/24/241111/20241109_180933.jpg,/images/blog/Photography/24/241111/20241109_181116.jpg,/images/blog/Photography/24/241111/20241109_181144.jpg,/images/blog/Photography/24/241111/20241109_181230.jpg,/images/blog/Photography/24/241111/20241109_182039.jpg,/images/blog/Photography/24/241111/20241109_182043.jpg,/images/blog/Photography/24/241111/20241109_182508.jpg,/images/blog/Photography/24/241111/20241109_183010.jpg,/images/blog/Photography/24/241111/20241110_160343.jpg)1e:T1021,I always want to have a virtualization lab in my home. But I don't want my server to fully commit to that idea.
Even though Proxmox seems like a decent OS for the job, I still pick Debian for more customization. It's more
general-purpose compared to dedicated OS. There's only one package that can help me realize the dream, *Cockpit*.

[Cockpit](https://cockpit-project.org/) is a web interface for managing a server. It comes with many plugins that can be 
installed separately. I planned to use this for managing virtual machines, because this is the only application
with a UI to do so.

#### Installing
Quite easy if you're on Debian or Ubuntu. Just type
```
sudo apt install cockpit cockpit-machines
```
It will automatically install *Cockpit* along with VM plugin and other dependencies.

#### Quick look
Access the Cockpit UI through address [https://your.ip:9090/](https://your.ip:9090/). Your username and password
is your current account.

![](/images/blog/Tech/24/241019/1.jpg)
![](/images/blog/Tech/24/241019/2.jpg)

When you first log in, the account will be assigned *Limited access*, meaning it does not have *sudo* access.
You need to [escalate](https://cockpit-project.org/guide/latest/privileges.html) to *Administrative access*
if you want more functionalities.

#### Creating virtual machines
Now, this is the hard part. I tried getting it work in the past and didn't end well. With a new server, I intended to
do it again. Maybe this time it would work.  
Anyway, this is not a comprehensive guide, I got it working but I will try to retrace my steps and record them for
future references.

[These parts are referenced from this article.](https://help.ubuntu.com/community/KVM/Installation)  
First, run this command to make sure VT-x (Intel) or AMD-V (AMD) is enabled in BIOS.
```
kvm-ok
```
If it says **INFO: /dev/kvm exists** then you can proceed.  
Second, add your own user into group *kvm* and *libvirt*.
```
sudo adduser `id -un` kvm
sudo adduser `id -un` libvirt
```

Next, I need to set up a storage pool. In Cockpit, a storage pool makes sense for hard drives, not really for disk
images, because they would ask you to show them the *location* of the ISO file, regardless of it belonging in the pool.

![](/images/blog/Tech/24/241019/3.jpg)
![](/images/blog/Tech/24/241019/4.jpg)
![](/images/blog/Tech/24/241019/5.jpg)

When it asks you what type of connection, there are two types. These also show up when creating a virtual machine (VM).
The two types are system and user session:

**System**
- Ideal for server VMs
- VM will launch with root permissions
- Ideal networking support
- Permissions denied for disk images in home directories

**User session**
- Good choice for desktop virtualization
- VM launched with unprivileged limited access, with the process and PTY owned by your user account
- Restrictions in networking (SLIRP-based emulation) and PCI device assignment
- Disk images can be stored in user home directory

When first starting, I created like one type of pool, and another type of VM. So mix and match, which ended up with the
VM reporting error about permissions on the drive or images. Even if they both the same type (User session), I still
received some errors about permissions as well. So I consulted [this GitHub issue](https://github.com/jedi4ever/veewee/issues/996)
and some solutions worked:
- Change /etc/libvirt/qemu.conf to make things work. Uncomment user/group to work as root.
- Copy your ISO images and hard disks to /var/lib/libvirt/images. It only works for *system* VMs.
- Change permission and owner:group of folder you store disks in using chmod and chown, respectively.

I also adjust Spice and VNC listen address to be 0.0.0.0 by default *in /etc/libvirt/qemu.conf*, so I can connect to the VM [remotely](https://github.com/cockpit-project/cockpit-machines/issues/73).  
One last thing. Make sure the CPU type is **host-passthrough** for the best performance. According to
[an OpenStack post](https://wiki.openstack.org/wiki/LibvirtXMLCPUModel), there is a difference between
host-model and host-passthrough.

![](/images/blog/Tech/24/241019/6.jpg)1f:Tc8b,One of the most frustrating points of owning Intel laptops, or any laptops, is dealing with
heat issues. It usually stems from overclocking by the CPU. It's because of 
[Intel Turbo Boost](https://en.wikipedia.org/wiki/Intel_Turbo_Boost). It's a frequency scaler that can
change a CPU's frequency to go higher than base clock depending on workload. That's why when you 
search for a CPU, there are 2 frequencies, Base Frequency and Turbo Frequency. The Turbo Frequency
is for 1-core boost, multi-core boost is in lower frequency.

![](/images/blog/Tech/24/241018/9750h.png)

It makes sense on a desktop because we're not limited by battery life or thermal. But when you're on
a laptop, those are the main concern. And a laptop when boosting up, has a tendency to overheat, bad!
I have seen it reached 99 degree Celsius, even shutting down. So I have an aversion toward using 
Turbo Boost in a laptop and try turning it off. Several ways have been used to disable it.

#### Disable SpeedStep
This was my first method with my first laptop. However, it not only disabled the overclock, but also
disable frequency scaling completely, which was not ideal but I didn't know at the time. Dynamic frequency
scaling helps regulate power usage and thermal.

#### The 99%
My family had a convertible laptop with an [i5-7200U](https://ark.intel.com/content/www/us/en/ark/products/95443/intel-core-i5-7200u-processor-3m-cache-up-to-3-10-ghz.html). It was slow, ran hot as hell, small screen (13 inch) 
and expensive (800USD compared to 500 USD for a normal one). A way to deal with the heat was to go to **Power Options**
in Control Panel of Windows, click on *Change plan settings* of the current power plan, *Change advanced power settings*.
Afterward, scroll down to *Processor Power Management*. At *Maximum processor state*, fix On battery (and maybe
Plugged in) to **99%**. One downside is that you won't be accessing 100% of the CPU power. There is another way involving
[ThrottleStop](https://www.techpowerup.com/download/techpowerup-throttlestop/) but I've never looked into it.

![](/images/blog/Tech/24/241018/power-1.png)
![](/images/blog/Tech/24/241018/power-2.png)

#### Disable Intel Turbo Boost [(Linux only)](https://forums.linuxmint.com/viewtopic.php?t=355295)
This one was both hard and easy. Hard for anyone not understanding Linux. Easy because I think the way to do it is.
Use **Terminal** and type:
```
echo 1 > /sys/devices/system/cpu/intel_pstate/no_turbo
```
This willturn off Intel Turbo Boost, *for now*. The next time you reboot, it resets to 0. To keep it
last, put it in a file, chmod +x *that file* and put in  a cron job for every startup like
```
@reboot home/user/noturbo
```
or create an [*udev* rule](https://superuser.com/questions/1417292/udev-rule-to-start-a-command-on-ac-battery-plug-unplug-event)
if you want *plugged in* to have a different behavior to *battery*. Create a *powersave.rules* file, save it in
*/etc/udev/rules.d/*:
```
# Rule for when switching to battery
SUBSYSTEM=="power_supply",ENV{POWER_SUPPLY_ONLINE}=="0",RUN+="/home/user/noturbo"

# Rule for when switching to powersupply
SUBSYSTEM=="power_supply",ENV{POWER_SUPPLY_ONLINE}=="1",RUN+="/home/user/noturbo"
```20:T599,A week ago, I started transitioning from using my old laptop as a server to a brand new tower.
The old one worked fine, but it looked janky, hackney, unprofessional. Not too mention, it got
hit by my roomba all the time, disconnecting the hard drive connecting from a dock using a
USB cable. The new one has 4-core CPU i3-8100 instead of 2-core i3-4130U, and has a higher clock
too so it is faster. Other than that, it still runs Debian 12 like the last one.

However, I named the new one when installing *bach-server-2* instead of the old name, *bach-server*,
because at the time, I was moving back and forth between the two. Now that was finished, I renamed the new
one *bach-server*, but something happened. The SMB/Samba connection I used for file transfer seemed slower.
Any command run on sudo seemed sluggish, like the part where you enter the password showed up late.
And it turned out, according to this [post](https://serverfault.com/questions/38114/why-does-sudo-command-take-long-to-execute) from Server Fault, and [this] (https://www.linuxquestions.org/questions/linux-newbie-8/fedora-11-sudo-has-a-20-second-start-delay-732291/#post3575840) from Linux Questions,
it happens when I change the hostname like
```
sudo hostnamectl set-hostname bach-server
```
without changing the hostname in **/etc/hosts**, resulting in slowness.

So by changing the hostname, and the hostname in */etc/hosts*, everything works out again.21:T7e2,Today I got around to upgrade my old Ryzen PC. I gave it a new SSD to replace the old one,
because the old one had a smaller capacity. I decided to purchase an NVMe one,
[Lexar NM620](https://www.lexar.com/product/lexar-nm620-m-2-2280-nvme-ssd/). I chose this one
because while there was a Western Digital blue one, it was also a QLC SSD, which you **don't**
want to buy if you want the SSD to last a while.

However, when I tried cloning the drive from the old **SATA** drive to the new **NVMe** drive, 
an error came up when booting into Windows: INACCESSIBLE_BOOT_DRIVE, in Blue Screen of Death.
I didn't know what happened. Later, I cloned the old SATA to a new SATA drive and it booted just the same.
I tried installing a fresh Windows on the NVMe, then cloned the *partition* containing Windows on the 
Sata drive to the NVMe. Same problem.

So I looked up the Internet for this type of error occurring on Clonezilla. Turned out, I wasn't alone
in this regard. According to this [Superuser post](https://superuser.com/questions/1640562/inaccessible-boot-device-after-m-2-ssd-upgrade), because I installed Windows on a **SATA** drive first,
it will boot with the SATA driver in (StorAHCI), *without the NVMe driver* (StorNVMe). I need to change
Windows *in the SATA drive* to boot from NVMe, so they load the NVMe driver in first, using this command:
```
sc.exe config stornvme start= boot
```
This will activate the Windows' built-in NVMe driver during the early boot phase. Once that's done, I cloned
the system to the NVMe SSD. It worked and the system worked normally afterward.

Much difficulty cloning drives like this, I wonder if things are easier when cloning happens on Linux.
But then I remember you have to modify /etc/fstab, GRRUB configurations or else the system won't boot.
So nevermind. Just wonder if I have to load NVMe driver on Linux before booting as well.

:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;^)  
[Reference](https://youtu.be/HU1QUSrgp4E?si=LaVtDMPm36k67m5h&t=192)22:T5e5,I came across a [Reddit post](https://old.reddit.com/r/linux/comments/1fqa36v/why_is_rm_rfing_a_folder_over_thousands_of_times/) about deleting files taking so long on
Ubuntu file explorer, Nautilus. That got me thinking. This stuff happened on my Linux 
workstation all the time. Anytime I try deleting a folder with a lot of files,
this is what happens. I still want to see if it's true so I create a little experiment
according to the post.

#### The experiment
Using this command, the machine creates 30000 empty files in a folder of my choosing,
let's call it *delete*.
```
for name in $(seq 30000); do touch text$name.txt; done
```
Then I delete that folder using *Shift+delete* for permanent delete.
Same folder will be created again, but this time being deleted using the second way.
```
rm -rf delete/
```

#### Result and conclusion
For the first way on a file explorer, it took about 22 seconds.

![](/images/blog/Tech/24/240929/pcmanqt.jpg)

The second way was much faster. Without using something like
```
time rm -rf delete/
```
you would think it's a blink of an eye.
They say this happens because the explorer spends time tracking progress, updating the UI, etc.
So maybe that's it.  
This also applies for copying, cutting too; network transfer on Samba/SMB and FTP. In fact, on my
home network, if I want to transfer multiple files fast, I usually use Filezilla instead, because despite
the inconvenience, it's faster than using a file explorer, and it's multi-connection so multi transfers.23:Tbac,I just got a new second job at my college, Oregon State U. You wouldn't believe
just how hard it was to get a job here. I not only had to compete with international
students, but also native students here for just a job, not just tech-related jobs.
Out of two dozens job I had applied, about seven are rejection letters, others I didn't
receive any replies. My first job was working at the Memorial Union as a food worker.
While I enjoyed the work, I still preferred working with machines more than humans so
always looking forward to dish room duty, ironically. But currently, I am working as a
Web Content Assistant for the Outdoor School of OSU Extension Service. I am thankful for
the opportunity working manual labor job, though. It gives me more appreciation for the
people working these types of job, and how much they have to put up with.

Now, why did I title this post **A different mindset**? Well, my job consists of moving
contents from the old web page, made in Umbraco, to the new site, made in Drupal. But I
am not allowed to touch any codes. Like, I am told to make the new contents closest to the
old ones' look under new guidelines of the new site. Knowing this made me realize what my
employer meant when they said I was overqualified for the job. So now I can't think of the
web in terms of codes, inner structures and workings of the site. Only its contents matter.
Doesn't matter if they won't match design in the end, as long as they are brought over under
new design patterns. I do my job, afterward recap all I have done back to the project manager. We will have
weekly meeting every Wednesday, same as my previous job. In fact, I was the one who brought
up the weekly meeting idea, a thing I usually did in my developer routine.

It took some time getting used to this role. It's an odd feeling. Like, I used to be the one behind
how the web looked. I was both frontend and backend. The old job's page, I was the one to make
changes directly, with the full power of programming. And now, making web with *Legos*,
buttons and clicks. You want to add button, there's a button for that. You want three columns, *button*.
I wasn't even allowed to touch *HTML mode* to align three buttons to be on the same row. I had to get creative with this limitation, and added an extra three-column row so they are aligned. I can only do this job similar
to how most people running a website would do when they aren't as proficient in programming as I am.

I could understand the reasoning behind this limited power. The design is decided by a higher power.
So it's wise not to mess with it too much. But hey, a tech job is a tech job. After so many rejections,
I'm just happy to take whatever counts as computer job. And who knows? Doing this job well, I might be
considered to be put on the Salesforce team, or become one of the developers. That is, if they still have
a slot. Working here means a foot in the door of tech employment here. One for my resume.

*Life is good.*24:Tc07,After not working for a while as a full stack developer, I got a new
job. Now I\'m about to be a web developer, again. This time, I will,
along with a team, manage a website running a content management system
(CMS), Drupal. Since I have never dealt with CMS, or PHP, before, this
is a new venture for me. In preparation for this new job, I have watched
tutorials, reinstalled Docker and many containers, done some works.
Let\'s say I\'m excited to come back to programming. I guess having a
job does push you to be more motivated.

During my preparation, my brain just wondered somewhere. I typed in
Google \".net vs javascript\" and stumbled upon a post in
[Reddit](https://www.blogger.com/). I discovered there is such a thing
as NET Minimal API, similar to the one I deployed on my server as a
music, file server over HTTP on ExpressJS a while ago. This got me
thinking a bit so I searched \"NET Minimal API\" on Google and there was
a tutorial for minimal API with .NET by
[Microsoft](https://www.blogger.com/). I was surprised.

When I was still working as a Full Stack Developer for my old place, I
**hated** their .NET Core codebase. Because at the time, I didn\'t
understand what MVC was for, and many more intricacies in the underlying
structure of their codebase. I often argued with their senior developer
about the necessity of such baggage like interface, dependency
injection. To this day, I still can\'t see the reason. Maybe because
I\'m ignorant to them, or I don\'t have the view of the bigger picture,
as most my web applications are quite small, a simple ExpressJS with a
couple of APIs should do it. That\'s why I was ecstatic when we move on
to other backend frameworks. My favorite at the time was NestJS. It was
built upon ExpressJS, so right up my alley. And since a new codebase
meant moving on from legacy baggages, no more problems from .NET Core
haunting me. Another thing I hated was I couldn\'t program the .NET
server on Linux, I could only use Windows with Visual Studio, a behemoth
IDE that ate up all of 12GB ram whenever I wanted to debug the program.
I could never find ways to debug on VS Code, better yet, create a new
.NET Web API project. Now with the discovery of .NET\'s command line,
maybe those could be done on Linux.

But that got me to reflect on myself. What if I had figured this out
sooner, would I still hate .NET as much as I did before. Maybe I would
have enjoyed the framework, because the language C\# syntax is much
better than Java. I had difficulty working with LINQ before slowly it
becoming my favorite thing when dealing with array of objects. It has
two ways of doing things: query-like SQL or method (callback). I used
the method way back then. My greatest achievement on LINQ was using that
and my then-newfound knowledge of garbage collection to create about 10
million records for a table on MySQL daily. That job used to belong to a
MySQL stored procedure, which runs for hours. My new way took 5 minutes
to run. I always wondered whether the result was correct every time it
ran but no one seemed to complain.25:Tb0e,To be honest, with all the claims from Microsoft that S Mode is supposed
to represent performance and security, it is still Windows. Still heavy,
sweating Windows that eats up 3 GB of RAM for lunch while offering less
speed than Ubuntu or Fedora, two of which only eat up half as much RAM.
But I can't deny the security aspect. Since you are only allowed to
install applications from Microsoft Store, malware is less likely to
enter your system. But the store is pretty lacking in terms of
applications that you want to use in your everyday task. The part you'll
probably hate is that you're forced to use Edge as the web browser, and
you can't switch to a different search engine except Bing. Luckily, I
got around it using Alt+Home key shortcut with Google as the homepage.
If your laptop doesn't come preinstalled with Microsoft 365, you have to
use any number of subpar office suites on the store to compensate.

You can switch out of S Mode by asking Settings for it. I tend to do
that later, so I can rip any remaining bundlewares off my laptop,
especially McAfee. For now, using S Mode is like a dare for me, to me
how far I can stand it. It's quite good so far. I got Office
preinstalled, Edge is alright, lighter than Firefox, can install
extensions from either Edge or Chrome. When I need to connect to a Linux
box, there is a ssh client called PuTTY that somebody ported to the
store. No Visual Studio Code, so I settle for Code Writer on the store
and use that Linux box to compile code for me. But my patience is
running low.

#### First time running Windows without using a Microsoft account

Note: I tried this trick on Windows S Mode. This trick DOES NOT WORK ON
S MODE, because Terminal, or Command Prompt doesn't work on S Mode.

Press Shift+F10 while in the Out-Of-Box-Experience, the interface anyone
who first starts their laptop would see. Type in *oobe\\bypassnro* and
restart the computer. Then when the setup asks for an Internet
connection, click on *I don't have Internet* option.

For S Mode: you can enter no\@thankyou.com as the username and a random
password, which causes the login to fail, allowing local account setup.

#### Some tricks in Registry Editor to improve performance

Disable Widgets, so that even with update, it will NEVER be turned on:  
*HKEY\_LOCAL\_MACHINE\\SOFTWARE\\Policies\\Microsoft\\*  
Create Dsh key. Go inside, create AllowNewsAndInterests DWORD Value,
leave it at 0.

Disable Diagnostic Data (Telemetry):  
*HKEY\_LOCAL\_MACHINE\\SOFTWARE\\Policies\\Microsoft\\Windows\\*  
Create DataCollection Key. Go inside, create AllowTelemetry DWORD Value,
leave it at 0.

Disable Web Search in Start Menu, Search bar:  
*HKEY\_LOCAL\_MACHINE\\SOFTWARE\\Policies\\Microsoft\\Windows\\*  
Create Explorer key. Go inside, create DisableSearchBoxSuggestions DWORD
Value and type 1.26:T1d70,I keep delaying this post because it's something that has already been
done, and I don't want to repeat myself. But Jeff Geerling, a Youtuber I
follow, posted a [video](https://www.youtube.com/watch?v=5NJ6V8i1Xd8)
about deploying your own VPN to access your server from a remote
location, and I feel like I must write my own experience on the matter.

#### The differences in my approach

According to Mr. Geerling, he had a public IP (though not static) and
pointed his domain to this IP to connect to his network using Wireguard
installed by PiVPN. I do not have such luxury, as my public IP is
10.x.x.x through PPPoE to my ISP, Viettel, so using his way was out of
the question. I am stuck in a situation known as CGNAT. What's more, he
exposed ALL his network out, which, to each of their own, is quite
dangerous as the VPN can be used as an attack vector to your own
network. I did a similar thing while creating my own VOIP service using
Asterisk, but it only lasted a day, and I quickly closed it due to the
danger behind it. PiVPN, the tool he used, is quite fascinating and I
will look into it in the future. But back when I built my VPN, it was on
a virtual server, and I built it manually. I didn't know any automated
tool like his, I just followed some guides from DigitalOcean to set up
Wireguard, along with fail2ban, ssh. In fact, the reason I chose
Wireguard was that it was easier to set up. OpenVPN has a lot of moving
parts needed to run, while Wireguard only requires a pair of keys.
Granted, there are
[scripts](https://github.com/angristan/openvpn-install) that help
install OpenVPN, but the performance is OpenVPN's Achilles's heel. I
only have 1 vCPU, so performance is kind of a big deal. Lastly, his
video mentioned "a little extra security on public Wifi" and "bypass
content restriction". While my VPN can't bypass any content restriction,
it can provide encryption for my traffic on public Wifi, in addition to
providing its own DNS server to speed up DNS query.

#### CGNAT (carrier-grade network address translation)

A blog [post](https://www.draytek.co.uk/information/blog/what-is-cgnat)
on Draytek explains this well, but to quote from a
[reddit](https://www.reddit.com/r/HomeNetworking/comments/hi2sde/i_just_learned_my_internet_connection_is_cgnat_is/)
comment as a short version: "CGNAT means your ISP doesn\'t have enough
public IPv4 addresses to assign one to each user. So they are
essentially doing to you what your home router does to the Internet by
giving you a NAT\'ed IP address. Yes, that means you can\'t run your own
servers or forward traffic at home". My situation may not technically be
CGNAT, could be simply double NAT from my end and my ISP's, because my
"public" IP is not in the CGNAT address block, which is usually from
100.64.0.0 to 100.127.255.255, is 10.x.x.x. I first noticed this
phenomenon in 2014, when I installed fiber. Though back then I didn't
know how to bridge the ISP router to my TP-Link router, I knew of double
NAT and opened similar port on both routers to torrent. However, I
checked on [https://canyouseeme.org/](https://canyouseeme.org/) and they couldn't see the open
port. The torrent could still download, but it couldn't upload. It was
strange, because before that, I could see the open port when I was still
on ADSL (also double NAT). It was my biggest achievement back in 8^th^
grade, to open port and torrent, or host my own radio using Windows
Media Encoder. The second biggest was getting 3D games to run on my
Pentium 4 computer.

#### Setting up virtual server

There are a lot of options when choosing a virtual server provider. I
chose Viettel IDC because it was the closest to home, and I also use
their fiber service. I bought 1 vCore with 1GB RAM, 20GB SSD, 300 Mbps
unlimited bandwidth. I chose Ubuntu Server as the base OS, because I'm
used to Debian-based OS. I guess the way to choose your preferences
works the same in other providers, whether AWS, GCP, Linode\...

Some steps I performed before setting up WIreguard:

\- Install ssh to have remote access, instead of using console from
browser. Change ssh port, only allow access with key

\- Configure firewall using
[ufw](https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-with-ufw-on-ubuntu-20-04):
Deny all incoming, allow ssh port, Wireguard port

\- Install
[fail2ban](https://www.digitalocean.com/community/tutorials/how-fail2ban-works-to-protect-services-on-a-linux-server)
to limit amount of login attempts

#### Setting up Wireguard

I followed this
[guide](https://www.digitalocean.com/community/tutorials/how-to-set-up-wireguard-on-ubuntu-20-04)
on how to set up Wireguard Server. First, I generated 2 pairs of keys,
one for the server, one for the client using the commands:

*wg genkey \| sudo tee /etc/wireguard/private.key*

*sudo cat /etc/wireguard/private.key \| wg pubkey \| sudo tee
/etc/wireguard/public.key*

Following that, I had to choose a subnet. Since 192.168.0.x, 1.x are all
too common, I chose anything from 2.x and up. After that, I went to
*/etc/wireguard/*. I created a config file for my VPN, *wg0.conf*

*\[Interface\]*

*Address = 192.168.13.1/24*

*PostUp = ufw allow 51820/udp*

*PostUp = ufw route allow in on wg0*

*PreDown = ufw delete allow 51820/udp*

*PreDown = ufw route delete allow in on wg0*

*ListenPort = 51820*

*PrivateKey = \<server private key here\>*

*\[Peer\]*

*PublicKey = \<client public key here\>*

*AllowedIPs = 192.168.13.2/32*

*\[Interface\]* is configurations for your own VPN interface, whether
it's a server or a client. *PostUp* and *PreDown* are commands to run
*after* turning on the VPN server and *before*
shutting down server, respectively. I set up a bunch of commands that
open port, allow traffic running inside VPN and vice versa when turning
off server. *\[Peer\]* are configurations for clients that will connect
to the server. Each *\[Peer\]* adds another client to the server.
*AllowedIPs* is where you type in the client's VPN IP address. If the
client also acts as a router to another subnet, for instance,
192.168.0.x, you can add *192.168.0.0/24* and you can access that subnet
from the VPN.

On my home server, not the virtual one. I also created a config file in
*/etc/wireguard/wg0.conf*:

*\[Interface\]*

*PrivateKey = \<client private key here\>*

*Address = 192.168.13.2/24*

*DNS = 8.8.8.8*

*\[Peer\]*

*PublicKey = \<server public key here\>*

*AllowedIPs = 192.168.13.0/24*

*Endpoint = \<server real IP\>:51820*

*PersistentKeepalive = 25*

*\[Peer\]* here means something different. For a client to connect to a
server, it only needs 1 peer. For *Endpoint*, you need to pinpoint the
virtual server's IP address. *PersistentKeepalive* is necessary to keep
the connection up, as we are running essentially a tunnel from the
virtual server to the real one. If the client isn't a server, that part
won't be needed.

On both servers, I typed in *wg-quick up wg0*. I pinged from each side
with the other's IP address and it worked.

![](/images/blog/Tech/24/240902-1/wireguard_8070_8878.png)

References:

\- [Jeef Geerling - Build your own private WireGuard VPN with
PiVPN](https://www.jeffgeerling.com/blog/2023/build-your-own-private-wireguard-vpn-pivpn)

\- [Information about icanhazip.com, you can use ident.me
instead](https://blog.apnic.net/2021/06/17/how-a-small-free-ip-tool-survived/)

\- [ELI5: How does NAT (Network Address Translation)
work](https://www.reddit.com/r/explainlikeimfive/comments/1wqc30/eli5_how_does_nat_network_address_translation_work/)27:T18ce,It's very nice to have something powerful in a compact form, like a
gaming laptop, when your job requires a heavy workload. But when your
job requires you constantly in a meeting, only doing spreadsheets on a
day-to-day basis, or if you are a student, sitting at lectures on end,
then a gaming laptop may not be for you because its battery life is
horrible. I mean, 3-4 hours is nice, only if you do not run any heavy
workload, or else it will drop to 1-1.5 hours. That's why I'm searching
for this *elusive* 8-hour battery laptop. I asked about it in a local
electronic retail store. They said it doesn't exist, only about 6 hours
or so. Not planning to give up, I scoured the Internet to find something
like that.

#### Low-powered solutions

I came up with some solutions:

\- A laptop with a low-powered x86 CPU: like Atom (N3350, N4000, N5000,
N4020, N5100, N6000), or m-series (m3)

\- A laptop with an ARM CPU: from MediaTek (MT8183, ...) or Qualcomm
(7c, 7c gen 2, SQx family)

Another consideration is the operating system (OS) running on the
laptop. It's more important on ARM laptops because MediaTek CPUs are
only on ChromeOS, while Qualcomm ones are available on either ChromeOS
or Windows. But using an ARM laptop is quite limited, especially on
Windows, as you are constricted by the number of applications written
for the architecture. It's quite small. While battery life on ARM
laptops is vastly superior to that of x86 laptops, it doesn't matter if
there isn't any app for them. So, I leaned towards x86 ones. And today,
I got a chance to try out a Chromebook.

This article is written using that same Chromebook, on Microsoft 365,
because I'm more used to Office than Google Docs.

#### What is Chromebook?

Chromebook, simply put, is a laptop with ChromeOS as the default OS.
Unlike most OSes, it only works when connected to the Internet, even
though Google is trying to rectify that by allowing Android apps and
Linux apps to be installed. The focus of the entire OS is the web
browser, Chrome, which powers the OS as well. With the web browser, you
can, of course, browse the web. You can also install and run web apps. A
Chromebook utilizes its own cloud solution for most tasks, like office
with Google Docs, file storage with Google Drive (there is an internal
storage with a file manager). ChromeOS was built loosely on Gentoo
Linux. I said *loosely*, because there isn't much Linux inside ChromeOS.
Most commands are removed by Google. As the purpose of this OS is for
web browsing only, it's very light, and can run on some of the weakest
hardware, say Celeron or Pentium, or cheap ARM cores. Although compared
to Linux, not lighter by much. But much lighter than Windows by 3 GB of
RAM.

![](/images/blog/Tech/23/231011/top.png)

![](/images/blog/Tech/23/231011/System_rest.png)

#### My thought on Chromebook

The one I borrowed was a [HP
Chromebook](https://www.notebookcheck.net/HP-Chromebook-13-G1-Core-m3.215846.0.html)
running [Intel Core
m3-6y30](https://ark.intel.com/content/www/us/en/ark/products/88198/intel-core-m36y30-processor-4m-cache-up-to-2-20-ghz.html)
and 4 GB of RAM. It came out in 2016-2017 so it is quite old already. So
my experience will revolve around this one.

\- Keyboard lacking some keys for text editing: Home, End, Page Up /
Down, no Function keys. Start (Super on Linux) key is gone, replaced
with Search key which replaces the Caps Lock for no reason. Why not just
replace the Start key and leave the Caps Lock alone? Those missing keys
have been replaced by shortcuts found by pressing **Ctrl+Alt+/** on the
keyboard to show off the shortcut list

\- Ran surprisingly fast on only 4GB of RAM. Could be because this
machine has the Android portion disabled by the organization I borrowed
from

\- It's quite warm on the underside when working hard because there's no
cooling fan (these low-powered chips don't usually have fans), but most
of the time it's cool

\- Battery lasted about 6-7 hours, much longer than my gaming laptop. If
running a heavy webpage, I think it could run for 2-3 hours

\- Lightweight. You can carry it with you like a tablet. But the same
can be said for Windows laptops of the same specs. But they probably run
much hotter due to being a heavier OS *compared to ChromeOS*

![](/images/blog/Tech/23/231011//IMG_20230922_115538_030.jpg)

![](/images/blog/Tech/23/231011/IMG_20230922_115555_363.jpg)

\- File manager is very basic. It's like they took the codebase of
Google Drive and used it as basis for the file manager

![](/images/blog/Tech/23/231011/filemanager.png)

\- There's a terminal but it's hidden. You can access it using
**Ctrl+Alt+T**, just like in Linux (which is funny, ChromeOS is loosely
based on Gentoo Linux). But it's quite limited in command. Type
**help\_advanced** to show off all commands available on ChromeOS

**-** Settings: When you pull the scrollbar, the menu heading doesn't
follow you, which is quite useless as the function of a heading should
be. To be fair, Windows's Settings flaw is when you return to the
previous page, it doesn't *automatically scroll you to the previous
checkpoint*. **WHY IS IT so hard for them to design a decent Settings
app??? They made it work ON ANDROID**

**-** My Chromebook is old, so its GPU doesn't support the newest
codecs. Playing Youtube videos, if I leave it to run as is, the browser
defaults to VP9 and eats up 45% CPU. So I installed h264ify to switch
codec to H264 and pull the CPU usage down.

![](/images/blog/Tech/23/231011/system_h264.png)

\- AUE: This is the biggest downside of using ChomeOS. There is an
expiry date, just like MacOS. When it hits the date, it won't receive
any more updates from Google, even the browser, as the browser is
**coupled with the OS. Yes, very WISE DECISION.** May have been
deliberate for planned obsolescence. There was news regarding
[separating the two
apart](https://chromeunboxed.com/chromeos-116-transition-lacros-chrome-browser-seamless/),
but it remains to be seen what Google is planning. Does it allow to
update the browser indefinitely, or just a few versions apart from the
OS? As for my Chromebook, the update is no more, as it is expired. Still
usable, if you don't have any concern regarding security

I will be on the lookout for any Windows laptop running this CPU or
similar and compare their performance and battery life.28:T9d3,For the longest time, I was scared of using UEFI on my PC. With the
exception of my laptops, which force me to use UEFI though I disabled
Secure Boot because it's a pain to deal with, I have been using CSM mode
(compatibility mode) that simulates BIOS. Lately with a new hard drive
to test various Linux OSes on, I've decided to reinstall Windows 10
inside the PC on UEFI mode, so on the new Linux hard drive I can install
multiple OSes without having their bootloaders stepping on each other
like in the BIOS age.

#### Howto

I learned this from [this
article](https://askubuntu.com/questions/509423/which-commands-to-convert-a-ubuntu-bios-install-to-efi-uefi-without-boot-repair)
in StackExchange. These steps apply too, I guess, Ubuntu, Fedora, Arch,
or anything using GRUB as bootloader. Tldr, we *chroot* into the root
directory *of the OS you want to convert*, run some commands and GRUB is
restored.

First, I checked to see whether the machine is on UEFI mode using this
command:

*\[ -d /sys/firmware/efi \] && echo UEFI \|\| echo BIOS*

Proceed if it says UEFI, otherwise go into the BIOS menu and change it.

Afterward, I mapped some partitions into the root directory of the OS
that is on the way to be converted (supposed that *sda1* is the OS
partition, *sda2* is the EFI system partition, */mnt* is where you want
to chroot to, could be anywhere else):

*sudo mount /dev/sda1 /mnt*

*sudo mount /dev/sda2 /mnt/boot/efi*

*sudo mount \--bind /dev /mnt/dev*

*sudo mount \--bind /proc /mnt/proc*

*sudo mount \--bind /sys /mnt/sys*

*sudo* mount *\--bind /run /mnt/run*

Later on, I loaded a module called *efivarfs* (UEFI Runtime Variables
Support) using *sudo modprobe efivarfs*. Then I went in using *sudo
chroot /mnt*.

Now, depend on the OS, say Ubuntu or Fedora, you use their respective
package manager. For my case, that was apt. So:

*apt update && apt list grub\**

Check for package *grub-efi* and *grub-efi-amd64*
(*grub-efi-amd64-signed* if Secure Boot was enabled, I didn't try it).
And then I went:

*grub-install \--target=x86\_64-efi \--efi-directory=/boot/efi
\--bootloader-id=ubuntu \--recheck \--no-floppy \--debug*

Alternatively, [this
article](https://superuser.com/questions/376470/how-to-reinstall-grub2-efi)
suggests reinstalling *grub-efi*. This is how I recover GRUB on Fedora,
since *grub-install* didn't work.

References:

\- [What exactly is the problem with
UEFI](https://www.reddit.com/r/linuxquestions/comments/63azo4/eli5_what_exactly_is_the_problem_with_uefi_and/)29:T167b,When I tried out a bunch of distros, Fedora was among the ones what
weren't like the rest. Another was EndeavourOS, based on Arch Linux. A
few things I learned while using Fedora Workstation, which was using
GNOME as its desktop environment (DE).

#### Choice of desktop environment

Of all the distros I tried, they all shared similar desktop
environments. Some can have multiple distros, each made with a different
DE:

\- GNOME: probably the most mature of all. It's fast, plenty of
animation, its design is quite professional. Except the concept is
different. It's thinking desktop in term of workspaces, so each
application gets their own desktop. There's no minimize button, no
maximize except double-clicking to do so. The Windows key (or Super key)
becomes a central key for most actions on the desktop. You use this to
switch back and forth between workspaces. GNOME takes 2^nd^ place in
terms of memory consumption, close to KDE.

\- KDE: probably the one I liked the least. While quite polished like
GNOME and Windows-like, it's a bit buggy, a bit too many customizations
in Settings so quite cumbersome to use. It's also a bit laggy and heavy,
heavier than GNOME. For Fedora cold boot, KDE desktop takes 1.5 GB RAM,
while GNOME about 1.2 GB RAM. Small different but KDE is not as fast as
GNOME.

\- Xfce: Lightweight, fast, comparable to LXQt so they both share the
same spot. I happen to like LXQt more due to being a Lubuntu user
instead of Xubuntu. The latter

\- MATE: If you enjoy the look of old GNOME from back in '09, then use
MATE. Like Xfce and LXQt, quite light on the resource.

\- Cinnamon: Linux Mint's own implementation of GNOME, Windows-like,
light, fast. One of my favorite next to LXQt.

Note that this is my opinion on these DEs as their original forms,
instead of the customized looks that can be made by other distros. See
[Xero Linux](https://xerolinux.xyz/) for KDE or
[EndeavourOS](https://endeavouros.com/) for Xfce,
[ZorinOS](https://zorin.com/) for GNOME, Xfce.

#### Display Protocol

As of the time of writing, there exists two protocols: X11 and Wayland.
[Wayland](https://dudemanguy.github.io/blog/posts/2022-06-10-wayland-xorg/wayland-xorg.html)
is still in development and supposed to supersede X11, which has existed
since [1987](https://en.wikipedia.org/wiki/X_Window_System). I tried
Wayland out in GNOME on Fedora and here are a few things I found:

\- Firefox finally utilized Nvidia GPU for video decoding through
[nvidia-vaapi-driver](https://github.com/elFarto/nvidia-vaapi-driver). I
tried numerous times on Lubuntu, which uses X11, and it didn't work. I
can finally watch 4K content on YouTube, though Iwill probably disable
AV1 playback on Firefox because my GPU doesn't support AV1 codec.

\- There's no fractional scaling on GNOME, AFAIK. There's only integer
scaling (200%, \...)

\- No custom resolution. I used that on Nvidia because they never
support my resolution 1600x900, which is supported on Windows. It's only
available on X11.

\- Performance on [Cemu](http://cemu.info/) is noticeably slower on
Wayland than on X11. This is achieved using the Vulkan backend with GTX
1060 and Ryzen 5 1600. It's also
[darker](https://www.reddit.com/r/linux_gaming/comments/142s10n/is_nvida_making_cemu_darker_on_wayland/).
The advice on Reddit was to avoid Wayland for this application due to a
missing function in Vulkan.

#### Package Management

Fedora includes GNOME software center for installing and updating apps
as well as the OS. This is way easier, more intuitive, and has more apps
than using Discover, its equivalent on my Lubuntu or KDE-based distros.

If you are a hardcore and want to use the terminal then **dnf** is the
equivalent of apt:

\- At every first run when you open the terminal, dnf caches the
repository's package list. It's quite annoying, slow (because I haven't
figured out how to change mirror but I digress). But anytime you need to
remove a package, you don't have to *autoremove* all of its dependencies
like in Ubuntu, it will do it for you.

#### Codec

Unlike other distros, Fedora doesn't include the popular video codecs
out-of-the-box: H264, H265 for instace. That puts a damper on the first
impression of anybody using Fedora. You won't be able to play any videos
using these codecs on the Video app (Totem) or Firefox without first
installing OpenH264, and you can forget about watching H265. Lucky
YouTube uses VP9, which is open-source so you can still watch it on
Firefox. Installing my usual app for watching video with Nvidia Hardware
Decoding, Celluloid, which uses
[mpv](https://www.reddit.com/r/Fedora/comments/xe0p52/psa_mpv_is_now_available_on_fedora_37/)
and
[ffmpeg](https://discussion.fedoraproject.org/t/cant-install-codecs/73797/5)
as backend, didn't play H264 using hardware decoding because the codec I
installed didn't support it, and of course no H265. VLC, however,
worked. It decoded H264, H265 normally. But that was because they used
their own ffmpeg to do it. Using Celluloid on Flatpak, which is a
container format for storing applications, I was able to play videos
using hardware decoding. Celluloid on Flatpak packages its own
dependencies, which means its own mpv and ffmpeg with support for
hardware decoding.

#### Fixing UEFI bootloader

Reinstall packages related to GRUB instead of running *grub-install
--target=x86\_64-efi* like in Ubuntu/Debian

#### Microsoft Core Fonts (Arial, Times New Roman)

This one depends on preferences, but I installed these fonts so that I
can use the docs files exported from LibreOffice Writer on Microsoft
Word. For Ubuntu/Debian, you can install the *ttf-mscorefonts-installer*
package. For Fedora, follow [this
guide](https://mscorefonts2.sourceforge.net/) to install
*msttcore-fonts*.2a:T2aec,I have just bought a couple of SSDs for cheap on Facebook. They were
taken from , I guess prebuilt computers that their owners want their
preinstalled disk drives replaced. So I plan to try out a couple of
operating systems (OS) bare metal instead of using virtual machines, so
that I can see how it feels.

#### Windows 11

This is the first one I tried out. First off, I couldn't flash its ISO
file onto the USB on Linux. I guess Windows ISO are built different. So
I used [Rufus](https://rufus.ie/en/) from Windows to flash it. The
program supports bypassing Windows 11's lousy requirements, which are
TPM (Trusted Platform Module), Secure Boot, 4GB RAM minimum. While it's
amazing that they include those in Rufus, I didn't really need it as
Windows 11 ISO I got was from undisclosed sources, they've already
scrubbed off those requirements. While installing, when you get to the
adding user screen, MAKE SURE not to connect to the Internet, if you
wish not to login your Microsoft account and create a local account.
After all installation steps, I started using Windows 11 and here is
what I found:

\- Normal cold boot of Windows 11 took about 15 seconds, compared to
Windows 10's 7 seconds. So it's slower, not a good start.

\- By default, the Start Menu is situated in the middle of the Taskbar.
That aggravated me, because for the last 30 years, Start Menu has always
been on the left of the screen. That was the standard. And now they
decided to move it for poorly justified reasons.

\- Taskbar's right click menu misses a lot of the options found in
Windows 10, especially Task Manager. Normally I hold Ctrl + Shift + Esc
to open it, but it reminds people that it exists when they right-click
on the Taskbar.

\- Settings seems to have improved a lot after Windows 10, which has a
lacking Settings app. However, it's still no substitution for Control
Panel. I found myself still using it on Windows 10 and 11.

\- Right click menu is limited because menu was shorten with only few
selections, copy, paste had turned into icons. I presumed this is for
touchscreen, but dang it I was on a desktop. I had to
[hack](https://www.theverge.com/23707964/windows-11-regedit-registry-menu-how-to)
it to restore the previous menu.

In short, I went back to Windows 10 after a day. But it's no use.
Windows 11 will eventually become the OS I **have** to use when Windows
10 is deprecated, much like Windows 7 before.

That was Windows 11 version 21H2. Things changed when I tried to give
Windows 11 one more shot with 22H2. While right click menu is still
limited, they speed up the cold boot time to about Windows 10's time.
Taskbar's right click menu finally got its Task Manager option back, and
it's been redesigned to reflect the design of Windows 11. Using Windows
11 felt a bit faster than Windows 10, especially the effects. I
discovered that the Microsoft Store allows you to download apps without
login into Microsoft account and I found Windows Subsystem for Linux and
Android. The Android one was amazing. While YouTube didn't work, I was
able to install
[SmartTubeNext](https://github.com/yuliskov/SmartTubeNext) and played
some videos on it, fully hardware-accelerated. This is different than
any emulator I have tried, which never had hardware acceleration. The
Linux one is fine. I just don't see the appeal, beside using this when
installing bare-metal or using VirtualBox is not an option. Keep in mind
that each subsystem **eats up about 2 GB of RAM**, so be mindful when
using them on anything less than **8 GB of RAM**.

![](/images/blog/Tech/23/230823-1/win11-taskmgr.png)

#### Linux Mint

I recently turned to Linux as a daily driver, after multiple incidents
of Windows 10 on my laptop threatening me that it would update itself to
Windows 11, and the button to skip it was a rather small one on the left
of the screen, and you will definitely miss it, **as** Microsoft
designed it so. I explored a couple of options in the Ubuntu ecosystem
before settling for Lubuntu:

\- Ubuntu was a bit heavy, I wanted something leaner. Besides, when I
tried to install it, I am stucked at partitioning. For whatever choice I
picked, it wouldn't let me continue.

\- Xubuntu, though as light as Lubuntu with its Xfce desktop environment
instead of LxQt, is rather metallic in color and quite bright.

Using Lubuntu for a while, I decided to look into Linux Mint. Based on
Ubuntu, but without **Snap**, which is already a plus, it's regarded
highly within the Linux community for its simplicity, ease of use. Linux
Mint has a few flavors to choose:

\- Cinnamon, the team's own take on GNOME

\- MATE (read ma-te), continuation of GNOME 2

\- Xfce

I chose Cinnamon, as that's the default of the OS. Here are my thought:

\- The design of the desktop is quite nice, due to it looking like
Windows 10 but better.

\- Their Settings app works more like the Control Panel, where it's just
a collection of tools. It takes a bit getting used to, cause I'm used to
Lubuntu.

\- Most of the apps you use are available from the start, like Firefox,
office with LibreOffice, watch movies with Celluloid (mpv with
interface). However, if you wish to install more, there's a software
manager that you can run to install more. It works like an app store for
your PC.

\- Unlike Windows 10 and 11, I can choose whether to let it auto update
or not, and update what packages. There's an app that takes care of
that, if not I can use **apt**.

With Ubuntu 24.04 slowly turning to force Snap as its app management to
all users, kinda like Windows, people including me are considering
moving shops to Linux Mint because at least they have yet to sell like
corporate sellout.

![](/images/blog/Tech/23/230823-1/cinnamon.png)

#### Elementary OS

This is another OS that is based on Ubuntu. Seems to be a running theme
for my choice of Oses. I guess because Ubuntu itself is popular and
beginner-friendly. Whenever Linux is mentioned to anybody, their first
thoughts are Ubuntu and Debian. I began my journey to download the ISO
file.

![](/images/blog/Tech/23/230823-1/elementary.jpg)

The first thing that caught my eye is that they asked you to pay for the
OS. I was planning to skip this OS when I tried typing zero into the
price and it allowed me to download again. Usually in other OSes, they
ask you before you download if you'd like to donate them some money.
This one essentially tricked you into thinking that you have to buy it.
Well, maybe there's a reason for that. I installed the OS and ran it. It
looked very good. There have been works done to make Elementary OS look
like a beautiful piece of art. Quite like macOS except I liked this way
more. That is Pantheon desktop environment, by the way. Like Linux Mint,
they use software manager called AppCenter to manage all packages. But I
had to give this OS a pass. Because when I tried installing NVIDIA
driver on and restarted my PC, the desktop environment stopped showing,
leaving the terminal behind. So there were some bugs or compatibility
problems with Pantheon. Maybe if I had an AMD GPU or using Intel CPU, I
could use it a bit longer. Shame!

#### Pop OS

Well, another derivative of Ubuntu developed by System76, a manufacture
of desktops and laptops specifically for Linux. So unlike other Linux
distributions (or distros), this OS is not community-driven but
maintained by a company, so there is a degree of responsibility to
ensure their OS work perfectly on their products, and by association our
own PCs. They use their own desktop environment, which is COSMIC, a
customized GNOME. Well, not really heavily customized. I could point out
a few similarities between them. Downloading ISO was simple enough.
There was even a specialized version for Nvidia GPU, like in my desktop.
Still, I tried the normal version and worked the way up. Unlike that
buggy Elementary OS, it actually ran after installing the GPU driver.
The distro was quite good even if I didn't spend as much time on it. I
guess the experience is the same if you've used any other distros with
GNOME desktop.

![](/images/blog/Tech/23/230823-1/Pop-OS-22.04-Desktop-beta.webp)

#### Debian

The daddy of all distros based on it. This distro is recommended only
for server because of its stability, reliability. Part of it is because
the packages on this one are old, not as up-to-date in order to be
stable. Unlike on my server which is running Debian 12 (bookworm), I've
decided to try the testing branch. And guess what, it was a bad idea.
The kernel update version 6.4 from the testing branch broke the OS. I
had to boot from an older one (5.10) to salvage it. I pulled the kernel
6.1 from Debian 12 to run on my desktop and it worked. I installed KDE
Plasma desktop environment, ran it in Wayland mode. (Wayland here is a
window system protocol, like its predecessor, X11. Its job is to render
windows and any elements onscreen). And it **ran** like a turtle, CPU
spiked to 400% on a Ryzen 5 1600 6-core. It wasn't until I installed the
Nvidia GPU driver that it got better. However, I didn't really like
KDE's look. It's a bit rugged, square, even though I could say the same
thing about Lubuntu's LXQt. But I did not like it. I know about GNOME
and KDE are vastly customizable, and I would get to those one day, for
now it's just my first impression on the desktop environment. I later
tried KDE on Fedora and also didn't like it, either. If you're
acquainted with using Ubuntu, then Debian shouldn't be any different,
since Ubuntu derived from Debian.

#### Fedora

There are so many things to say about this one that it deserves its own
article.

#### EndeavourOS

This one is based on Arch Linux. Despite what everyone said about how
hard it is to use it, there's even a meme "I use Arch, btw" meaning it's
a tough cookie to crack, I had fun with it. It's easy to use, its
package repository is packed with applications that have newest
versions. Firefox is in it instead of in a container format like Snap on
Ubuntu or exists only as *firefox-esr* like Debian. It's not insane in
avoiding proprietary components at all cost like Fedora, to the
detriment of the usability of the OS. And it's a new kid in town, not
surrounded with dramas like
[*Manjaro*](https://www.youtube.com/watch?v=oVlD17OjFAc). It's only
crime is that its package manager,
*p[acman](https://wiki.archlinux.org/title/Pacman/Rosetta)*, works a
little different than the rest.

![](/images/blog/Tech/23/230823-1/Screenshot_endeavourOS.png)

#### Zorin OS

Much like Linux Mint, it is based on Ubuntu and looks like Windows. It
comes with 2 flavors: Core in GNOME, Lite in Xfce.

![](/images/blog/Tech/23/230823-1/Zorin-OS-16.1-Core.png)
#### Xero Linux

Based on Arch Linux like EndeavourOS before it and also a new kid in
town. But while by default EndeavourOS uses Xfce, this one uses KDE
Plasma as its beautifully crafted desktop environment, with a GNOME
dashboard and a wobbly effect whenever I move the window.

![](/images/blog/Tech/23/230823-1/xerolinux.webp)2b:Tc54,After multiple times compiling drivers on multiple environments,
specifically OpenWrt, I'd decided to see if I could compile the driver
of my wifi adapter, [rtl8821cu](https://github.com/brektrou/rtl8821CU), for my
Raspberry Pi 3 from my laptop. Raspberry Pi ran on DietPi, which is
based on Debian.

#### Compile on Raspberry Pi

First, I installed *raspberrypi-kernel-header*, which is a package
containing the kernel source of Raspberry Pi. Afterwards, I ran this
command to compile the driver, it worked:

*make -j4*

I tried out this trick I learned from r8152 source compiling, but it
failed:

*make -C \<kernel source\> M=\$(pwd) -j\$(nproc)*

It didn't work when I added cross compiling parameters, either:

*make ARCH=arm64 CROSS\_COMPILE= -C \<kernel source\> M=\$(pwd)
-j\$(nproc)*

#### Compile on x86

I downloaded the [Raspberry Pi Kernel Source
Code](https://github.com/raspberrypi/linux) from Github and
installed the package gcc-aarch64-linux-gnu. I used the following line
but that didn't work:

*make -C \<kernel source\> M=\$(pwd) -j\$(nproc)*

So is the next one:

*make ARCH=arm64 CROSS\_COMPILE= -C \<kernel source\> M=\$(pwd)
-j\$(nproc)*

After reading *Makefile* in the *rtl8821cu* folder and found a line at
the *modules* part:

*\$(MAKE) ARCH=\$(ARCH) CROSS\_COMPILE=\$(CROSS\_COMPILE) -C \$(KSRC)
M=\$(shell pwd) modules*

I rechecked my command line. While **ARCH, CROSS\_COMPILE** I filled in
correctly, I should be filling in **KSRC=\<kernel source\>** instead of
**-C \<kernel source\>**. It worked afterwards:

*make ARCH=arm64 CROSS\_COMPILE=aarch64-linux-gnu-
KSRC=\~/Documents/Programming/linux-rpi-6.1.y/ -j\$(nproc)*

![](/images/blog/Tech/23/230722/make1.jpg)

However, the output told me to go to the kernel source and run *make
oldconfig && make prepare*. So I did:

*make ARCH=arm64 CROSS\_COMPILE=aarch64-linux-gnu- oldconfig && make
ARCH=arm64 CROSS\_COMPILE=aarch64-linux-gnu- prepare*

It asked a ton of questions though.

![](/images/blog/Tech/23/230722/make%20oldconfig.jpg)

About to finish, it came out with this error.

![](/images/blog/Tech/23/230722/make2.jpg)

I looked into line 2501 of Makefile of the driver, it was the *module*
part, so not the place yet. Line 1929 of Makefile of the kernel source
showed more promise.

![](/images/blog/Tech/23/230722/make3.jpg)

I looked into *Makefile.modfinal*. It's like the file and the error are
both looking for *module.lds* but it's not available in the kernel
source. Temporarily, I copied *module.lds.S* to *module.lds.* It did
compile, but it didn't work on Raspberry Pi, likely because of kernel
6.1.21 currently on Pi, compared to kernel source 6.1.35.

#### What happened if you missed ARCH and CROSS\_COMPILE?

Missing **ARCH** came out with this error.

![](/images/blog/Tech/23/230722/missing%20arch.jpg)

Missing **CROSS\_COMPILE** came out with this error.

![](/images/blog/Tech/23/230722/missing%20cross%20compile.jpg)
**Conclusion**

So I guess for now I just compile the driver against the source on the
device then. Until I get the hang of cross-compiling.

References:

\- [](https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1906131)2c:Tce2,I have recently become a permanent resident of the Linux land. I live in
Lubuntu town. That's a funny way to say that I use Lubuntu as my daily
driver on my laptop. On my laptop, which is an Intel i7 9750H + GTX 1060
combo, it's been kind to me and given me my preferred screen resolution,
which was 1600x900 out of the box. That wasn't the case for my desktop,
which is an AMD Ryzen 5 1600 + GTX 1060 combo, as it gave me its default
resolution of 1920x1080. There's nothing wrong with it, other than the
letters appear like tiny dots on screen. When I opened the Monitor
Settings, it didn't give me 1600x900, instead there were 1920x0180,
1680x1050, 1600x1200. Nvidia Settings certainly didn't help, it didn't
have 1600x900, either. So I had my work cut out for me.

![](/images/blog/Tech/23/230721/nvidia.jpg)

#### Finding answers in vain

I first tried out [this
method](https://itslinuxfoss.com/set-custom-resolution-using-xrandr/)
to set a custom resolution. However, it returned this error and wouldn't
allow me to add that resolution:

*X Error of failed request: BadMatch (invalid parameter attributes)*

*Major opcode of failed request: 140 (RANDR)*

*Minor opcode of failed request: 18 (RRAddOutputMode)*

I searched everywhere for a solution to no avail. That means, while
there are answers, none satisfies what I'm looking for.. So I tried the
next method, setting it on Nvidia's side using Nvidia Settings.
According to [this
post](https://bbs.archlinux.org/viewtopic.php?id=255287),
*you want to do this by setting your ViewPortIn to your desired
resolution, and your Panning to the desired resolution as well. Do NOT
touch ViewPortOut*.

![](/images/blog/Tech/23/230721/lxqt-config-monitor.jpg)

I applied it and saved the settings to X File. However it won't write
the X File **xorg.conf** down to */etc/X11/* so I have to issue a
command [*sudo chmod u+x
/usr/share/screen-resolution-extra/nvidia-polkit*](https://forums.developer.nvidia.com/t/cant-save-to-x-configuration-file-on-nvidia-settings/185069)
to make it work. After I'd done that, I logged out and back in.
Interestingly, the login screen showed that the custom resolution
worked, but as soon as I logged in*,* the screen *turned back to
1920x1080* and Nvidia reported my screen resolution as Auto.

#### Stumbled upon the solution

At that point, I was stump. Like what do I do now? I kept trying back
and forth between two ways for hours. Nothing works. Until something
amazing happened. I read somewhere that after saving the settings on the
Nvidia's side, I should change the monitor settings from the OS side, so
I switched it to 1680x1050, logged out, logged back in. And voila. It
finally clicked. I can't believe it. So I guess that's how it's done.

According to the [official
guide](https://forums.developer.nvidia.com/t/persist-nvidia-x-server-settings/158102/5),
the desktop environment, in this case LXQt, may have overridden any
configuration from nvidia-settings, hence why Lubuntu switched to
1920x1080 after its login screen was 1600x900. The way I pulled it off
seems like a hack, because it is. I'm supposed to either change
resolution from the monitor settings within Lubuntu or disable any
feature for managing displays. But hey, as long as it works.

![](/images/blog/Tech/23/230721/it_work.png)2d:T1620,If you have to do research on cell phones like I do, you'll eventually
find that any phone can have multiple models existing in the wild. For
each market, say Asia, Japan, the US, China\... they released a
different model. Most of the times, it supported different **frequency
bands**, because some country like the US, Korea,\... have **cell phone
standard** that separated them from the rest of the world. Other times,
it was a model exclusive to a network, a company, an event. Today, I
wanted to tell a couple of stories involving phone models catering to
different frequency bands.

#### Oneplus One: Holy grail of phone design, price-performance ratio, practically useless as a phone

This was back in 2014. I just finished my university entrance test and
got into a major university in my city. So I was given fairly big budget
to purchase my favorite thing. I chose to buy a smartphone. I was the
first of my family to get a smartphone. However, this was for my
*second* one. The first one I bought beforehand was a [Nokia
Lumia 820](https://www.gsmarena.com/nokia_lumia_820-4968.php). It was a
Windows Phone, because my friend convinced me to the platform. It was
nice and fast, but also lacking in applications. The phone in question,
Oneplus One, was pushed heavily in online marketing. There was an event
back then which you typed in your email on their website and prayed to
the lucky star to get an *invite* to buy their phone
internationally. SO of course I didn't win.

![](/images/blog/Tech/23/230707/OnePlus-Never-Settle.jpg)

I later found a model that was selling at a nearby store. Costed about
the same as the one on their website, which was \$350. To put it into
perspective, a phone with a similar performance to Oneplus One was
double the price. So you can see the value Oneplus offered. Anyway, I
bought the phone. I inserted my SIM card in, not connected. I tried
multiple times, including restarting the phone, switch on and off
*Airplane Mode*, change *Select Network* to *Manual*. I found out later
that **maybe** the model I bought was a Chinese one, not an
international one, so the frequency bands might be different. Figured,
since there was only a limited number of the latter in the world due to
that event. I searched for ways to fix this. ROM hacks, firmware
updates, modem fix, \... many ways. I tried them all. This was during
the era when custom ROMs, which were customized Android OSes, reigned
supreme, and was a way to boost a phone's performance because of early
2010s' lackluster specs on smartphones. Nowadays, it's becoming harder
since phones have become cheaper, more capable, and more secure. Forums
like [XDA-Developers](https://forum.xda-developers.com/) were where I
frequented to find ways to fix the phone. At one point, I even stuck a
paperclip in to try to fix the SIM card slot. Hilariously, the phone
store couldn't fix it. So I had to fix it by slowly pulling it out. I
successfully pulled it, but the phone still didn't work on my network.
So I was stuck with a Lumia and a 5.5-inch tablet. But at least it had a
Snapdragon 801, a beast of an ARM CPU at the time. At least until I
later changed to Coolpad Note 3 Lite after I broke my Lumia 820. FYI,
the Coolpad phone was horrible and slow.

Sometime later, I pulled the Oneplus One out for my sister after
retiring it long ago, gave it an update to Android 6 and **then** it can
accept my SIM card, albeit only 3G was possible.

**Oneplus Nord CE 2 Lite: How not paying attention to About Phone can
cost you big time**

Just last June, 2023. I planned to buy this phone in anticipation for my
travel to the US. I needed a phone that could use the US cellular
network without buying from the US, because I thought it would be
expensive. I checked the specs of the phone online, cross-compare to
other phones of the brand. I was looking for headphone jack and
dual-SIM, because I hate this trend of removing what should already be
possible on thin phones. I checked out 8 Pro, 7 Pro, Nord N20 and found
this one fit, and somebody resold this used one for about 3.2 million
VND. So I took the chance and bought it. After a few hours, I innocently
searched for the model, CPH2381, seems that there were 2 models of this
phone. And I was hit with results from Amazon India and Indian phone
stores. While the other model, CPH2409, was the international one.

![](/images/blog/Tech/23/230707/cph2381.jpg)

![](/images/blog/Tech/23/230707/cph2409.jpg)

Then something clicked. On the page they advertised this used phone,
there was an image of the phone's About Phone page that said *model
CPH2381*. So because of **one little mistake***,* I took home a phone
that will most likely be useless in the US, because it didn't support
enough frequency bands from the US. And I can't take the phone back,
because technically it still works here in Vietnam. So no dice. I ended
up once again, gave this one to my sister so she could replace her aging
Samsung Galaxy A7. There goes my birthday present.

![](/images/blog/Tech/23/230707/OnePlus-Nord-CE-2-Lite-5G_FoneArena-11-1024x691.jpg)

#### What we can take away for these stories

\- Probably pay more attention to the model if you are looking for a
specific phone, since it's so rare and hard to find.

\- Just to go the country you plan to go and buy the phone from there.
Because now I have to pay double for a phone in the US, half for the
Oneplus CE 2 Lite, half for whatever I will buy in the US to use.

References:

\- [Oneplus One
Specifications](https://www.gsmarena.com/oneplus_one-6327.php)

\- [OnePlus Nord CE 2 Lite 5G
Specifications](https://www.gsmarena.com/oneplus_nord_ce_2_lite_5g-11344.php)2e:T2899,I wrote a post on compiling OpenWrt from source a few months ago. Since
then, I've been playing around with its source, building new images with
it to test on virtual machines. OpenWrt finally added [support for
Orange Pi R1 Plus (LTS)](https://github.com/openwrt/openwrt/pull/12818) for
their next release, 23.05. And with a new driver for RTL8153, a chipset
used in the board, I decided to go back to patching OpenWrt one more
time.

#### Kernel patch

As shown from my previous post on OpenWrt for Orange Pi R1 Plus, kernel
patches are how they affect the kernel to their preferences for running
OpenWrt, like allowing unsupported devices to run the OS. The Linux
kernel source has upstreamed dts for R1 Plus on v6.3 and LTS on v6.4,
and now is *backported* to kernel 5.15 for OpenWrt 23.05 using kernel
patches. Patches are created using either *diff* or *git diff*.

#### How to create diff

It's actually quite easy. Just follow this command:

*diff -rupN \<source\> \<target\> \> \<output\>*

With:

\- r to compare with subdirectories, subfolders

\- u outputs NUM (default 3) lines of unified context (yeah I don't get
it)

\- p shows which C function each change is in

\- N treats absent files as empty

Or:

*git diff \<source\> \<target\> \> \<output\>*

#### Patch new driver into the kernel

I first tried using */dev/null* as source to diff against *r8152.c* file
from Realtek, and then put it in as patch. I deleted a patch related to
*r8152.c* so it remained original to kernel source. I put the patch in
*target/linux/generic/hack-5.15*, same as where I deleted the previous
patch. But replacing the kernel driver wasn't easy, I tried

*\-\-- a/drivers/net/usb/r8152.c*

*+++ /dev/null*

*\-\-- /dev/null*

*+++ b/drivers/net/usb/r8152.c*

or

*\-\-- /dev/null*

*+++ b/drivers/net/usb/r8152.c*

The source didn't compile due to the file already existing in the
kernel.

So I did the hard way. I went into *dl* folder, extract *r8152.c* from
*linux-5.15.117.tar.xz* (at the time OpenWrt was built on kernel
5.15.117) then diff against the same file from Realtek. It compiled
successfully. I could run it well on a virtual machine.

![](/images/blog/Tech/23/230623/patch_2.jpg)

Apparently, the compiler doesn't read anything above the first change in
the patch. So the lines before that is considered comments to the
compiler. I added a note to say that this driver is not from the kernel
source.

#### Patch new driver into ImmortalWrt

I also used ImmortalWrt 21.02 for testing their software offloading
*TurboACC*. Originally, ImmortalWrt wouldn't compile with the original
source because of lack of 'libcap'. I found out that the library existed
in 22.03 of OpenWrt, not in 21.02 which was the base for ImmortalWrt. So
I copied it from OpenWrt at *package/libs/libcap* and took it to
ImmortalWrt. It compiled.

#### Test RTL8153 using OpenWrt

I tested it using my device and iperf3. The LAN port contains RTL8153
chipset and I tested it half-duplex, 1 download 1 upload separately.
Download from my laptop to the LAN port got me **940 Mbps**, which was
max bandwidth for **1 Gbps** Ethernet:

*\[ ID\] Interval Transfer Bitrate Retr Cwnd*

*\[ 5\] 0.00-1.00 sec 113 MBytes 950 Mbits/sec 0 708 KBytes*

*\[ 5\] 1.00-2.00 sec 111 MBytes 933 Mbits/sec 0 758 KBytes*

*\[ 5\] 2.00-3.00 sec 112 MBytes 944 Mbits/sec 0 799 KBytes*

*\[ 5\] 3.00-4.00 sec 111 MBytes 933 Mbits/sec 0 841 KBytes*

*\[ 5\] 4.00-5.00 sec 111 MBytes 933 Mbits/sec 0 901 KBytes*

*- - - - - - - - - - - - - - - - - - - - - - - - -*

*\[ ID\] Interval Transfer Bitrate Retr*

*\[ 5\] 0.00-5.00 sec 559 MBytes 939 Mbits/sec 0 sender*

*\[ 5\] 0.00-5.00 sec 557 MBytes 934 Mbits/sec receiver*

Upload on original driver reached only **630 Mbps**:

*\[ ID\] Interval Transfer Bitrate*

*\[ 5\] 0.00-1.00 sec 70.1 MBytes 588 Mbits/sec*

*\[ 5\] 1.00-2.00 sec 74.6 MBytes 626 Mbits/sec*

*\[ 5\] 2.00-3.00 sec 75.2 MBytes 631 Mbits/sec*

*\[ 5\] 3.00-4.00 sec 75.4 MBytes 632 Mbits/sec*

*\[ 5\] 4.00-5.00 sec 74.7 MBytes 627 Mbits/sec*

*- - - - - - - - - - - - - - - - - - - - - - - - -*

*\[ ID\] Interval Transfer Bitrate Retr*

*\[ 5\] 0.00-5.00 sec 371 MBytes 622 Mbits/sec 0 sender*

*\[ 5\] 0.00-5.00 sec 370 MBytes 621 Mbits/sec receiver*

Upload after patch reached **880 Mbps**:

*\[ ID\] Interval Transfer Bitrate*

*\[ 5\] 0.00-1.00 sec 97.8 MBytes 821 Mbits/sec*

*\[ 5\] 1.00-2.00 sec 107 MBytes 894 Mbits/sec*

*\[ 5\] 2.00-3.00 sec 107 MBytes 896 Mbits/sec*

*\[ 5\] 3.00-4.00 sec 103 MBytes 861 Mbits/sec*

*\[ 5\] 4.00-5.00 sec 106 MBytes 885 Mbits/sec*

*- - - - - - - - - - - - - - - - - - - - - - - - -*

*\[ ID\] Interval Transfer Bitrate Retr*

*\[ 5\] 0.00-5.00 sec 522 MBytes 876 Mbits/sec 0 sender*

*\[ 5\] 0.00-5.00 sec 519 MBytes 871 Mbits/sec receiver*

#### Test RTL8153 using ImmortalWrt

I also tested the RTL8153 chipset with ImmortalWrt 21.02 original
driver. It got me **940 Mbps** download:

*\[ ID\] Interval Transfer Bitrate Retr Cwnd*

*\[ 5\] 0.00-1.00 sec 113 MBytes 948 Mbits/sec 0 396 KBytes*

*\[ 5\] 1.00-2.00 sec 112 MBytes 941 Mbits/sec 0 396 KBytes*

*\[ 5\] 2.00-3.00 sec 111 MBytes 932 Mbits/sec 0 563 KBytes*

*\[ 5\] 3.00-4.00 sec 112 MBytes 940 Mbits/sec 0 563 KBytes*

*\[ 5\] 4.00-5.00 sec 112 MBytes 938 Mbits/sec 0 563 KBytes*

*- - - - - - - - - - - - - - - - - - - - - - - - -*

*\[ ID\] Interval Transfer Bitrate Retr*

*\[ 5\] 0.00-5.00 sec 560 MBytes 940 Mbits/sec 0 sender*

*\[ 5\] 0.00-5.00 sec 558 MBytes 935 Mbits/sec receiver*

and **720 Mbps** upload:

*\[ ID\] Interval Transfer Bitrate*

*\[ 5\] 0.00-1.00 sec 84.5 MBytes 709 Mbits/sec*

*\[ 5\] 1.00-2.00 sec 87.5 MBytes 734 Mbits/sec*

*\[ 5\] 2.00-3.00 sec 86.5 MBytes 726 Mbits/sec*

*\[ 5\] 3.00-4.00 sec 85.5 MBytes 717 Mbits/sec*

*\[ 5\] 4.00-5.00 sec 86.9 MBytes 729 Mbits/sec*

*- - - - - - - - - - - - - - - - - - - - - - - - -*

*\[ ID\] Interval Transfer Bitrate Retr*

*\[ 5\] 0.00-5.00 sec 433 MBytes 726 Mbits/sec 0 sender*

*\[ 5\] 0.00-5.00 sec 431 MBytes 723 Mbits/sec receiver*

I tested RTL8153 again after patch with iperf3 upload. It got **870
Mbps**:

*\[ ID\] Interval Transfer Bitrate*

*\[ 5\] 0.00-1.00 sec 103 MBytes 862 Mbits/sec*

*\[ 5\] 1.00-2.00 sec 103 MBytes 867 Mbits/sec*

*\[ 5\] 2.00-3.00 sec 103 MBytes 862 Mbits/sec*

*\[ 5\] 3.00-4.00 sec 104 MBytes 870 Mbits/sec*

*\[ 5\] 4.00-5.00 sec 105 MBytes 879 Mbits/sec*

*- - - - - - - - - - - - - - - - - - - - - - - - -*

*\[ ID\] Interval Transfer Bitrate Retr*

*\[ 5\] 0.00-5.00 sec 521 MBytes 874 Mbits/sec 0 sender*

*\[ 5\] 0.00-5.00 sec 517 MBytes 868 Mbits/sec receiver*

#### Test YT8531c using OpenWrt and ImmortalWrt

I couldn't test the WAN port with YT8531c chipset. I couldn't get IP
address on my laptop, despite setting the WAN port to have the same
settings as the LAN port for DHCP. I did try in vain to patch it using
dts patch of the R1 Plus LTS board. As you can see, they had updated
Mootorcomm driver and the device tree source with new values like
clk-out-frequency-hz, keep-pll-enabled, auto-sleep-disabled. Maybe there
is something wrong with the driver, because this also happened on
ImmortalWrt 23.05. Using
[Armbian](https://github.com/armbian/community), however,
I could use the WAN port normally.

![](/images/blog/Tech/23/230623/patch_2305_not_possible_dts.jpg)

![](/images/blog/Tech/23/230623/patch_2305_not_possible_8531.jpg)

So in the end, OpenWrt 23.05 **shouldn't be used** just yet.

I rolled back to OpenWrt 22.03. I tested the WAN port with iperf3 again.

Download **940 Mbps**:

*\[ ID\] Interval Transfer Bitrate Retr Cwnd*

*\[ 5\] 0.00-1.00 sec 113 MBytes 948 Mbits/sec 0 551 KBytes*

*\[ 5\] 1.00-2.00 sec 113 MBytes 945 Mbits/sec 0 551 KBytes*

*\[ 5\] 2.00-3.00 sec 111 MBytes 932 Mbits/sec 0 551 KBytes*

*\[ 5\] 3.00-4.00 sec 112 MBytes 943 Mbits/sec 0 551 KBytes*

*\[ 5\] 4.00-5.00 sec 112 MBytes 937 Mbits/sec 0 551 KBytes*

*- - - - - - - - - - - - - - - - - - - - - - - - -*

*\[ ID\] Interval Transfer Bitrate Retr*

*\[ 5\] 0.00-5.00 sec 561 MBytes 941 Mbits/sec 0 sender*

*\[ 5\] 0.00-5.01 sec 559 MBytes 935 Mbits/sec receiver*

Upload **930 Mbps**:

*\[ ID\] Interval Transfer Bitrate*

*\[ 5\] 0.00-1.00 sec 105 MBytes 881 Mbits/sec*

*\[ 5\] 1.00-2.00 sec 111 MBytes 931 Mbits/sec*

*\[ 5\] 2.00-3.00 sec 111 MBytes 931 Mbits/sec*

*\[ 5\] 3.00-4.00 sec 111 MBytes 934 Mbits/sec*

*\[ 5\] 4.00-5.00 sec 112 MBytes 937 Mbits/sec*

*- - - - - - - - - - - - - - - - - - - - - - - - -*

*\[ ID\] Interval Transfer Bitrate Retr*

*\[ 5\] 0.00-5.00 sec 552 MBytes 925 Mbits/sec 0 sender*

*\[ 5\] 0.00-5.00 sec 550 MBytes 923 Mbits/sec receiver*

ImmortalWrt 21.02 gave out similar results.

#### Note about offloading

These tests have been performed *with and without [software
offloading]*. Doesn't seem like it does anything. Whether
OpenWrt or *TurboACC* from ImmortalWrt. Packet steering also doesn't
work, either.

#### Reason for better performance on ImmortalWrt compared to OpenWrt

As you can see when using RTL8153 original driver, OpenWrt only reached
**630 Mbps** while ImmortalWrt got **720 Mbps** in iperf3 upload is
because, ImmortalWrt overclocked the processor, Rockchip RK3328, from
stock 1.3 Ghz to **1.6 Ghz**. ImmortalWrt has a patch where they add
clock frequencies to the [operating performance point (OPP)
table](https://www.kernel.org/doc/Documentation/power/opp.txt).
ImmortalWrt was running RK3328 at 1.6 Ghz max.

*\-\-- a/arch/arm64/boot/dts/rockchip/rk3328.dtsi*

*+++ b/arch/arm64/boot/dts/rockchip/rk3328.dtsi*

*@@ -140,6 +140,21 @@*

*opp-microvolt = \<1300000\>;*

*clock-latency-ns = \<40000\>;*

*\};*

*+ opp-1392000000 \{*

*+ opp-hz = /bits/ 64 \<1392000000\>;*

*+ opp-microvolt = \<1350000\>;*

*+ clock-latency-ns = \<40000\>;*

*+ \};*

*+ opp-1512000000 \{*

*+ opp-hz = /bits/ 64 \<1512000000\>;*

*+ opp-microvolt = \<1450000\>;*

*+ clock-latency-ns = \<40000\>;*

*+ \};*

*+ opp-1608000000 \{*

*+ opp-hz = /bits/ 64 \<1608000000\>;*

*+ opp-microvolt = \<1450000\>;*

*+ clock-latency-ns = \<40000\>;*

*+ };*

*\};*

*amba \{*

References:

\- [Kernel Patch](https://www.kernel.org/doc/html/v4.18/process/applying-patches.html)

\- [RTL8153 linux driver](https://www.realtek.com/en/component/zoo/category/network-interface-controllers-10-100-1000m-gigabit-ethernet-usb-3-0-software)

\- [OpenWrt 23.05 RTL8153 patch](https://github.com/bachsofttrick/openwrt/commits/openwrt-23.05)2f:T1820,In celebration of the release of [Debian
12](https://www.debian.org/News/2023/20230610), I downloaded and tried
it out on a VM (virtual machine). Unfortunately, my [network
driver](https://www.realtek.com/en/component/zoo/category/network-interface-controllers-10-100-1000m-gigabit-ethernet-usb-3-0-software)
won't compile under Linux kernel version 6.1. I thought they were just
kidding when they said kernel version \<= 5.17. So I held off upgrading
my server to Debian 12. A short while back, I read this
[post](https://jamesachambers.com/orange-pi-i96-getting-started-guide/)
about getting i96 board from Orange Pi to work. That got me thinking.
[Are kernel and OS
separated?](https://askubuntu.com/questions/913351/why-are-the-operating-system-and-kernel-treated-separately-in-linux)
The board in question could run Debian 11 Bullseye on kernel 3.10, which
was very old.

#### Debian 10

Because I couldn't find the ISO for Debian 11 that is currently on my
server to replicate the server environment on a VM, I used Debian 10
ISO. Lucky enough! It came with kernel 4.19. While installing, I tried
using a mirror server from Vietnam to speed up downloading packages. It
worked! So good that I changed mirrors on my server, my laptop OS to
Vietnam to. As previously, I downloaded packages from the sources, which
are from the US so they were slow.

I upgraded [Debian 10 to
11](https://www.cyberciti.biz/faq/update-upgrade-debian-10-to-debian-11-bullseye/)
by changing all instances of *buster* in */etc/apt/source.list* to
*bullseye* and use *apt full-upgrade*. Debian 11 gave me kernel 5.10,
same as my server. I added the
[*backport*](https://wiki.debian.org/Backports) repository to the apt
source list, because they have new softwares and kernels there:

*deb http://debian.xtdv.net/debian/ bullseye-backports main*

Next, I searched for a new kernel by filtering apt list:

*apt list linux-image\* \| less*

It came up with tons of results so it could get confusing. Fortunately,
the kernel the OS used probably looks like *linux-image-5.10.0-23-amd64*
so using this, I could track down the kernel I need, like
*linux-image-6.1.0-0.deb11.7-amd64*. I did try one with *cloud* in it,
and it shrunk the font on screen. After installing, it would generate a
new config file for the boot loader, GRUB. The next restart, it will
*reboot to the new kernel*. And it did. Here was the result
of *uname -a*:

*Linux debian 6.1.0-0.deb11.7-amd64 \#1 SMP PREEMPT\_DYNAMIC Debian
6.1.20-2\~bpo11+1 (2023-04-23) x86\_64 GNU/Linux*

* *

I also tried upgrading to Debian 12 while *holding* the
*linux-image-amd64* from upgrading, to see if it was possible to get to
Debian 12 without using kernel 6.1. It also worked.

#### Lubuntu 22.04

I replicated the experiment on a fresh Lubuntu 22.04.2 VM. It was a bit
different. The package I was looking for was
*linux-image-5.15.0-73-generic*. The newest kernel they got was
*linux-image-5.19.0-43-generic* so I tried *linux-image-6.1.0-1013-oem*.
It booted back in after installing and restarting the VM.

#### Compiling driver

Back to Debian 11 with kernel 6.1, I tried compiling driver again after
installing *linux-headers-6.1.0-0.deb11.7-amd64*. It didn't work and it
gave errors:

*/home/bach/r8152-2.16.3/r8152.c: In function 'sg\_en\_store':*

*/home/bach/r8152-2.16.3/r8152.c:20462:2: error: implicit declaration of
function 'netif\_set\_gso\_max\_size'; did you mean
'netif\_set\_tso\_max\_size'? \[-Werror=implicit-function-declaration\]*

*20462 \| netif\_set\_gso\_max\_size(netdev, tso\_size);*

*\| \^\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~*

*\| netif\_set\_tso\_max\_size*

*/home/bach/r8152-2.16.3/r8152.c: In function 'rtl8152\_probe':*

*/home/bach/r8152-2.16.3/r8152.c:20704:3: error: too many arguments to
function 'netif\_napi\_add'*

*20704 \| netif\_napi\_add(netdev, &tp-\>napi, r8152\_poll, 256);*

*\| \^\~\~\~\~\~\~\~\~\~\~\~\~\~*

*In file included from /home/bach/r8152-2.16.3/r8152.c:16:*

*/usr/src/linux-headers-6.1.0-0.deb11.7-common/include/linux/netdevice.h:2569:1:
note: declared here*

*2569 \| netif\_napi\_add(struct net\_device \*dev, struct napi\_struct
\*napi,*

*\| \^\~\~\~\~\~\~\~\~\~\~\~\~\~*

*/home/bach/r8152-2.16.3/r8152.c:20706:3: error: too many arguments to
function 'netif\_napi\_add'*

*20706 \| netif\_napi\_add(netdev, &tp-\>napi, r8152\_poll, 64);*

*\| \^\~\~\~\~\~\~\~\~\~\~\~\~\~*

*In file included from /home/bach/r8152-2.16.3/r8152.c:16:*

*/usr/src/linux-headers-6.1.0-0.deb11.7-common/include/linux/netdevice.h:2569:1:
note: declared here*

*2569 \| netif\_napi\_add(struct net\_device \*dev, struct napi\_struct
\*napi,*

*\| \^\~\~\~\~\~\~\~\~\~\~\~\~\~*

*cc1: some warnings being treated as errors*

For the first error, I changed the function according to the tip. For
the following errors, I consulted the wisdom of the Internet and found
this
[patch](https://lore.kernel.org/netdev/20221002175650.1491124-1-kuba@kernel.org/t/),
so I changed the function again. I recompiled again and it got through.
Using *modinfo r8152.ko* yielded result that it was compiled using
kernel 6.1:

*vermagic: 6.1.0-0.deb11.7-amd64 SMP preempt mod\_unload modversions*

#### Compiling driver (new version 2.17.1)

After the release of Debian 12, Realtek issued an update on their
RTL8156 source driver. I downloaded it and compiled against kernel
version 6.1 and installed it. It worked, without any errors from the old
version. There was also a driver already in the kernel so I tested both
drivers. The in-tree kernel module required firmwares to be installed,
you can find it in *firmware-realtek* package in *bullseye-backports*
repository. However, Debian didn\'t recognize the network USB, so I have
to force driver by hand using this command as root (not sudo, it didn\'t
work):

*echo 0bda 8156 \> /sys/bus/usb/drivers/r8152/new\_id*

Then it recognized the USB. By using **iperf3**, I measured performance
between 2 drivers. While they were able to saturate the 1Gbps bandwidth,
the in-tree module took 10% more CPU usage compared to the Realtek
driver. The in-tree module also required a hacky workaround for the
server to recognize, so I opted for the Realtek one.30:Tbbc,After writing blogs for over a month, I checked to see if my blog showed
up on Google Search. And\... Nothing. So what? Why? How? Why doesn't my
blog exist in Google's eyes? So I asked a friend, he asked if I had put
my page on the search console. I wondered what that is. Turns out to be
the Google Search Console.

I went to [https://search.google.com/search-console](https://search.google.com/search-console). It showed me this
dialog.

![](/images/blog/Tech/23/230610/domain.jpg)

I was supposed to provide the console with the domain I wanted to put on
the map, so I typed in this blog's domain in *Domain*. After that, it
led me to the dashboard.

![](/images/blog/Tech/23/230610/overview.jpg)

I thought that was it and left it there. The following day, I opened up,
and it was still nothing, staring at me like suggesting that I do
something. Searching around, they said I need to put in my sitemap so
that Google has something to crawl and indexes pages to their search
engine. I didn't know what sitemap was. I found a [sitemap
generator](https://www.labnol.org/blogger/sitemap/) and it
gave me this answer.

*\# Blogger Sitemap created on Thu, 27 Apr 2023 12:15:06 GMT*

*\# Sitemap built with https://www.labnol.org/blogger/sitemap*

*User-agent: \**

*Disallow: /search*

*Allow: /*

*Sitemap:
https://testingguy96.blogspot.com/atom.xml?redirect=false&start-index=1&max-results=500*

![](/images/blog/Tech/23/230610/blogger_sitemap.jpg)

I could put this in my blog settings, under *Enable custom robots.txt*.
But I put the xml sitemap in *Sitemap* as
[https://testingguy96.blogspot.com/atom.xml](https://testingguy96.blogspot.com/atom.xml).
This
[article](https://www.searchenginejournal.com/google-recommends-using-xml-sitemaps-rssatom-feeds-optimal-crawling/118364/)
told me to also include xml sitemap, as the last one was an Atom one. It
was *sitemap.xml*.

![](/images/blog/Tech/23/230610/sitemaps.jpg)

Not wanting to wait for indexing, I decided to take matters into my own
hands. I gathered all my post URLs, put each of them to the search bar
on top, and requested index manually.

![](/images/blog/Tech/23/230610/url_inspect.jpg)

After about 3 days, I checked and my blog and its accompanying posts
started showing up. Mission successful! I also learned later that I need
to
[ping](https://developers.google.com/search/docs/crawling-indexing/sitemaps/build-sitemap)
Google to submit sitemap *again* for it to update my sitemap to get new
posts, and request indexing for new posts if I want updates right then.

![](/images/blog/Tech/23/230610/google_search_result_2.jpg)

References:

\- [Blogger blog not getting indexed (More than 10 days already passed
after
creating)](https://support.google.com/webmasters/thread/74316675/blogger-blog-not-getting-indexed-more-than-10-days-already-passed-after-creating?hl=en)

\- [Search Console - Best practices for XML sitemaps and RSS/Atom
feeds](https://developers.google.com/search/blog/2014/10/best-practices-for-xml-sitemaps-rssatom)31:T8d2,I know that Snap earned a bad reputation among Linux folks due on it
being closed-source by Canonical, which developed the open-source Ubuntu
Linux. I haven't used Linux for long, but I have to agree with the
general consensus. Snap on my system, while generally doesn't degrade
performance much, basically acts like Windows 10, auto update anytime it
wants, regardless of my opinion. Its daemon, snapd, **does** degrade
performance when updating apps. When using my Ubuntu virtual server, I
uninstalled snapd, because all of my apps can be obtained from apt or
docker. On the other hand, I was hesitant to remove snapd, along with
Firefox, because I was afraid it would mess up something to my daily
driver, Lubuntu. But it had to be done

#### Howto (by [source](https://askubuntu.com/questions/1399383/how-to-install-firefox-as-a-traditional-deb-package-without-snap-in-ubuntu-22))

You might want to backup the OS first before committing to this. So I
used
[Clonezilla](https://clonezilla.org/downloads/download.php?branch=stable)
to back up the OS. You can use whatever.

Back at Lubuntu, I backed up my Firefox profile by going to
*about:profiles*, look at the default profile, click *Open Directory* on
*Root Directory*. Copy its content to another folder outside.

Next, I added Mozilla's repo using terminal:

*sudo add-apt-repository ppa:mozillateam/ppa*

I uninstalled Firefox from Snap using:

*snap remove firefox*

I then created 2 new files at 2 locations, 1 is for prioritizing the apt
Firefox over snap Firefox, 1 is for preventing snap Firefox from coming
back, respectively:

\- /etc/apt/preferences.d/mozilla-firefox

*Package: \**

*Pin: release o=LP-PPA-mozillateam*

*Pin-Priority: 1001*

*Package: firefox*

*Pin: version 1:1snap1-0ubuntu2*

*Pin-Priority: -1*

\- /etc/apt/apt.conf.d/51unattended-upgrades-firefox

*Unattended-Upgrade::Allowed-Origins::
\"LP-PPA-mozillateam:\$\{distro\_codename\}\";*

After that, I uninstalled snapd, which Lubuntu prompted me to reinstall
Firefox as apt instead. Just accept it.

*sudo apt autoremove snapd \--purge*

Repeat the step to back up Firefox profile, this time is for recreating
the profile. I created a new profile, opened its directory, pasted the
backup profile there. And that's it.32:T16a5,by The Testing Guy

Last night on Wednesday, May 10, I came across a post on
[Reddit](https://www.reddit.com/r/youtube/comments/13cfdbi/apparently_ad_blockers_are_not_allowed_on_youtube/)
saying that Youtube is beginning to block videos if you are using
ad-block, such as me on Firefox using uBlock Origin. I thought that was
some kind of April Fool joke so I ignored it. Today, I received a
community post by Youtuber [Cynical
Reviews](https://www.youtube.com/channel/UC1DCPS2j-o0bvfIilkc8RSw/community?lb=UgkxRDC4JuhK_O3jyMqIIyGe8a0u850H6qTR)
saying the same thing yesterday. So I thought: "We're in the endgame
now".

![](ic/images/blog/Tech/23/230511/ban_adblock.png)

#### My history of the Internet

I've been with the Internet since the very beginning of it. I used
dial-up back in the 2000s and switched to DSL later on. My family used
to chat on Yahoo Messenger, play flash games (RIP Adobe Flash, you will
be missed for your large catalog of content you provided for us), play
Boom Online, and watch videos on Youtube. Those days, Internet was
expensive, counted by MBs you consumed, so you had to watch the amount.
I only downloaded heavy files at night to cut cost. But it was less
restrictive, less corporate, curated like today. It was the "wild west"
where anything could happen. You could find fun things while searching
the old web. Back at that time, it was Yahoo Search, nobody heard of
Google yet. Youtube was its own company then, just launched. I started
watching it at a later time. I used to watch Inuyasha, the entire
collection on Youtube, because copyright wasn't enforced then. I started
watching [nigahiga](https://www.youtube.com/@ryanhiga) in 2021. If you
follow his channel, you can basically see the history of Youtube and the
world of the second decade of the 21^st^ century unfolds.

#### What's wrong with today's Youtube?

It's generally what's wrong when anything becomes too big, too popular.
It's becoming sanitized, safe, family-friendly (whatever that means),
corporate. And Youtube is no exception. I see its changes from a service
centered around its creator to slowly moving away, instead pleasing the
advertizers, the investors, the big names in the MSM (mainstream media).
So Google created various changes to their platform, including but not
limited to: demonetize any video with curse words in it (even videos not
meant for kids); false copyright claims run rampant (even on channels
whose videos are owned by the creator get copyrighted); losing revenue
by Youtube taking your copyrighted video and giving it to the "original"
owner; ad runtime increase; before video then after video then middle,
from 3, 5 seconds, to 15 seconds, skippable to nowadays unskippable,
some ads even 15 minutes, a lot of them are scam;
[Adpocalypse](https://youtube.fandom.com/wiki/YouTube_Adpocalypse);
and now, about to force me to turn off ad-blocker.

#### Commentary

Like hell I'm turning off ad-blocker. This has been going on at other
sites as well. They detect that you're using ad-blocker, block the site
and "ask" you to take it down. Sure, take it down so they can shove ads
covering your screen, loud videos in your face. While I can ignore any
other sites doing this, I can't ignore Youtube. It has become a large
part of everyone's lives and livelihoods. I can just buy Premium and
forget about all this, but that's on top of more bills to pay (Netflix,
Internet, VieOn), and you pay for something that is and will always be
free. Maybe you can buy it to support your creators, but that's the
case, why do they have to take sponsorships and Patreons, open their own
merchandise store then? Sponsorships are ads that are on top of
Youtube's dumb ads, this time INSIDE the videos. As seen in adguard's
[article](https://adguard.com/en/blog/firefox-manifestv3-chrome-adblocking.html)
and EFF's
[article](https://www.eff.org/deeplinks/2021/12/chrome-users-beware-manifest-v3-deceitful-and-threatening),
this isn't the first time Google tried to shut down ad-block. And to me,
it's kind of depressing thinking about what's to come, as the Internet
becomes more restrictive as time goes on. Soon due to geopolitics, there
will be a localNet^(tm)^ instead of Internet, where each country has
their own version of the Internet. And because your typical user doesn't
care, they will stay on Chrome and Youtube, which Google has the power
over and can tell us what to see and not see, not just ads, but contents
that fit their "vision". Firefox may give us some freedom from Chrome
now, but for how long? I saw even Mozilla has lost its
[focus](https://www.mozilla.org/en-US/products/vpn/)
[over](https://mozilla.social/explore) the years. I thought DuckDuckGo
focuses on privacy, but then [they sell your data to
Microsoft](https://www.bleepingcomputer.com/news/security/duckduckgo-browser-allows-microsoft-trackers-due-to-search-agreement/).
My favored Linux distribution, Ubuntu, becomes more corporate, forcing
weird decisions like [this](https://evertpot.com/firefox-ubuntu-snap/)
and
[this](https://www.reddit.com/r/linux/comments/j3ajnf/whats_wrong_with_snaps_why_so_many_people_hate_it/).
Reading
[on](https://www.reddit.com/r/Cyberpunk/comments/wxra6o/we_already_live_in_a_cyberpunk/)
[Reddit](https://www.reddit.com/r/Cyberpunk/comments/b5srqp/do_we_live_in_cyberpunk_already/),
and recently finished watching [Cyberpunk
Edgerunner](https://www.youtube.com/watch?v=JtqIas3bYhg), I think we are
already living in a cyberpunk dystopia. Various service we use for our
conveniences like Facebook, Google might as well came out of George
Orwell's *1984*, or I can do one better, Aldous Huxley's [*Brave New
World*](https://www.reddit.com/r/books/comments/yq7yt/so_i_read_brave_new_world_how_is_it_a_dystopia/).
Maybe\... This is the endgame for all of us.33:T1f4c,I recently got my hand on a new router to play with. It's an [Orange Pi
R1 Plus
LTS](http://www.orangepi.org/html/hardWare/computerAndMicrocontrollers/details/orange-pi-R1-Plus-LTS.html),
an Rockchip RK3328 board with dual-gigabit Ethernet ports. The reason
for the *LTS* or *Long Term Support* is because of chip shortage, they
lacked the Realtek RTL8211 chip for the WAN port, so they substituted it
with Motorcomm YT8531C because it was more abundant. I plan to use this
board as either a DNS Server to speed up domain querying in place of my
Raspberry Pi, or as a router. There is a similar board which this one
takes inspiration from (including device tree source, more on that
later), [NanoPi
R2S](https://www.friendlyelec.com/index.php?route=product/product&product_id=282).
However, that board was pricier and I felt a bit adventurous that day.
So first off, I tried out Openwrt on this board, since it was
recommended by the board manufacturer.

![](/images/blog/Tech/23/230523/my_r1.jpg)

#### Different flavors of OpenWrt

When I bought this board used, they gave me a metal case, a 32GB SD card
with their own version of OpenWrt 21.02 installed. It was packed to the
brim with stuff, Docker, adblock, bandwidth monitor, wake on LAN,
torrent downloader, DLNA, Dynamic DNS. It wasn't for my liking since it
slowed the OS down so I tried something else.

Following [this
page](https://orangepi.vn/huong-dan-tai-cac-ban-openwrt-cho-orange-pi-r1-plus-lts.html),
I tried out the manufacturer's OpenWrt. Much like the previous one, it
was based on 21.02 but fairly minimal. A Youtube named Van Tech Corner
[created his own OpenWrt
release](https://github.com/vantechcorner/openwrt-orangepi) from the
[source code provided by the
manufacturer](https://github.com/orangepi-xunlong/openwrt). You can
check out the [unboxing and
testing](https://www.youtube.com/watch?v=vtdBMK8Cyx0&pp=ygUMb3JhbmdlIHBpIHIx)
video,
[similar](https://www.youtube.com/watch?v=c7dTmngyaVM&pp=ygUKbmFub3BpIHIycw%3D%3D)
video for NanoPi R2S. The two releases differ in the number of packages
preinstalled. I tested the Van Tech's one. It was better because of its
slim size. But when I tried to install any package that has a kernel
dependency, like Wireguard, 4G USB support (RNDIS), it said *The
installed version of package kernel is not compatible.* According to the
OpenWrt [page](https://openwrt.org/faq/cannot_satisfy_dependencies),
these were self-compiled image, and couldn't use kernel-related packages
from the official repository, but had to be either included in or built
beforehand and installed externally. I tried out OpenWrt official
download [page](https://downloads.openwrt.org/), but no luck for this
board. NanoPi R2S did have an image, though. So I'm out of luck until
official support from OpenWrt or Orange Pi, right?

#### A daring approach: Compile from source

Before this, I compiled Asterisk for my VOIP server experiment. It was
the recommended way of installing it, as the one on the Ubuntu repo
(repository) is old. I just followed the instructions and it compiled
and installed. Another instance is driver install. Some drivers like my
RTL8156 2.5Gbps Ethernet USB for my server had to be compiled from
source because again, Debian's one was too old to support it. So I
checked out source code from [Van
Tech](https://github.com/vantechcorner/openwrt-orangepi),
which is a derivative (or fork) of the source code from Orange Pi's
OpenWrt. At first, I just randomly followed instruction, feeds update,
feeds install. Inside menuconfig, Global build settings, I picked
*Select all target specific packages by default*, *Select all kernel
module packages by default*. So it took *a few hours* to either compiled
and didn't run on the R1 Plus board, or it caught an error halfway.
After a few more tries, I eventually got it compiling correctly, though
I chose to *make -j1* because I needed to trace the error if it popped
up.

![](/images/blog/Tech/23/230523/menuconfig.jpg)

After testing the compiled image on the board to verify it running
correctly, I searched Google and found [this forum post from OpenWrt and
image and source code from
walmartshopper](https://forum.openwrt.org/t/orange-pi-r1-plus-support/84824/246).
It was newer, version 22.03, and it worked using their provided image.

I got curious about the changes in the source code that Orange Pi made,
so I used Visual Studio Code to look into the source. I searched for
anything related to Orange Pi R1 Plus (LTS included) and came across
multiple results. I will tell you some notable ones:

![](/images/blog/Tech/23/230523/kernel_patch.jpg)

\- The .patch files inside *target/linux/rockchip/patches-5.4* and
*package/boot/uboot-rockchip/patches*. According to
[kernel.org](https://www.kernel.org/doc/html/v4.18/process/applying-patches.html),
these are kernel patches. This is how Orange Pi add support for their R1
Plus (and LTS) board to OpenWrt, even though you can't find this board
on OpenWrt's download page. They patched dts files in the kernel, in
addition to the YT8531C driver for the ethernet.

\- *target/linux/rockchip/image/armv8.mk* shows how OpenWrt build the
image for the board, as well as *package/boot/uboot-rockchip/Makefile*
for the bootloader.

Note that this is an ARM processor, so the boot process is different
than your computer. It requires a dtb, or a device tree blob that is
compiled from dts - device tree source file, and its own bootloader.
They usually use U-Boot. To this day, Orange Pi R1 Plus (and LTS) dts
files haven't been upstreamed, or merged back to the OpenWrt source. The
Linux kernel source has upstreamed dts for R1 Plus on v6.3 and LTS on
v6.4. Maybe in the future, as there has been several attempts at doing
so at OpenWrt pull requests.

Looking at other git repos like from
[walmartshopper](https://github.com/walmartshopper/openwrt-orangepi-r1-plus/commits/openwrt-22.03?author=walmartshopper),
[baiyut](https://github.com/baiywt/openwrt/commits/openwrt-22.03?author=baiywt)
(who is in charge of the patches in Orange Pi OpenWrt, his own repo also
has OpenWrt 22.03),
[ImmortalWrt](https://github.com/immortalwrt/immortalwrt) (which allows
non-upstreamable patches), they also applied this technique to support
the R1 Plus (and LTS). From [walmartshopper's
repo](https://github.com/walmartshopper/openwrt-orangepi-r1-plus/commits/openwrt-22.03?author=walmartshopper),
I tried merging OpenWrt 22.03 current branch to his, but the number of
conflicts is too big, I wondered if the amount of work put into keeping
R1 Plus up-to-date with OpenWrt was this huge. It's quite amazing.

In the future, with the release of OpenWrt 23.05, if those customized
repos don't support the board, and OpenWrt doesn't support either, I
will see if it's possible to port the files for R1 Plus (and LTS) over.

#### Note on using Android TV Box as router

Before all this, I tried testing a X96 Air S905X3 4GB and Mecool M8S Pro
W S905W 2GB with this OpenWrt implementation by
[ophub](https://github.com/ophub/amlogic-s9xxx-openwrt). He used Armbian
bootloader to boot to OpenWrt environment. One of the flaws I discovered
after testing [Coreelec](https://coreelec.org/) on the Mecool is that [I
can\'t boot back to Armbian or OpenWrt
anymore](https://forum.armbian.com/topic/18871-boot-from-usb-having-armbian-on-emmc/),
due to Coreelec overwriting the eMMC bootloader and I don't want to
re-flash Android on the TV Box. In fact, this was exactly why I
purchased this Orange Pi R1 Plus LTS board. So I don't have to go
through this hassle with TV Box. And in the event of Raspberry Pi
shortage such as right now, I want to switch to alternative single board
computers such as Orange Pi from now on. While support is spotty, they
outperform the Raspberry Pi and don't *cost an arm and a leg* to buy.

References:

\- [OpenWrt source
code](https://openwrt.org/docs/guide-developer/source-code/start)

\- [OpenWrt Build system
usage](https://openwrt.org/docs/guide-developer/toolchain/use-buildsystem)34:Tc1e,This post is supposed to be an update on the 4G-to-Wifi series
*Upgrading Grandparents' Wifi* I did previously. But discussing with my
family has led me to contemplate that saying. My country has a similar
one: *cure a healthy pig and make it lame as a result* or *chữa lợn lành
thành lợn què*.

#### The update

After a month of running my grandparents' network on 4G, on April 23
2023, the project was effectively shut down. The Mi Wifi R3G router was
instead connected to SCTV cable Internet, which is rated at 50 Mbps. A
few problems rose from the project:

\- 4G network was unstable. Sure, it worked. But it disconnected every
few days, forcing me to reconnect it.

\- It wasn't as fast as I hoped. When the towel wasn't congested, it
could reach 80 Mbps. But most of the time, inconsistent from 15 to 50
Mbps. That wasn't any better than our cable Internet. It could be
because the 4G USB modem is cheap, so the antenna quality wasn't good,
or it couldn't utilize Carrier Aggregation, which is something you'd
find on modern smartphones. My phone can easily reach 190 Mbps download
out of our nearest towel alone.

\- Double pay. We already paid for our cable Internet, now I had to pay
my own to do this experiment. So it wasn't meant to last.

So now the 4G modem sits in my inventory, occasionally being pulled out
of its slumber so I can test it on my laptop for fun. Guess it can only
be used as backup.

#### The proverb

![](/images/blog/Tech/23/230506/Picture1.png)

My hobby is interesting. I regularly install, uninstall, dismantle,
reassemble things more times than I could count. But it comes with
karma. I can't stop. Like if there was something to improve
technologically in my house, or there were techs that intrigued me, I
would try it out, which usually ends up breaking everything else. Can't
count the number of close-calls I had with my devices breaking because
of the new things I put in, lack of precaution, no backup plan\... I am
constantly reminded by my family "If it ain't broke, don't fix it". It's
a similar thing I learned when I was still working as a software
developer. Because a lot of functions in a software are built on top of
each other, they act like a domino chain. If one falls, every one will
fall, too. Heck, my 4G-to-wifi project had to be pulled partly because
of my endless experiments on the Pi router end up breaking the network
from time to time. My family said: "Enough with this. Return everything
back to **normal**. You had your fun. If it ain't broke, don't fix it".
Maybe they're right. After all, this is just to satisfy my boundless
curiosity. Nobody is going to care where they got their Internet from,
or how fast. They only concern whether it will get them to Facebook. To
them, a DNS Server to speed up 1 second of scrolling through posts does
nothing. It does to me. It makes a 50 Mbps cable Internet feel like it
can match the snappiness of a 150 Mbps fiber connection.

I feel like anyone who is an artisan, an engineer, a mechanic, or works
in the technology sector, may run into something similar to the problem
I have.35:T19ba,I am a media consumption enthusiast. Let's just say I watch movies a
lot. Usually, people like me will have a big home theater setup with a
large TV, a large speaker set, a media player with huge HDD storage. But
that sounds like too much work, since you have to update the hard drive
constantly with new catalogues. So I built my server out of an old i3
laptop, a SSD, 2 HDD lying around with a dock and an Ethernet USB
dongle. I chose 2.5 Gbps dongle version because I wanted to future-proof
my server. But that proved to be my undoing, because the OS I chose for
my server, Debian, had an older version of the driver that didn't
support the RTL8156 chipset. It might support an older one, the RTL8153,
which is the 1 Gbps variant. So I searched for its driver. It's quite a
little adventure.

![](/images/blog/Tech/23/230504/DKMS_flow.webp)

#### First time compiling from source

A Google search for RTL8156 driver for linux led me to the
manufacturer's driver page to download the driver. However, the
compressed file I downloaded (in this instance .tar.bz2) didn't have any
.deb file to install. Instead I was left with a bunch of .h, .c files
with a Makefile. I thought: "Wait. This is a source code!".

So far, I have mostly installed apps and drivers through apt so this was
a new territory. I did some researches and tried compiling the driver.
In the source code folder, I typed:

*make -j4*

With -j4 being number of jobs to run simultaneously, 4 is the number of
threads of my CPU. After it finished, the result was r8152.ko file, a
kernel module. I plugged in the Ethernet USB. It didn't work. Then I
tried loading the module into the kernel like [this
article](https://www.tecmint.com/load-and-unload-kernel-modules-in-linux/)
suggested:

*insmod r8152.ko*

Then it worked. My server recognized it.

*ip a*

*3: enx00e04e3b0ac0: \<BROADCAST,MULTICAST,UP,LOWER\_UP\> mtu 1500 qdisc
pfifo\_fast state UP mode DEFAULT group default qlen 1000*

I edited the *interface*s file in */etc/network* to assign it a static
address by adding:

*allow-hotplug enx00e04e3b0ac0*

*iface enx00e04e3b0ac0 inet static*

*address 192.168.4.3/24*

*gateway 192.168.4.1*

For then on, I could access my server in my house through that IP,
*192.168.4.3.*

But I discovered that:

\- At start-up, I have to *insmod* like that to load the module. This
was solved by simply copying that module to /lib/modules/\$(uname
-r)/kernel/drivers/net/usb. Didn't have to *insmod* anymore. But that
wasn't all.

\- Every time I update the server with apt update, apt upgrade, and
there is a kernel update, I have to compile module from source, copy it
over again or else I lose the driver. So I often delay updating my
server, which is bad because you want to keep your kernel up-to-date on
bugfix, vulnerabilities.

I needed a way to make it compile every time there is a kernel update.
So is there a way?

#### dkms - Dynamic Kernel Module Support

Nowadays, I use an Ubuntu desktop as my main driver. I often see
something along the line of dkms for my Nvidia card anytime there is a
kernel update. After rebooting, the video card still works with the new
kernel. Naturally, I started looking into this "dkms".

According to this [article](https://linuxhint.com/dkms-linux/), dkms
*"is a framework where device driver source can reside outside the
kernel source tree so that it is very easy to rebuild modules as you
upgrade kernels"*. So this is the stuff I was looking for. The author
also encountered dkms similarly to me, but by following guides to
install his Wifi driver.

So with the source code of my Ethernet USB, I copied it to */usr/src*. I
also created a file inside the source code's folder, *dkms.conf* with
the following content:

*PACKAGE\_NAME=\"r8152\"*

*PACKAGE\_VERSION=\"2.15.0\"*

*BUILT\_MODULE\_NAME\[0\]=\"r8152\"*

*MAKE=\"\'make\' -j\$(nproc) KVER=\$\{kernelver\}\"*

*CLEAN=\"\'make\' clean\"*

*DEST\_MODULE\_LOCATION\[0\]=\"/kernel/drivers/net/usb/\"*

*AUTOINSTALL=\"YES\"*

PACKAGE\_NAME gives the name to the entire package of modules.

PACKAGE\_VERSION give the version of the entire package of modules being
installed with dkms. These two form the name of the folder that contains
the source code, *r8152-2.15.0.

BUILT\_MODULE\_NAME gives the name of the module just after it is built.

DEST\_MODULE\_LOCATION specifies the destination where a module should
be installed to, once compiled. From the example: /lib/modules/\$(uname
-r)*/kernel/drivers/net/usb*.

Note that for each module within a dkms package, the numeric value of \#
must be the same for each of BUILT\_MODULE\_NAME and
DEST\_MODULE\_LOCATION and that the numbering should start at 0. So each
module goes with its own destination

MAKE and CLEAN correspond to commands used to run when dkms builds
(make) the module and cleans up after.

AUTOINSTALL is set to yes so that the service
/etc/rc.d/init.d/dkms\_autoinstaller will automatically try to install
this module when upgrading kernel.

After that, I ran three commands:

\- *sudo dkms add r8152/2.15.0*

\- *sudo dkms build r8152/2.15.0*

\- *sudo dkms install r8152/2.15.0*

And it installed the driver to the kernel. From then on, it will build
and reinstall anytime I upgrade the kernel.

Result:

*sudo dkms add r8152/2.15.0*

*Creating symlink /var/lib/dkms/r8152/2.15.0/source -\>*

*/usr/src/r8152-2.15.0*

*DKMS: add completed.*

*sudo dkms build r8152/2.15.0*

*Kernel preparation unnecessary for this kernel. Skipping\...*

*Building module:*

*cleaning build area\...*

*\'make\' -j4 KVER=5.10.0-22-amd64\...\...*

*cleaning build area\...*

*DKMS: build completed.*

*sudo dkms install r8152/2.15.0*

*r8152.ko:*

*Running module version sanity check.*

*Good news! Module version v2.15.0 for r8152.ko*

*exactly matches what is already found in kernel 5.10.0-22-amd64.*

*DKMS will not replace this module.*

*You may override by specifying \--force.*

*depmod\....*

*DKMS: install completed.*

*dkms status*

*broadcom-sta, 6.30.223.271, 5.10.0-20-amd64, x86\_64: installed*

*broadcom-sta, 6.30.223.271, 5.10.0-22-amd64, x86\_64: installed*

*[r8152, 2.15.0, 5.10.0-22-amd64, x86\_64: installed]*

If you wish to remove the driver, type in *"dkms remove r8152/2.15.0
\--all"*.

References:

\- [man dkms](https://linux.die.net/man/8/dkms)

\- [Realtek USB FE / GBE / 2.5G / Gaming Ethernet Family Controller
Software](https://www.realtek.com/en/component/zoo/category/network-interface-controllers-10-100-1000m-gigabit-ethernet-usb-3-0-software)

\-
[rtl8821CU](https://github.com/brektrou/rtl8821CU/blob/master/dkms-install.sh)36:T3e96,I have a curious habit. When checking out the best deals from my
country's cell companies, I searched Google for illegitimate websites
instead of going straight to the sources. They have a tendency to hide
their promotional data plans deep within the Internet, and only show
standard data plans on their websites. I came across a few ones that
caught my attention. They all had something to do with free data under
selected services:

\- YT30 from Viettel allowed you to watch Youtube videos and didn't
count towards your data caps

\- Big50Y from Vinaphone allowed watching Youtube, Tiktok, using Zalo
apps not counting towards caps and gave you 5 GB per day

\- Y60, our subject of investigation today, allowed the same things and
gave you 2GB per day.They came with a requirement of the promotion only
applies to the Youtube, Tiktok apps.

So I plan to investigate whether it could be applied to the website, and
could it be used on a laptop when tethered to.

#### Preparation

When I tried to register Y60 data plan on my Mobifone, I did not qualify
for it because it required that I was born before 1995. But I was able
to register for **G1** data plan, which included free data for the
following apps: Instagram, ZingTv, Zing MP3, Gmail, Google Drive, Zalo,
Viber, Tiktok, FPT Play. I also found another SIM on Vinaphone to
register **GT1** data plan, which included free data for Youtube, VieOn,
Nhaccuatui, Tiktok.

For Mobifone, they required you to install an app called mobifoneGo.
This app would tell you when an app launched is permitted for free data.
In addition, it also allows you to buy extra data plans for specific
apps you want free.

![](/images/blog/Tech/23/230427/mobifonego.jpg)

#### Result

According to my findings, mobifoneGo created a VPN that only tunneled
traffic through if it was coming from the selected apps. For example, I
used FPT Play to watch some TV using 4G. When I activated 4G, a VPN
tunnel was opened and when FPT Play was opened, the program showed a
notification stating that I had obtained unlimited data and using FPT
Play didn't reduce my data cap. If it had been any other apps, it
wouldn't have worked and my data cap would be decreased. I tried
broadcasting Wifi to my laptop to see if [https://fptplay.vn/](https://fptplay.vn/) counted
as free data but it didn't work, not even creating a proxy using Every
Proxy to go through the VPN tunnel on the phone solved it. It reduced my
data cap. The desktop-sized picture is when I ran out of my data cap.

![](/images/blog/Tech/23/230427/fpt out of gb with phone.png)

![](/images/blog/Tech/23/230427/fpt out of gb with proxy pc.jpg)

For Vinaphone, it was simpler. You would get free data by either visit
the website like [https://youtube.com/](https://youtube.com/), [https://tiktok.com/](https://tiktok.com/),
[https://vieon.vn/](https://vieon.vn/), or use the equivalent apps. However, only Youtube
got free data, the rest didn't get free data, it subtracted my data cap.
I see a false advertising here!

#### Routing table in Android from Mobifone

Utilizing Termux, which is a terminal for Android, I looked for some
information regarding the tunnel.

*ip route show table 0*

\- With mobifoneGo:

*default dev tun0 table tun0 proto static scope link*

*10.0.0.2 dev tun0 table tun0 proto static scope link*

*default dev dummy0 table dummy0 proto static scope link*

*default via 10.100.58.145 dev rmnet\_usb0 table rmnet\_usb0 proto
static*

*10.100.58.144/30 dev rmnet\_usb0 table rmnet\_usb0 proto static scope
link*

*10.51.40.254 via 10.100.58.145 dev rmnet\_usb0 src 10.100.58.146*

*10.53.120.254 via 10.100.58.145 dev rmnet\_usb0 src 10.100.58.146*

*10.100.58.144/30 dev rmnet\_usb0 proto kernel scope link src
10.100.58.146*

*local 10.0.0.2 dev tun0 table local proto kernel scope host src
10.0.0.2*

*broadcast 10.100.58.144 dev rmnet\_usb0 table local proto kernel scope
link src 10.100.58.146*

*local 10.100.58.146 dev rmnet\_usb0 table local proto kernel scope host
src 10.100.58.146*

*broadcast 10.100.58.147 dev rmnet\_usb0 table local proto kernel scope
link src 10.100.58.146*

*\[\...\]*

\- Without mobifoneGo:

*default dev dummy0 table dummy0 proto static scope link*

*default via 10.100.58.145 dev rmnet\_usb0 table rmnet\_usb0 proto
static*

*10.100.58.144/30 dev rmnet\_usb0 table rmnet\_usb0 proto static scope
link*

*10.51.40.254 via 10.100.58.145 dev rmnet\_usb0 src 10.100.58.146*

*10.53.120.254 via 10.100.58.145 dev rmnet\_usb0 src 10.100.58.146*

*10.100.58.144/30 dev rmnet\_usb0 proto kernel scope link src
10.100.58.146*

*broadcast 10.100.58.144 dev rmnet\_usb0 table local proto kernel scope
link src 10.100.58.146*

*local 10.100.58.146 dev rmnet\_usb0 table local proto kernel scope host
src 10.100.58.146*

*broadcast 10.100.58.147 dev rmnet\_usb0 table local proto kernel scope
link src 10.100.58.146*

*\[\...\]*

As you can see, the 4G modem is *rmnet\_usb0*, the tunnel is *tun0.*
*tun0* didn't add any new route into the routing table, so I guess this
is a local VPN that changes the IP header from packets belonging to the
allowed apps so that Mobifone server can detect some kind of free data
flag, because it's unlikely for it to tamper with the original content
of a packet, which was usually encrypted by protocols like HTTPS in APIs
or video streams.

*traceroute 8.8.8.8*

\- With mobifoneGo:

*traceroute to 8.8.8.8 (8.8.8.8), 30 hops max, 60 byte packets*

*2 10.53.86.53 (10.53.86.53) 32.868 ms 31.891 ms 31.189 ms*

*3 10.53.125.82 (10.53.125.82) 27.192 ms 10.53.125.83 (10.53.125.83)
26.642 ms 26.123 ms*

*4 10.53.124.88 (10.53.124.88) 25.665 ms 25.177 ms 24.627 ms*

*5 10.53.124.131 (10.53.124.131) 24.017 ms 10.53.124.130 (10.53.124.130)
23.223 ms 10.53.124.131 (10.53.124.131) 22.370 ms*

*6 10.53.125.103 (10.53.125.103) 21.179 ms 22.430 ms 21.790 ms*

*8 10.53.165.41 (10.53.165.41) 27.832 ms 27.374 ms 26.764 ms*

*9 10.53.119.218 (10.53.119.218) 53.620 ms 53.101 ms 52.582 ms*

*10 142.250.47.38 (142.250.47.38) 51.971 ms 51.422 ms 59.356 ms*

*12 dns.google (8.8.8.8) 57.587 ms 63.294 ms 62.622 ms*

*\[\...\]*

*- Without mobiifoneGo:*

*traceroute to 8.8.8.8 (8.8.8.8), 30 hops max, 60 byte packets*

*2 10.53.86.53 (10.53.86.53) 33.631 ms 27.100 ms 26.123 ms*

*3 10.53.125.82 (10.53.125.82) 25.116 ms 24.536 ms 18.127 ms*

*4 10.53.124.88 (10.53.124.88) 17.487 ms 24.567 ms 21.240 ms*

*5 10.53.124.131 (10.53.124.131) 28.382 ms 10.53.124.130 (10.53.124.130)
27.832 ms 27.221 ms*

*6 10.53.125.102 (10.53.125.102) 26.672 ms 10.53.125.103 (10.53.125.103)
27.008 ms 26.245 ms*

*7 10.53.165.206 (10.53.165.206) 25.361 ms \* \**

*8 10.53.165.41 (10.53.165.41) 27.130 ms 34.577 ms 30.976 ms*

*9 10.53.119.218 (10.53.119.218) 57.739 ms 50.903 ms 50.324 ms*

*10 142.250.47.38 (142.250.47.38) 57.160 ms 65.888 ms 56.335 ms*

*12 dns.google (8.8.8.8) 59.235 ms 62.500 ms 58.167 ms*

*\[\...\]*

There isn't much change in the way a packet traveled through 4G either
way.

#### How Vinaphone found out about my free data

As most traffic is end-to-end encrypted by HTTPS, the only way I see
Vinaphone detect the free data is through reading the destination of a
packet being sent. They have a IP whitelist for the free-data plan. For
example, Youtube had the following IP list when I queried it using my
DNS Server:

*;; ANSWER SECTION:*

*youtube.com. 120 IN A 64.233.170.136*

*youtube.com. 120 IN A 64.233.170.93*

*youtube.com. 120 IN A 64.233.170.91*

*youtube.com. 120 IN A 64.233.170.190*

So it's likely Vinaphone allowed these IPs to not reduce my data cap
when I watched videos on them. It worked even when I tethered the phone
to my laptop to access Youtube on the web browser.

#### Zero-rating and net neutrality

Basically, when you use Internet on your phone through technologies like
3G, 4G, LTE, you have a data plan ahead with some limit on how much you
can consume. And some carriers sell special plans that allow you to
access some online services without reducing your data caps, usually
related to video streaming, communication\... That practice is known as
**zero-rating**. I got introduced to this concept by chance. First by
coming across BIG50Y data plan from Vinaphone, and the word came about
later when I was researching on this topic. This practice just showed up
in Vietnam recently, while had shown up in the US before. Like **Binge
On** from T-Mobile that doesn't reduce data cap when you watch videos on
Youtube, Netflix, HBO\... but how they go about doing it is [throttling
bandwidth of **any** videos regardless of
services](EFF Confirms: T-Mobile’s Binge On Optimization is Just Throttling, Applies Indiscriminately to All Video).

Facebook also jumped on the zero-rating bandwagon with their own [Free
Basics](https://en.wikipedia.org/wiki/Internet.org) (internet.org)
program, which granted you free access to Facebook (duh!) and other
services that had made deal with Facebook. It used to be deployed in
third world nations like India, Myanmar, but has since been removed.
Because it's a double-edged sword.

On the one hand, this exercise goes against net neutrality.

![](/images/blog/Tech/23/230427/facebook-freebasics-india-1100px.webp)

What is net neutrality you may ask? **Net neutrality** is the principle
that an ISP has to provide access to all sites, online services with the
same speed, same treatments without blocking, slowing down or give
"special treatment" to any others. It's the idea that governs free
Internet as we now know today. So **zero-rating** is essentially ISP
playing favorites to those paying to sponsor your data, whether is
content provider like Youtube, social media like Facebook, or both like
Tiktok. ISP can also play favorites to their own services. Why would you
want to watch live streaming on website A when service B, offered by the
ISP, charged nothing and reduced no data cap. Thus creating an unfair
advantage to anyone not willing to "pay-to-win", as the term from online
games goes. The consumers are disincentivized to explore alternative
sites, leaving "sponsored" sites the only choices they have, closing of
the Internet to a few sites. [There were surveys conducted in various
countries showed that people thought Facebook is the
Internet](https://qz.com/333313/milliions-of-facebook-users-have-no-idea-theyre-using-the-internet).

Another problem arises is privacy and security concern over the practice
of checking packet (or packet inspection) to see whether it goes to the
zero-rated destination, or man-in-the-middle proxy to check its content
like Free Basics.

![](/images/blog/Tech/23/230427/free_basics_proxy.png)

The practice gives too much power to the ISP, who can now decide which
service providers it likes, which it doesn't and limit them.

An article on
[TechCrunch](https://techcrunch.com/2017/04/16/wtf-is-zero-rating/)
pointed out the logical fallacy I liked about zero-rating. Basically, if
you can infinitely watch video on their chosen platform, then there must
be enough bandwidth to handle it. If that were true, data caps wouldn't
be necessary at all. Which brings the whole zero-rating practice to
question.

There are, however, arguments to be made about the necessity of
zero-rating in very poor countries like
[Laos](https://news.ycombinator.com/item?id=31463249), or continents [in
Africa](https://www.theguardian.com/technology/2022/jan/20/facebook-second-life-the-unstoppable-rise-of-the-tech-company-in-africa).
Where there isn't enough money to eat, let alone spending it on data and
Internet, zero-rating at least gives people a chance to learn, a
platform for commerce, a tool for cheaper communication, however
limited. According to a Reddit comment about Free Basics, ["it does
include free access to Wikipedia as well as other sites like
Dictionary.com, a translator, BBC News, lots of Indian news sites,
WikiHow, Unicef and various other sources of health
information.\"](https://www.reddit.com/r/worldnews/comments/3z94u3/a_week_after_india_banned_it_facebooks_free/)
Depriving people of the Internet altogether means losing out on an
utility we all take for granted today. As a short term solution, it\'s
an unequivocal yes. There are an unbelievable number of African
businesses that exist only because of the [Facebook's Free
Basics](https://www.theguardian.com/technology/2022/jan/20/facebook-second-life-the-unstoppable-rise-of-the-tech-company-in-africa)
program. But calling it "Digital colonialism" is not fall from the
truth, as [Facebook became the Internet itself in the eyes of a majority
of
Africans](https://www.theguardian.com/world/2016/aug/01/facebook-free-basics-internet-africa-mark-zuckerberg).
Hence why it was banned in India.

Another use case for the practice is free access to public service, such
as in medical, education, as pointed out by this [blog
post](https://www.humanrightspulse.com/mastercontentblog/is-zero-rating-a-threat-to-human-rights).
The Colombian Government sanctioned zero-rated educational services so
that students wouldn't miss school during COVID pandemic. The Australian
and the UK partnered up with mobile carriers to curb misinformation
about public health, reduce cost barrier, achieve health equality. "Not
only did the service allow people to use online services to access
medical records, book appointments, and other services, but it also
enabled them to obtain information on several health topics".

[https://www.youtube.com/embed/mfY1NKrzqi0?si=UCtLbr28hEZT_oJY](https://www.youtube.com/embed/mfY1NKrzqi0?si=UCtLbr28hEZT_oJY)

#### Conclusion

After a lot of articles, researches on these topics, it's hard for me to
decide whether this should be acceptable. I'm pro net-neutrality. I'm
against the idea of a walled-garden for the Internet. But zero-rating
has its use, IMHO only for public services or disaster situation. It
shouldn't be used as a way to stifle competition.

#### Note: Fun fact about T-Mobile's Binge On

If you check out this
[article](https://www.eff.org/deeplinks/2016/01/eff-confirms-t-mobiles-bingeon-optimization-just-throttling-applies),
Electronic Frontier Foundation (EFF) did an experiment to check if
T-Mobile throttled their downloads based on their contents and
protocols. From the result, it could be seen that they throttled
bandwidth **only** when they could **detect** the content type or file
type, which was only possible on HTTP because HTTPS encrypted data.

References:

\- [Net neutrality](https://en.wikipedia.org/wiki/Net_neutrality)

\- [Zero-rating and what\'s wrong with
it?](https://techcrunch.com/2017/04/16/wtf-is-zero-rating/)

\- [How does an unlimited YouTube data plan work (StreamOn, T-mobile,
De)?](https://www.quora.com/How-does-an-unlimited-YouTube-data-plan-work-StreamOn-T-mobile-De-How-does-it-know-if-I-am-streaming-from-a-laptop-connected-at-a-mobile-hotspot-or-if-I-am-watching-from-my-phone-through-the-YouTube-app)

\- [G1 MobiFone](https://mobifonego.vn/goi-g1-mobifone/)

\- [GT1 Vinaphone](https://vinaphone.com.vn/di-dong/GT1/)

\- [Can I get the routing table entry in
Android?](https://stackoverflow.com/questions/6940973/can-i-get-the-routing-table-entry-in-android)

\- [Free Basics vs. Free Internet: Your Guide to the Raging Net
Neutrality
Debate](https://www.gadgets360.com/internet/features/free-basics-vs-free-internet-your-guide-to-the-raging-net-neutrality-debate-782554)

\- [Free Basics Technical
Guidelines](https://developers.facebook.com/docs/internet-org/platform-technical-guidelines)

\- [The Rise and Fall... and Rise Again of Facebook's Free Basics: Civil
Society and the Challenge of Resistance to Corporate Connectivity
Projects](https://globalmedia.mit.edu/2020/04/21/the-rise-and-fall-and-rise-again-of-facebooks-free-basics-civil-and-the-challenge-of-resistance-to-corporate-connectivity-projects/)

\- [Is Unlimited Data Really
Unlimited?](https://unlimitedlteadvanced.com/4g-lte/is-unlimited-data-really-unlimited/)

\- [It's a battle for internet
freedom](https://timesofindia.indiatimes.com/blogs/toi-edit-page/its-a-battle-for-internet-freedom/)37:T1d1c,After a blog series about using 4G as house Wifi, I need an short
article to breathe a bit. So this is gonna be a short one.

#### Background

Last year, I decided to upgrade the network in my house. My home network
was not much to speak of, just a Viettel modem (H646EW) connected to the
previously mentioned TP-Link Archer C50. My home server was connected to
the network through Wifi, because the router is in the kitchen while the
server was in my room adjacent to it, and wiring is out of the question.
The router slowly became a bottleneck, as the number of devices
connected to it increased and my server had to serve media contents
around the house as well as download contents from the Internet.
Internet bandwidth was also increased by the ISP to 150 Mbps and my old
router could not utilized it fully, only averaging 65 Mbps. So I
replaced the main router with an Asus RT-AC1300UHP. It's a 2.4/5 GHz
Wifi Router with Gigabit LAN. Its specs include a quad-core Qualcomm
IPQ4018 ARM processor at 700 MHz, 256 MB RAM, much more powerful than
the Archer with single-core Mediatek MT7628A MIPS running at 580 MHz
with only 64 MB RAM.

![](/images/blog/Tech/23/230415/router-wifi-bang-tan-kep-cong-suat-cao-asus-rt-ac1300uhp-mu-mimo.webp)

I replaced the router by connecting LAN1 from H646EW to WAN of the Asus
router, went in the configuration page of Asus router, changed WAN type
to DHCP (or in this case Automatic IP). And that was it. Speed test
using either speedtest.net or fast.com gave me full 150 Mbps
symmetrical.

![](/images/blog/Tech/23/230415/asus_wan_dhcp.jpg)

One day, as I was browsing through Facebook, I came across this group
talking about PPPoE and using another router to "dial" it instead of the
one provided by the ISP. So it got me thinking: "What if I can apply it
to my network then?"

#### Point-to-Point over Ethernet (PPPoE) and bridge mode

PPPoE is a network protocol for using PPP on Ethernet. Back in the old
days, PPP is used for dial-up Internet access. Nowadays, PPPoE is used
for customer authentication, record on DSL network, fiber network. When
you register for Internet service, your provider will give you a
username for the PPPoE account, and they pre-configured the account in
their modem with the password. Then from the modem, you would connect
another, better router to it, use it as the main point to connect to the
Internet for all devices in your house. The reason is that ISP modems
are usually weak, unreliable if left to handle anything to heavy. But by
using 2 routers, this leads to a situation called "double NAT", where
traffic coming to and from a client has to route twice before hitting
the Internet, increasing latency and causing problems to programs that
need to open port. The first drawback is why you would want to turn your
modem to bridge mode, so the router has to do most of the heavy lifting,
the modem's only job is conversion from fiber to Ethernet. The second
downside is kind of meaningless, as in IPv4, you most likely have an IP
address given by the ISP, which allows Internet access but the outside
world can't connect to you because a lot of users around your house also
have that same address (which is a large problem if you want to do
anything involving P2P like torrenting, VOIP, online gaming. Fixing this
is a story for another time).

![](/images/blog/Tech/23/230415/asus_wan_dhcp.jpg)

Bridge mode essentially turns your modem into a bridge, "bridge" the ISP
end to your router on the other end. It bypasses routing, DHCP of the
modem, sends traffic directly to the router.

#### Disclaimer

Before performing this, I should warn you. When I performed this, I
locked myself out of the modem multiple times, lost access to the
Internet, had to call their technician before resetting the modem fixed
the issue so that I could try again. So if your Internet is running
fine, you shouldn't bother doing this. Maybe you can look into DMZ
setting if available.

Another point is that each modem is different and each ISP is different.
Some modems may not have bridge mode available. Go through your modem's
settings first, talk to the ISP technician if needed before trying this.

Additionally, your router must be more powerful than your modem to go
through this procedure. Because dialing PPPoE is a single-threaded task
\[1\].

#### How to do it?

First, we need to change the modem to bridge mode. This depends on
model, so these steps is for my Viettel GPON modem H646EW.

[https://www.youtube.com/embed/CexU8EHlQ-0?si=KBSVzC9e2At7m7se](https://www.youtube.com/embed/CexU8EHlQ-0?si=KBSVzC9e2At7m7se)

Login to the configuration page using [https://192.168.1.1/](https://192.168.1.1/). Turn it
into Advanced Mode. First go to Advanced Setup on the left panel -\> LAN
settings to disable DHCP and Wifi Setup to disable Wifi on the modem.

Then go to Advanced Setup -\> WAN Connections.

![](/images/blog/Tech/23/230415/vlcsnap-2023-04-15-19h39m19s620.png)

Click Edit on any profile that is PPPoE mode if your ISP doesn't give
you your credential when registering for Internet service. It contains
your credential.

![](/images/blog/Tech/23/230415/vlcsnap-2023-04-15-19h39m37s389.png)

Right click on the Password text box and click Inspect Element. Find the
\<input\> tag that points to the Password box, change type from
"PASSWORD" to "text". It shall reveal your PPPoE password. Copy PPPoE
username and password, set status to Deactivated and click Apply.

![](/images/blog/Tech/23/230415/vlcsnap-2023-04-15-19h40m15s589.png)

Back at WAN Connections, we add a new entry, Bridge Mode, then click
Add.

![](/images/blog/Tech/23/230415/vlcsnap-2023-04-15-19h41m38s057.png)

Set status to Activated. IP choose IPv4/IPv6. At 802.1q, you have 2
options:

\- Tag VLAN at the modem: VLAN 35 for Viettel

\- Passthrough: pass VLAN Tagging to the router. You can usually find
this option under IPTV

For demonstration, I chose tagging VLAN at the modem.

![](/images/blog/Tech/23/230415/vlcsnap-2023-04-15-19h41m38s057.png)

After that, look under the modem for its MAC address. Then connect the
modem LAN1 to WAN of the router. For this instance, it's an Asus
RT-AC1300UHP. Login to Asus configuration page at [http://192.168.0.1/](http://192.168.0.1/).
Go to Advanced Settings -\> WAN. Change WAN Connection Type to PPPoE.
Fill in your PPPoE username and password. At Special Requirement from
ISP, set No to all and put MAC address the address you found under the
modem. Then click Apply. The router should now dial directly to ISP to
get Internet service, instead of going through routing from the modem.

![](/images/blog/Tech/23/230415/asus_wan_pppoe_1.jpg)

![](/images/blog/Tech/23/230415/asus_wan_pppoe_2.jpg)

References:

\- [Facebook wifi technology
community](https://www.facebook.com/groups/vntik/)

\-
[RT-AC1300UHP](https://cellphones.com.vn/router-wifi-bang-tan-kep-cong-suat-cao-asus-rt-ac1300uhp-mu-mimo.html)

\- [Wikipedia - Point-to-point over
Ethernet](https://en.wikipedia.org/wiki/Point-to-Point_Protocol_over_Ethernet)

\- [Why do ISPs still use PPPoATM or PPPoE instead of
802.1x?](https://www.reddit.com/r/networking/comments/t16fnc/why_do_isps_still_use_pppoatm_or_pppoe_instead_of/)

\- [What\'s Double NAT and why do I want to avoid
it?](https://www.reddit.com/r/HomeNetworking/comments/8tl0wv/whats_double_nat_and_why_do_i_want_to_avoid_it/)

\- [\[1\] Is PPPOE wan
single-threaded?](https://forum.mikrotik.com/viewtopic.php?t=156753)38:T22c1,So. Here we are. The third part of the long-running series where I try
to improve my Internet condition. So no point beating around the bushes.
I plan to transform my 4G connection into Wifi using whatever was
available to me, because I'm a cheapskate that refuse to spend money,
but had no problem spending it on a thermometer, then broke it by
putting it in a freezer. I also enjoy learning how networking works, as
I always thought that a router is like a magic box. It was when I got an
Asus router, turned on ssh that I discovered routers are all Linux
boxes.

#### Prerequisites

To prepare for this job, I dug up my old Raspberry Pi 3. I haven't had
much use for it since my HP laptop took over the server work from the
board. It has 4 USB port and a LAN port. My plan was to turn this board
into a router. Just a router, not one of those combo things that you
commonly find. The LAN port would be connected to a Wifi access point
(AP). For the USB port, I plugged a 4G USB Modem with a SIM card placed
in.

The TP-Link Archer C50 router currrently in use would be turned into AP
in place of a router. The reason was that the Raspberry Pi has a weak
Wifi chip, it couldn't transmit very far, not like a dedicated device
would. Moreover, I didn't need its routing function.

The 4G USB Modem would be a Sony Xperia Z. I borrowed it for this job
because it wasn't in use and it could install a custom ROM or OS, free
from restrictions of the original ROM. I used Lineage OS 16, which was
Android 9 for the phone. Android 9 and later allows you to set your
phone to USB tethering mode as default anytime it is connected via USB.

A 4GB or higher micro SD card was needed to install a router OS of your
choice. In this case, OpenWrt.

Location. You need to get as close as possible to a cell tower from your
house. This would require you to use a phone with the SIM card you want
to use as the source to find a cell tower that belongs to the SIM
network. You can check signal strength by going to Settings -\> About
phone -\> SIM Status or something similar. Keep an eye on the negative
number and dBm. The higher the number (lower number in negative) the
better the signal. You can also use speedtest.net or fast.com to make a
quick speed test.

#### Preparing the router

![](/images/blog/Tech/23/230413/pi_router/OpenWrt_Logo.svg)

The reason I chose OpenWrt for my router OS is that, while it's
intriguing to DIY by using Raspbian and set everything up using iptables
for NAT, ufw for firewall, dnsmasq for DNS, DHCP, it's a lot of work to
set it up separately. Instead, OpenWrt offers a web UI (luci) to help
you set everything up quickly. I also wanted to try it out on a real
scenario, as before this I ran it on my virtual machine to get a feel of
the OS.

Go to the download page of OpenWrt, get the latest version, with target
as bcm27xx -\> bcm2710 (Raspberry Pi 3 SoC). They offer 2 choice,
ext4-factory or squashfs-factory. I chose ext4 due to ease of use, as I
can use GParted to expand the data partition to full. squashfs takes
more steps, and has to be done in terminal. I might try out squashfs
version later, because that's the version normally used in modified
routers. After downloading the gzip file, extract it to get the image
(img) file. Use either balenaEtcher or dd command to flash it to the SD
card (sda in this example):

*dd if=openwrt.img of=/dev/sda bs=1M*

After that, put the card in the Pi, plug in the power and boot it
up.Connect to your Pi using LAN and open the browser, type in
[http://192.168.1.1/](http://192.168.1.1/) (default IP of the LAN interface) with username
root, no password to enter OpenWrt management.

![](/images/blog/Tech/23/230413/pi_router/1.jpg)

First, we need to install some additional packages. Go to Network -\>
Wireless. Press Scan on a wireless interface to connect to an access
point.

![](/images/blog/Tech/23/230413/pi_router/8.jpg)

![](/images/blog/Tech/23/230413/pi_router/9.jpg)

![](/images/blog/Tech/23/230413/pi_router/10.jpg)

Type in password of that Wifi AP and submit. On the next page, you can
just press Save, as that page only matters when you create an AP from
this board. Press Save & Apply. Now go to Network -\> Interfaces. You
should see another interface added in.

![](/images/blog/Tech/23/230413/pi_router/11.jpg)

Now go to System -\> Software and update lists. You have to do this at
every restart when you want to install new packages.

![](/images/blog/Tech/23/230413/pi_router/7.jpg)

You need to install these packages to use the 4G USB Modem, in this case
an Android phone.

#### Preparing the access point

![](/images/blog/Tech/23/230413/config_ac50_dhcp.jpg)

There are 2 ways around this. Either set this router into Access Point
mode, or you can turn off DHCP Server, which is a function that hands
out IP address to devices connecting to it. I chose the latter, because
I never had much luck with the former. Every time I try putting a router
into AP mode, I end up resetting it at the end due to not being able to
access its configuration page. But you do you.

After that, use an Ethernet cable, connect Raspberry Pi to any LAN port
on the TP-Link router, or either LAN / WAN if you choose AP mode.

#### Finding place to put the "combo" device

As I previously mentioned, location is important when it comes to 4G
connection. In my case, the house is situated near a cell tower, right
outside the kitchen's window.

![](/images/blog/Tech/23/230413/anten.jpg)

So the obvious answer is to place the router, the access point, the
modem in the kitchen, right? Well, yeah. I put the combo in a chair at
first, and also tried to elevate the phone using the Pi as leverage.
That way the phone could get the best signal. It was a sight to behold.

![](/images/blog/Tech/23/230413/combo.jpg)

2 weeks after that, I got a dock to prop the phone up properly so it
looked more professional and moved the combo to the top of the fridge,
closer to the cell tower. By placing it there, I got -89 dBm, as opposed
to -95 dBm on the chair. It was not much, because this was an old phone,
but good enough to work.

![](/images/blog/Tech/23/230413/phone_fridge.jpg)

#### Getting the router to connect to the Internet

Plugging the phone to the Raspberry Pi, I had to register the phone as a
network interface on OpenWrt. Go to Network -\> Interfaces. Click Add
New Interface. Name the interface. Choose DHCP client as protocol,
because you will get IP address from the USB-tethered phone. In device,
choose usb0 and click Create Interface. On the next screen, pick
Firewall Settings, assign the interface to wan zone then Save. After
that, click Save & Apply. So instead of cable Internet, I connected to
the Internet via 4G network.

![](/images/blog/Tech/23/230413/pi_router/3.jpg)

![](/images/blog/Tech/23/230413/pi_router/5.jpg)

If you prefer to use your custom DNS, go to 4G interface, Advanced
Settings, uncheck Use DNS servers advertised by peer. Then go to Network
-\> DHCP and DNS. Fill in your desired DNS in DNS forwardings (remember
to press plus) then Save & Apply.

![](/images/blog/Tech/23/230413/pi_router/12.jpg)

#### Result

So far so good. It worked like a dream. The Internet was a lot better.
And thanks to the Raspberry Pi having a better CPU than most routers, it
could withstand more clients connecting to the network and route better.
On early morning or late night, I could get up to 80 Mbps download.
Speed is inconsistent throughout the day, ranging from 15 to 50 Mbps.
But overall, it's more stable than the cable Internet.

#### Improvements

About 3 weeks into the project, I swapped the phone for a 4G USB Modem,
because doing this heated up the phone considerably and had a negative
impact to its battery. It's a cheap no-name one because I wasn't gonna
fully commit to this project. It also improved signal strength, getting
it up to -76 dBm.

![](/images/blog/Tech/23/230413/IMG_20230410_103017_860.jpg)

![](/images/blog/Tech/23/230413/4g_router/4g_1.2.jpg)

I also slowly phased out the TP-Link + Pi combo in favor of a Xiaomi Mi
WiFi R3G v1. It's a router with MT7621 SoC with dual-core 880 MHz MIPS
processor, 256 MB RAM, 128MB ROM. Compared to Raspberry Pi, it's like
David vs Goliath. But it does feature hardware routing capability, so
that's neat. It runs OpenWrt with 4G USB Modem support, so I could plug
the USB Modem in and be done with it. Same performance with 1 less
device to worry about.

![](/images/blog/Tech/23/230413/IMG_20230411_083037_638.jpg)

References:

\- [OpenWrt Downloads](https://downloads.openwrt.org/)

\- [balenaEtcher](https://www.balena.io/etcher)

\- [LineageOS 16.0 for Xperia
Z](https://forum.xda-developers.com/t/rom-final-9-0-lineageos-16-0-for-xperia-z.3924175/)

\- [Raspberry Pi 3 Model
B+](https://www.raspberrypi.com/products/raspberry-pi-3-model-b-plus/)

\- [Xiaomi Mi WiFi R3G](https://openwrt.org/toh/xiaomi/mir3g)39:T269d,There seems to be confusions surrounding common devices the Internet
service provider (ISP) gives. A lot of terms get thrown around: modem,
wireless router, 5 GHz, 1200 Mbps\... I want to offer my assistance to
help alleviate this problem.

#### Modem

If you were born before the explosion of the Internet, you would
encounter this device before, or at least know what it did to your
telephone line when you were on the Internet.

![](/images/blog/Tech/23/230404/usr815668d-56k-message-modem.jpg)

A modem is a modulator/demodulator unit, responsible for converting data
from digital signal into analog one. Digital data usually goes inside
the device, where as analog ones happen outside, on transmission like
phone line, fiber, coaxial cable. The unit seen on the picture is a
dial-up modem, used to connect a computer to the Internet via telephone
line, the same line you use to call another telephone. The dial-up modem
dials to a specific phone number (ex: 1269 back in my day), performs
handshake with the ISP's modem, and finally start transmitting data
between themselves. During this time, you can't use the telephone,
because the modem has already taken it.

[https://www.youtube.com/embed/bgTxFLHcuKc?si=V1IbEYuKT28f9yqF](https://www.youtube.com/embed/bgTxFLHcuKc?si=V1IbEYuKT28f9yqF)

Later, people were able to utilize frequency bands above the band used
for telephone. That gave birth to ADSL, or Asymmetrical Digital
Subscriber Line. With a DSL filter, often called splitter, the frequency
bands are isolated, permitting a single telephone line to be used for
both ADSL service and telephone calls at the same time as 2 lines.

![](/images/blog/Tech/23/230404/adsl-splitter.jpg)

![](/images/blog/Tech/23/230404/DSL-520B-yback.png)

Pictured above is the back of a typical ADSL modem, D-link 520b. Its
main feature is the 2 ports: DSL and LAN. As around this time, USB and
Ethernet became the standard. You plug the DSL port with the cable from
a splitter at the computer port's end, LAN to the computer. This modem
acts as both a modem, transferring data to and from ISP by the cable,
and a router, connecting the Internet to you and handing out an IP
address for your computer.

![](/images/blog/Tech/23/230404/internet-adsl-viettel.png)

Back then, it costed a fair bit of cash to have ADSL at home, so only a
handful of families got their hands on this. Still, this beat 56 kbps of
dial-up any day. The price above was from quite later as ADSL adoption
had slowed down and fiber started showing up. For my family, we paid by
MB we used, so I used to have a software that counted the MB and billed
it based on the hour of day. I often torrented at midnight because it
was cheaper then.

But then came fiber optic, or FTTH (fiber to the home). It was promised
to be the next big thing in Vietnamese Internet. For the first time, we
were able to get symmetrical speed, like 25 down 25 up, instead of 3
down 0.5 up (Mbps) like ADSL. It is increasingly important, as more
activities you can do on the Net with a larger upload speed. The ping of
fiber being lower also helps online gaming, VOIP services such as Zalo,
Messenger, Viber, Telegram won the favors of people over free voice and
video calls.

According to Quora \[1\], there seems to be answers at odds with each
other over whether Optical Network Terminal (ONT) should be called a
modem. In my humble opinion, it should be called a modem, since even
light can be considered analog. Fiber uses light as a mean to transmit
data to and from ISP.

#### Router

When I installed fiber Internet back in 2015, this is what they gave me.

![](/images/blog/Tech/23/230404/h646ew.jpg)
![](/images/blog/Tech/23/230404/h646ew_under.jpeg)

This is Dasan H646EW, a GPON ONT with 2.4 GHz Wifi. There's a lot of
conflicting information about which of the 4 ports has Gigabit Ethernet,
and which doesn't. As far as I know, port 1 has Gigabit Ethernet. The
device is once again, a combo device that is a modem + a switch (due to
4 ports present) + a router + a wireless access point.

You may be wondering why there is a separate section for routers. That
is because devices like H646EW are all collectively called routers. But
they are more like a combination of various hardware then just routers.
By definition, a router is a networking device that forwards data
packets (routes, if you will) from a computer host or network to another
computer host or network. Nowadays, they often sell wireless router
combos because they are an all-in-one, setup-and-forget solution for an
average consumer.

Due to being a jack-of-all-trade, they only do a good enough job as a
router, an access point. Anything that needs better performance, like
farther Wifi range, faster routing speed, a technical user should
consider separating each function to individual hardware. For instance,
ISP router + your own router. For better range in Wifi, ISP router +
specialized router + access points. ISP router are kept around due to
requirements from the ISP. I didn't use the ISP router and opted to use
my own. First, it's the Tenda AC10, then the TP-Link Archer C50, both
2.4/5 GHz 1200 Mbps Wifi routers. Tenda AC10 was defective so that's why
I replaced it.

![](/images/blog/Tech/23/230404/tenda-ac10.png)
![](/images/blog/Tech/23/230404/Archer-C50_UN_4.0-01_normal_1515392726561m.jpg)

The 2.4/5 GHz represents the bands that the Wifi router can broadcast,
in this case 2.4 GHz and 5 GHz. 1200 Mbps **is the aggregated speed of
both bands**:

\- 300 Mbps is from 2.4 GHz. Each antenna sends and receives signal with
a 40 MHz channel at 150 Mbps, so 2 antennae is 300 Mbps

\- Similarly, 900 Mbps is from 5 GHz. Each antenna sends and receives
signal with a 80 MHz channel at 433 Mbps, so 2 antennae is 867 Mbps,
which rounds up to 900 Mbps for marketing purposes.

\- Do note that this speed is theoretical. By using my phone, which has
1 antenna for Wifi, to test iperf3, at 2.4 GHz 40 MHz channel is around
100 Mbps, at 5 GHz 80 MHz channel is around 240 Mbps. Your mileage may
vary.

Back in 2015, my fiber speed was 25 Mbps, so with 100 Mbps WAN port it
was enough. But in 2021, with fiber reaching 150 Mbps and my server
needing faster wireless performance to serve movies around the house, it
was upgraded to the Asus RT-AC1300UHP. It has a quad core ARM CPU, which
trumps over MIPS CPU of the previous router in performance, as well as
better broadcasting range. Around this time, I joined a Facebook
community and they hinted at a possibility for a better performance if I
were to turn off routing on the modem by using what is called "Bridge
Mode". So now routing is done by the Asus router as it is connected
directly to the ISP, while the modem is simply passing the signal along.

![](/images/blog/Tech/23/230404/RT-AC1300UHP.png)

#### Converter

To put it simply, media converters terminate the fiber, turn fiber optic
signal to that of Ethernet for a single port connecting to a router. It
should not be confused with ONT because the converter has no regard for
things like IP, VLAN, MAC \[2\].

![](/images/blog/Tech/23/230404/media-converter.jpeg)

#### Cable modem

Why does this belong here? Because in Vietnam, hardly anyone wants to
use cable Internet. It feels like an afterthought of any cable service
provider. Unlike in the USA where it's one of the main ways to get
Internet with speed up to 1 Gbps, the fastest in Vietnam is with SCTV at
200 Mbps, while with Viettel you get 300 Mbps symmetrical plus TV for a
cheaper price. And the quality of Internet is cable is worse than fiber.

Cable Internet uses a standard known as DOCSIS (Data-over-Cable Service
Interface Specifications). It was developed by CableLabs. DOCSIS works
by utilizing TV channels on a coaxial cable to transfer data. Pre-DOCSIS
3.0, it was only using 1 channel for download, 1 for upload. DOCSIS 3.0
onwards can bond channels to increase bandwidth available to consumers.

![](/images/blog/Tech/23/230404/IMG_20230330_085715_959.jpg)
![](/images/blog/Tech/23/230404/docsis-bond.png)

The modem is a mplus CBC383, a Cable to Ethernet modem from Korea. It
supports 8 channels bonding downstream, 4 channels bonding upstream and
Gigabit Ethernet. Looking at its configuration page at
[http://192.168.100.1/](http://192.168.100.1/), it was clear that the modem bonded 8 channels
for downloading, 2 channels for uploading. It can run very fast, but
currently my grandparents' house is on a 50 Mbps plan from SCTV.

Some small notes:

\- I think the reasons for the poor performance of cable Internet are
company negligence and deprioritization during national Internet
bandwidth shortage.

\- Wifi, Bluetooth, your cell phone also use modems to send and receive
data.

References:

\- [Modem vs Router - What\'s the
difference?](https://www.youtube.com/watch?v=Mad4kQ5835Y)

\- [Fiber vs Cable (Coaxial) or ONT vs
Modem](https://dongknows.com/fiber-vs-cable-internet-docsis-modem-vs-ont/)

\- [Wikipedia - Modem](https://en.wikipedia.org/wiki/Modem)

\- [TP-Link Archer C50
v4](https://www.tp-link.com/vn/home-networking/wifi-router/archer-c50/v4/)

\- [Asus
RT-AC1300UHP](https://www.asus.com/networking-iot-servers/wifi-routers/asus-wifi-routers/rt-ac1300uhp/)

\- [Facebook wifi technology
community](https://www.facebook.com/groups/vntik/)

\- [Docsis 3-0 CBC383 CABLE MODEM
Specs](https://www.tradekorea.com/product/detail/P621075/Docsis-3-0-CBC383-CABLE-MODEM.html)

\- [What is DOCSIS?](https://networkshardware.com/what-is-docsis/)

\- [SCTV Price](https://www.sctv.com.vn/bang-gia-dich-vu)

\- [Viettel Fiber](https://www.viettelcapquang.vn/)

\- [\[1\] Quora - Is ONT a
modem?](https://www.quora.com/Is-the-ONT-a-modem)

\- [\[2\] Quora - Can I use a media converter + SFP to bypass using a
modem?](https://www.quora.com/Can-I-use-a-media-converter-SFP-to-bypass-using-a-modem-I-have-500mbps-fiber-optics-FTTH-What-SFP-will-work-best)3a:T260f,There is something about the idea of connecting to the World Wide Web
anytime, anywhere, on the go that always entice me. I remember staring
hours to a tiny screen of a Samsung slide phone when I was 7 because it
had 2G connection on it, and wasted 700.000 VND. It was a massive amount
of money in 2003. I had a memory in somewhere between 09 and 10 when I
was in possession of a Nokia E72 and get to use wifi for the first time.
It was like when men first discovered fire. It was magical. Of course,
being that young, I didn't think those will revolutionize the way we use
the Internet like today.

After a brief stint with using 4G on PC, I was hooked. So again I
searched the Internet whether anyone had tried something similar and
what was their experience like. I found out about a whole section of the
Internet dedicated to finding alternative ways to connect to the
Internet. A few of them are No Contract, Rural Internet subreddit on
Reddit.com. There are also XDA Developers if you have ever tried rooting
your Android phone. There is also a discussion on vozfourm or Facebook
about using 4G as substitute for home Internet.

![](/images/blog/Tech/23/230331/4g-home.png)

There are merits to using 4G as home Internet:

\- No need for home renovation due to no wire needed to run.

\- Data prioritization during national Internet bandwidth shortage. At
least in Vietnam, annually we have several times when our undersea optic
cables connecting us to the world are damaged in some ways, leading to
loss of Internet bandwidth. While fiber connection are slow, unstable,
4G connection are better due to the remaining bandwidth being preferred
for 4G over fiber.

However, **using 4G as home Internet should be considered a niche, a
temporary solution because**:

\- Cell towers are not designed to handle large traffic. If lots of
people use 4G as home Internet and downloading large amount of data, it
will eat up bandwidth of everyone else also using that cell tower on
their phones. This is much like how wifi would drop connections when
there are many devices connected, even if the uplink is fast enough to
support all. That's the reason why in large events, major conventions,
mobile cell sites are deployed on-premise to increase bandwidth
available to consumers at the location.

\- High latency makes it hard to use any applications that demand low
response time. Online gaming is out of the question, unless you are a
masochist that enjoy playing at \>80 ms ping at times. VOIP, most say it
also suffers. However, for me it actually improves, due to our network
prioritizing traffic.

\- Inconsistent speed. This largely depends on your location, distance
and obstacles to the nearest tower, tower bandwidth availability. For
example, my phone could reach 170 Mbps with a tower in my viewing
distance, but drop to 40 Mbps when it was a few kms from a nearest
tower.

\- High barrier of entry. Equipments for fiber connection like routers,
modems are quite easy to find, even given for free by the ISPs (at least
the modem), while 4G ones have to be sourced by various places, with
prices often twice of that of fiber ones.

![](/images/blog/Tech/23/230331/xe-phat-song-luu-dong-san-sang-khong-de-nghen-mang-dip-tet-2018-2.jpg)

Nevertheless, that hasn't stopped anyone from turning it to a reality.
So here are several ways to use 4G as an Internet source for your home:

#### 4G/Wifi USB Adapter

![](/images/blog/Tech/23/230331/usb-4g-wifi.jpg)
This is a device that takes a SIM, connects to the Internet via 4G and
broadcast it via 2.4 Ghz wifi. It is powered via USB, plugging to either
a charger or a portable battery. It can also be plugged into a PC,
laptop and used much like the USB Tethering function from Android.

There are 2 categories for the device:

\- Made by brand like ZTE, Huawei

\- No name or lesser known name like Olax (from ZTE), Jazz, NetMax.

The device on the picture is a no name brand. This is usually a Qualcomm
MSM8916 (Snapdragon 410) Android board repurposed to a 4G/Wifi USB
Adapter, so it behaves much like an Android phone with no screen. Some
comes with a more limited MDM9600 chipset \[1\].

Some devices don't come with wifi hotspot function, and must be plugged
to a PC to connect to the Internet.

Be cautious when using this as a hotspot. As it has to pull double duty,
connecting to the Internet via 4G (which can heat up the device
significantly) and broadcasting it via Wifi, it can break down easily.

#### Wifi Hotspot (or Mifi)

![](/images/blog/Tech/23/230331/olax-mt10.jpg)

This is a device that works similarly to the 4G USB Adapter, but it has
its own battery. I'm not sure whether this device supports USB
Tethering.

#### 4G/Wifi USB Adapter and a separate router supporting USB

![](/images/blog/Tech/23/230331/router-usb.jpg)

This is connecting the 4G USB Adapter to a router supporting Internet
connection via USB. The router must have drivers to run the USB, either
unique for the USB or the RNDIS driver, which is used by Android phones
and no name 4G USB. This way has the best chance of success if the
router is running a custom firmware, for example OpenWrt, Padavan, as
they often come with the drivers preinstalled.

#### Phone and a separate router supporting USB

![](/images/blog/Tech/23/230331/phone-router.jpg)

This is connecting an Android phone to a router supporting Internet
connection via USB. It must have the RNDIS driver preinstalled for this
way to work. Custom firmwares like OpenWrt, Padavan are recommended. It
is best to use any phone with Android 9 or later, as it has a function
that defaults its USB connection to tethering mode anytime the phone is
connected via USB to another device.

To do this, make sure your Android phone has the developer options
already turned on. If not, go to **About phone** in **Settings**, find
**Build number** and press 7 times. After that, get to **Developer
Options**. Find **Default USB configuration** in the **Networking**
category. And choose **USB tethering**. Now anytime your phone is
connected to a router via USB, it will be in tethering mode. Even in the
event of a blackout, when power returns, your phone will connect to the
router as a 4G USB Adapter.

![](/images/blog/Tech/23/230331/Screenshot_20230331-143353.png)
![](/images/blog/Tech/23/230331/Screenshot_20230331-143356.png)

#### Dedicated WWAN Box and a separate router supporting USB

![](/images/blog/Tech/23/230331/wwan-box.png)

For those hardcore enthusiasts who want to commit to 4G home Internet,
this is the option for you. This is a M.2 to USB adapter, commonly known
as WWAN Box. It takes in a M.2 WWAN card, usually found in laptop with
4G capability, and convert it to USB mode. It supports 2 external
antennae for better signal reception.

![](/images/blog/Tech/23/230331/wwan-box-inner.jpg)

Some typical M.2 WWAN Card:

\- Sierra Wireless EM7345, EM7430, EM7455

\- Quectel EC20, EC25

\- Fibocom L860

![](/images/blog/Tech/23/230331/em7455.jpg)

Some cards need re-flashing their firmware to receive your SIM properly.
You can follow Jeff Geerling's article \[3\] about that. He also talked
about the different protocols the card use to interact with the router:
QMI, MBIM, ECM\... This is important if you want to setup this card for
use in OS like Ubuntu, Raspbian.

For OpenWrt, there are packages used to interact with the card. You can
check out video \[2\], \[4\] for more information on how to setup
connection using QMI and MBIM mode.

#### Dedicated 4G Router (also called 4G network gateway)

![](/images/blog/Tech/23/230331/CPE-R311-PRO-1.jpg)

Manufacturers created these products as an all-in-one solution for 4G
home Internet. Just slot in the 4G SIM and it will create a wifi access
point for you to connect your devices. These devices are often just your
run-of-the-mill wireless router, slapped in a 4G modem chip. Here are
pictures of Tenda 4G06 disassembly, courtesy of Fccid.io. 4G06 uses
Quectel EC25 as the modem.

![](/images/blog/Tech/23/230331/Picture1.png)
![](/images/blog/Tech/23/230331/Picture2.png)
![](/images/blog/Tech/23/230331/Picture3.png)

Currently only Mobifone offers their 4G home Internet service, MobiWifi,
though they are very quiet about it. Their modem is a Huawei B311 with a
specialized SIM that only grants unlimited data to their device. The
2.4/5 GHz devices are pricier than their 2.4 GHz counterpart. I'll
advise you to buy a gateway and a router separately so that you can have
an easier time troubleshooting.

References:

\- [No Contract subreddit](https://www.reddit.com/r/NoContract/)

\- [Rural Internet subreddit](https://www.reddit.com/r/Rural_Internet/)

\- [XDA Developers Fourm](https://forum.xda-developers.com/)

\- [vozforum
4G](https://voz.vn/t/cong-dong-4g-5g-cong-nghe-di-dong-thac-mac-khoe-hang-danh-gia-cho-het-vao-day.563346/)

\- [Mobile cell sites](https://en.wikipedia.org/wiki/Mobile_cell_sites)

\- [Facebook wifi technology
community](https://www.facebook.com/groups/vntik/)

\- [WifiShop](https://wifishop.vn/)

\- [Tenda 4G06](https://www.tendacn.com/product/4g06.html)

\- [MobiWifi](https://mobiwifi.vn/)

\- [Fccid - Tenda 4G06 Internal
Photos](https://fccid.io/V7T4G06/Internal-Photos/Internal-Photos-5421535)

\- [\[1\] Hackable \$20 Modem Combines LTE And Pi Zero W2
Power](https://hackaday.com/2022/08/03/hackable-20-modem-combines-lte-and-pi-zero-w2-power/)

\- [[\[2\] Process of making WWAN Box Router
Combo]](https://www.youtube.com/watch?v=CUM87vjO9Ao)

\- [\[3\] Jeff Geerling - Using 4G LTE wireless modems on a Raspberry
Pi](https://www.jeffgeerling.com/blog/2022/using-4g-lte-wireless-modems-on-raspberry-pi)

\- [\[4\] OpenWRT - Install and Configure LTE modem in QMI
mode](https://www.youtube.com/watch?v=DRddwfZ_TBY)3b:T115a,Have you ever got a feeling that you would never go back once you tried
something that was way better than you expected? That was my feeling
once I replaced my router to an Asus one and get a taste of my fiber's
maximum speed of 150 Mbps, as opposed to 90 Mbps limited by TP-Link'
ancient hardware. Or that time I replaced my DSL connection to fiber
back in 2015. From 3 Mbps to 25 Mbps was a massive jump I couldn't
believe I didn't agree to have it earlier. But I was always a skeptic
towards new technologies.

In early 2023, I was tasked with taking care of my grandparents. So I
got some clothes, my laptop, my phone, my TV box and moved to my
grandparents' house. During this time, I was preparing my documents and
submitting them to various universities for a chance to study Masters in
the USA. And using SCTV's "excellent" Internet service was an exercise
in frustration. Every time I tried to access any web that was from the
US, it would either hang, or chug along. You would need a massive
tolerance for slowness to stand the kind of speed that makes the Chrome
(or Firefox if you're like me) tab spin round and round. I have to use
my VPN server, which is on Viettel Data Center, as a proxy to at least
mitigate it. Being used to fiber, this was unacceptable. I asked my
family to change ISP and their answer was no, which is understandable.
SCTV's cable + Internet combo monthly rate was 220.000 VND, my fiber
alone was worth that much.

Around this time, I came across an interesting offer from a new cell
company.

![](/images/blog/Tech/23/230330-2/so-sánh-mạng-internet-2g-3g-4g-5g.jpg)

I'm no stranger to using cellular network for Internet. I knew of its
existence back in the early days of Vietnamese Internet. It was 2G
network when I was 7 with my dad's Samsung slide phone. Back when it was
ridiculously expensive because there was no data plan, you were billed
by kilobyte so it was more of a novelty then a necessity like today.
I've come to use it frequently since the day I got my first my
smartphone, which was back in 2014, with my country utilizing 3G
network, superseding 2G. 4G came about in 2016 or so. The three major
cell networks: Viettel, Mobifone, Vinaphone, rolled out the carpet to
welcome the new standard. I chose Viettel at the time because as a
college student, money is pretty tight. So 30.000 VND/2,5 GB is a
reasonable data plan as I do not use social media much at the time and
Youtube could be watched at home. In 2019, iTel, a MVNO (mobile virtual
network operator) using Vinaphone as backbone, launched with a plan:
77.000 VND for 3GB per day. I only found out in 2021 through a flyer at
the post office, because MVNOs here aren't known for their massive ad
campaigns. Wanting to give it a test drive, I bought a sim and gave it
to my sister, who used Facebook more than I do. She said it was good and
didn't feel restricted by other networks' limited data caps. For
references, 3GB/day equals to 90GB/month, far exceeded anything that
were offered at the time. The other networks soon followed up with their
own monthly "data cap per day" mode like this. Then I stumbled upon a
data plan of Vinaphone: 500GB for 150.000 VND. That sounded good enough
to me, and I'm not one to pass up an offer that good. So I bought a
Vinaphone sim, replaced my aging Viettel one with it, and tested the
network. It was good, though signal is a bit weak compared to Viettel.
The data plan also comes with 5 Mbps if exceeded. I've been using
Vinaphone on my phone ever since.

Back to grandparents' Internet story. I used my phone as a hotspot and
continue my work. It was faster, around 80-150 Mbps down due to my place
near a cell tower and had a faster response to any website I visited,
especially those US university websites that were hard to get to.

I used a VSmart Live 4 with Android 11, which has an interface that is
closest to being pure Android compared to Samsung. First, you have to
turn on 4G and turn off wifi. Next, go to Settings -\> Cellular -\>
Hotspot & Tethering. And turn on Wifi hotspot or USB Tethering,
depending on your need.

![](/images/blog/Tech/23/230330-2/screen1.png)
![](/images/blog/Tech/23/230330-2/screen2.png)
![](/images/blog/Tech/23/230330-2/screen3.png)

References:

\- [The MAY Plan of
iTel](https://itel.vn/tin-tuc/tin-tuc-itel/sim-itel-goi-may)

\- [U1500 500GB SIM from
Vinaphone](https://cellphones.com.vn/sim-4g-vinaphone-u1500-500gb-thang-12-thang.html)3c:T1392,Hi, you may not know me. That's fair, this is my first blog after all.
You can call me The Testing Guy. For most of my life, computer has been
a major part of my life and my passion. I eat, sleep computer. I play
games, do homework, read news, watch Youtube on it like most people. I
have also done a lot of experiments, odd projects on computers and
various hardware throughout the years, but never documented them. May be
because of laziness, or maybe it's just easier to remember the things
you really like to do (and also the things you really hate too). After
an meeting with my friends yesterday, I have come to realize that:

\- Most of the people from my background have also done various personal
jobs like that.

\- That a lot of projects I've done sound like magic to everyone else,
including my family, despite them coming off as sometimes rather
mundane.

So today I decide to write a blog about my various adventures (and
misadventures) in past, present, and maybe future.

Like most folks around the world, in Vietnam, we watch television. In
particular, we watch it through cable. There are many cable TV providers
in Vietnam: VTV, HTVC from the government, SCTV of Saigontourist (yes, a
tourism company is also a cable provider), VTC. There are ISP like FPT,
Viettel, VNPT who also wanted a piece of television business and started
jumping in. My family chose SCTV, because it was one of the first
companies to provide cable TV, and has stuck with them since. My
grandparents also chose them as the cable provider, along with the
Internet service they provide as a combo. The reason for the included
Internet is that on weekends, we visit our grandparents and need some
connectivity for our Facebook and Youtube video consumption. My cousin,
who is working towards her college degree, also lives with our
grandparents and needs Internet to do her homework. Their speed is about
35 Mbps symmetrical (up and down speed is the same), which is not much
compared to my fiber at home, 150 Mbps symmetrical, but is good enough
for the purpose. They provided us a router and a modem.

![](/images/blog/Tech/23/230330-1/IMG_20230330_085715_959.jpg)

![](/images/blog/Tech/23/230330-1/IMG_20230303_143405_861.jpg)

According to my findings, the modem is a mplus CBC383, a Cable to
Ethernet modem from Korea. And the router is a standard-issue TP-Link
TL-WR841N, a 2.4Ghz 300 Mbps Wifi router you'll likely find cheap at a
used market somewhere.

SCTV installed it for us and it was working. So all is right with the
world. Or is it? A common wisdom I picked up over the years as a
somewhat network enthusiast is that you should never use any equipment
provided by your ISP. That proved to be true in this case. We installed
the Internet portion back in 2019. During its lifetime, I have cursed it
numerous time as it disconnected, it hung, forcing everyone to use 4g
from their phones as substitute more than once. I did try to go into the
configuration page of the router to change and/or reset it (the modem's
is inaccessible). So by 2022, I had enough. I decided to replace the
TP-Link one with another one from my house. That one was previously
replaced by an Asus router.

![](/images/blog/Tech/23/230330-1/Archer-C50_UN_4.0-01_normal_1515392726561m.jpg)

This is the TP-Link Archer C50, a 2.4/5 GHz 1200 Mbps Wifi router.
Anyone reading the specs might find that it only has a 100 Mbps WAN for
my 150 Mbps fiber. The story is I bought this back in 2014 as a
replacement for a Tenda router. After replacing this with an Asus one,
Mr. Archer is left without a job. So I gave him a new one. Because the
Internet of SCTV is only 35Mbps symmetrical, it's a non-issue.

I pulled the plug out of the WR841N, installed Mr. Archer in by plugging
the ethernet cable from the modem to the WAN port, access the router's
configuration page and change the wifi's name to match the previous
router's settings and done.

![](/images/blog/Tech/23/230330-1/config-ac50-ap.jpg)

Fast forward a month, the Internet at my grandparents' house has
improved dramatically. Of course there were hiccups here and there while
browsing Facebook. I figured it was because I hadn't put something in
correctly so back to the config page I went. This time to DNS Settings.

![](/images/blog/Tech/23/230330-1/config-ac50-dhcp.jpg)

I first tried Google DNS (8.8.8.8), because that's the first that comes
to anyone's mind whenever they think their Internet is slow. A short
while later I changed it to Cloudflare DNS (1.1.1.1) because when I ping
it, response time was 17 ms, much faster than Google's \>60 ms. It did
improve the situation, and made the Internet a bit smoother overall.

References:

\- [Docsis 3-0 CBC383 CABLE MODEM
Specs](https://www.tradekorea.com/product/detail/P621075/Docsis-3-0-CBC383-CABLE-MODEM.html)

\- [TP-Link
TL-WR841N](https://www.tp-link.com/vn/home-networking/wifi-router/tl-wr841n/#specifications)

\- [TP-Link Archer C50
v4](https://www.tp-link.com/vn/home-networking/wifi-router/archer-c50/v4/)0:["bB_dy8pqBnRs1hZv6AeEb",[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",{"children":["__PAGE__",{},[["$L1",["$","section",null,{"children":[["$","h1",null,{"className":"mb-8 text-2xl font-semibold tracking-tighter","children":"Brian Phan"}],["$","section",null,{"className":"flex flex-col md:flex-row mb-8 home-section","children":[["$","section",null,{"className":"mr-4","style":{"flex":1},"children":["$","img",null,{"src":"/images/about/portrait.jpg"}]}],["$","section",null,{"style":{"flex":2,"marginLeft":"1rem"},"children":[["$","p",null,{"className":"mb-4","children":["$","span",null,{"children":[["$","span",null,{"className":"italic","children":"”It is possible to commit no mistakes and still lose. That is not a weakness. That is life.\""}]," Captain Jean-Luc Picard"]}]}],["$","p",null,{"className":"mb-4","children":"I’m a full stack software developer who loves turning ideas into web applications that just work. I thrive on collaborating with teams to deliver reliable, high-performance solutions that users enjoy. Curious by nature, I’m always learning and experimenting through hands-on projects, and I see every challenge as a chance to discover something new."}],["$","u",null,{"children":["$","a",null,{"href":"/projects","children":"Check out my projects here."}]}],["$","br",null,{}],["$","u",null,{"children":["$","a",null,{"href":"https://github.com/bachsofttrick/","target":"_blank","children":"How about my GitHub?"}]}],["$","br",null,{}],["$","u",null,{"children":["$","a",null,{"href":"https://youtu.be/cgm2bytuO4g?si=EoEU9nAvUmxESRn1&t=153","target":"_blank","children":"Check out my OSU advertisement."}]}]]}]]}],["$","h1",null,{"className":"mb-4 text-l font-semibold tracking-tighter","children":"Recent blog posts"}],["$","$L2",null,{"allBlogs":[{"metadata":{"title":"OCR web project with Claude Code","publishedAt":"2026-01-04","order":1,"hidden":false},"slug":"260104","category":"Tech","content":"$3"},{"metadata":{"title":"GraphQL is good, within reasons. And also dependency injection","publishedAt":"2026-01-01","order":2,"hidden":false},"slug":"260101-2","category":"Tech","content":"$4"},{"metadata":{"title":"mod_wsgi not working with OpenSSL","publishedAt":"2026-01-01","order":1,"hidden":false},"slug":"260101","category":"Tech","content":"$5"},{"metadata":{"title":"How to cook rice like an expensive rice cooker","publishedAt":"2025-12-25","order":1,"hidden":false},"slug":"251225","category":"Cooking","content":"It's something I learned while researching my friend's luxury rice cooker. It was a \n[Zojirushi NS-ZCC10 5-1/2-Cup Neuro Fuzzy Rice Cooker](https://www.amazon.com/Zojirushi-NS-ZCC10-Uncooked-Premium-1-0-Liter/dp/B00007J5U7). He got it cheap, I think\nabout 100 dollars. But it always makes perfect rice, similar to the one rice cooker\nI got back home. I only got a 20-dollar Aroma rice cooker so I adapted a recipe found\nonline. The way the cheap rice cooker emulates cooking good rice is as follows:\n- Rice (after having washed off the starch) will be sitting in water for 15 minutes.\n- Afterwards, it will be cooked for 20-25 minutes. This is the part where *you plug in the cooker*.\n- Profit.\n\nAll these steps are automatic in the expensive rice cooker. Plus, temperature is adjusted according\nto a sensor to make the best cooked rice. But through these three steps, I can come close to it\nwith just a cheap one."},{"metadata":{"title":"The effect of frying","publishedAt":"2025-12-11","order":1,"hidden":false},"slug":"251211","category":"Cooking","content":"$6"},{"metadata":{"title":"I found gold at Goodwill","publishedAt":"2025-12-11","order":1,"hidden":false},"slug":"251211","category":"Tech","content":"![](/images/blog/Tech/25/251211/radio.jpg)\n\nDid you see the picture? This is Panasonic RX-C36. It was released in the 1980s. I called it the\n\"Say Anything boombox\", referencing that one scene where John Cusack's character held a boombox\nabove his head in front of the his girlfriend's house. When I plugged the radio in, it sounded like\nnothing I have ever heard before from a casette stereo. It was full, warm, booming. And that was\non radio only. It was that good for only 15 dollars. Sadly I couldn't buy it. I don't intend to stick\naround here for long, and having a big stereo around feels like a waste for me. It's hard to move\naround, hard to sell. So I ended up with a smaller GPX R633B. Not as good, but at least better than\nmy crappy free CD stereo I got two years ago. I only need a FM radio, anyway."},{"metadata":{"title":"Some tips I learned from a few hundred applications","publishedAt":"2025-11-28","order":1,"hidden":false},"slug":"251128","category":"Tech","content":"$7"},{"metadata":{"title":"Trying frozen pizza","publishedAt":"2025-11-26"},"slug":"251126","category":"Cooking","content":"$8"},{"metadata":{"title":"MySQL parseSlowQuery","publishedAt":"2025-11-23","order":2,"hidden":false},"slug":"251123-2","category":"Tech","content":"I want to give you my new tool. It reads the MySQL slow_query_log and sorts the queries\naccording to their query time in descending order. It later outputs to JSON and CSV file.\n\nGet it [here](https://github.com/bachsofttrick/mysql-parseSlowQuery)."},{"metadata":{"title":"Chicken Rice","publishedAt":"2025-11-23","order":1,"hidden":false},"slug":"251123","category":"Cooking","content":"$9"},{"metadata":{"title":"Bypass Websites that Block Copy/Paste in Input Fields","publishedAt":"2025-11-23","order":1,"hidden":false},"slug":"251123","category":"Tech","content":"Do you find it annoying that some companies put a block on copy/paste on some input fields.\nUnderstandable if it is a password retype, not so much for email retype. I guess it is to\ndouble check for correctness, but it is a hell of annoyance for someone who needs to do\nthings quickly.\nI found two ways to fix this:\n- Select All (or Ctrl+A) the entire content, then drag to the input field that blocks\ncopy/paste.\n- This one is for [Firefox](https://old.reddit.com/r/LifeProTips/comments/1exi6ub/lpt_how_to_bypass_websites_that_block_copypaste/), access `about:config` and change `dom.event.clipboardevents.enabled` to `false`."},{"metadata":{"title":"Breaking changes on Docker 29 and how to postpone it","publishedAt":"2025-11-20"},"slug":"251120","category":"Tech","content":"$a"},{"metadata":{"title":"Short tip on importing a large dataset to MySQL","publishedAt":"2025-11-16"},"slug":"251116","category":"Tech","content":"As I was working on improving the uploading process of my place's web page, I saw the way they handled uploading \na large dataset:\n```\nSET autocommit=0;\nSET unique_checks=0;\nSET foreign_key_checks=0;\n[do import here]\nCOMMIT;\nSET autocommit=1;\nSET unique_checks=1;\nSET foreign_key_checks=1;\n```\nThis is for mainly two reasons:\n- Avoiding unnecessary constraint checks during the import.\n- Allowing bulk inserts in a single transaction.\nBut this also means that you have to make sure the data is clean and doesn't have duplicate rows. Because MySQL won't\ncheck it for you."},{"metadata":{"title":"watch with colors","publishedAt":"2025-11-09","order":2},"slug":"251109-2","category":"Tech","content":"After the previous long post, this one is shorter.\n\nI was reading this [post](https://truelogic.org/wordpress/2024/08/14/installing-llama-cpp-on-ubuntu-with-an-nvidia-gpu/).\nAnd wanted to use `gpustat` as a way to continuously view GPU utilization. But using `watch -n1 gpustat` would wash\naway the colors. And using `-c` was not helping. Luckily, lol (yes, that's a handle) had a solution on [Stack Overflow](https://stackoverflow.com/questions/3793126/colors-with-unix-command-watch). It was to use `unbuffer` from `expect` \npackage. So it's `watch -n1 -c unbuffer gpustat` and it will show colors."},{"metadata":{"title":"Getting Nvidia GPU to work in Docker container: A Cursed Experience","publishedAt":"2025-11-09"},"slug":"251109","category":"Tech","content":"$b"},{"metadata":{"title":"DIY GPT","publishedAt":"2025-11-05"},"slug":"251105","category":"Tech","content":"$c"},{"metadata":{"title":"Silicone spatula for stainless steel pan","publishedAt":"2025-11-03"},"slug":"251103","category":"Cooking","content":"I have been using a silicone spatula as a challenge for my frying pan. Normally when I cook, I use a stainless\nspatula, because stainless steel pans can generally take a beating. That is why we bought them. But I figured,\nusing a silicone one is harder. There is no way to scrape hard bits off the pan, because the silicone is\nelastic, not hard like metal. So it will take a skillful pan user to use this new spatula as a scraper of\nfond. After a couple of tries, I did it. I used this to fold eggs, stir fry meat, scrape fond of the bottom\nof the pan easily. It's just in the heat, that's all. Nowadays, I use the silicone spatula extensively\nbecause it is much easier to clean than the stainless steel, which food tends to stick, or wood, which\nleaves smell and oil in wood fiber and is hard to clean.\n\n![](/images/blog/Cooking/25/251103/spatula.jpg)"},{"metadata":{"title":"Testing a new way to make glazed or sauced dishes","publishedAt":"2025-10-31"},"slug":"251031","category":"Cooking","content":"$d"},{"metadata":{"title":"Some videos on how Chinese-American dishes are made","publishedAt":"2025-10-25"},"slug":"251025","category":"Cooking","content":"$e"},{"metadata":{"title":"Some tricks for MySQL I learned","publishedAt":"2025-10-24","order":2},"slug":"251024-2","category":"Tech","content":"- innodb_buffer_pool_size should be given 50% to 80% of total RAM. So that more tables could be cached in RAM, reducing\nchances of using hard drive and slowing down queries.\n- \"Write-heavy tables should not use index\" is a lousy statement. One of the fixes a team discovered to enhance an upload\nprocess speed is putting two indexes in a column to be used in an UPDATE JOIN statement. It SLAHSED the time taken by\n99%. It doesn't mean to put indexes in every column, in every table. **Test and verify.**\n- If you have SELECT ... WHERE a = AND b =, index (a, b) is better than index a and index b separate. INDEX JOIN is\nexpensive.\n- MySQL slow query log should be turned on to monitor for any slow queries. As with caching, or saving precomputed\nresults of commonly used queries.\n- EXPLAIN and ANALYZE are your best friend. EXPLAIN will tell you what the database plans to do, while ANALYZE will\nrun the query AND explain what it did."},{"metadata":{"title":"PHP: First Steps","publishedAt":"2025-10-24","order":1},"slug":"251024-1","category":"Tech","content":"$f"},{"metadata":{"title":"Stir fry cheat sheet","publishedAt":"2025-08-31"},"slug":"250831","category":"Cooking","content":"Source: [https://reddit.com/r/food/comments/425rm7/stirfry_cheat_sheet/](https://old.reddit.com/r/food/comments/425rm7/stirfry_cheat_sheet/)\n\n![](/images/blog/Cooking/25/250831/stir-fry-cheat-sheet.png)"},{"metadata":{"title":"Cánh gà chiên nước mắm","publishedAt":"2025-08-22"},"slug":"250822","category":"Cooking","content":"$10"},{"metadata":{"title":"Finally, stainless steel pan worked","publishedAt":"2025-08-21"},"slug":"250821","category":"Cooking","content":"$11"},{"metadata":{"title":"Right place, right time","publishedAt":"2025-08-01"},"slug":"250801","category":"Life","content":"$12"},{"metadata":{"title":"How does a 1000W portable burner beat a $600 electric range?","publishedAt":"2025-07-12"},"slug":"250712","category":"Cooking","content":"$13"},{"metadata":{"title":"Dependency Injection I learned from .NET Core","publishedAt":"2025-07-07"},"slug":"250707","category":"Tech","content":"$14"},{"metadata":{"title":"Cooking rice with pot","publishedAt":"2025-07-01","order":2},"slug":"250701-2","category":"Cooking","content":"$15"},{"metadata":{"title":"Update on stainless steel pan and egg","publishedAt":"2025-07-01","order":1},"slug":"250701-1","category":"Cooking","content":"$16"},{"metadata":{"title":"Purge residual config packages on Debian and Ubuntu","publishedAt":"2025-06-21"},"slug":"250621","category":"Tech","content":"This article follows this [post](https://kitson-consulting.co.uk/blog/apt-dpkg-purge-rc-packages).\n\nI upgraded my Linux system today, from Lubuntu 22.04 to Lubuntu 24.04. So far, the upgrade was smooth, I haven't \nencountered any errors. Except when upgrading version, they replaced many apps with the new version's equivalents.\nSo many old apps were uninstalled and stuck at [residual-config].\nSo a way to solve this is through apt-get tool from Ubuntu and Debian.\n\nTo list packages that have been removed but still have configuration files left behind:\n```\napt list '~c'\n```\nTo remove the configuration files for packages that are no longer installed:\n```\napt purge '~c'\n```"},{"metadata":{"title":"Vegan cheese","publishedAt":"2025-06-20"},"slug":"250620","category":"Cooking","content":"$17"},{"metadata":{"title":"Roku TV Secret menu for channel scan","publishedAt":"2025-06-13"},"slug":"250613","category":"Tech","content":"This article follows this [post](https://www.avsforum.com/threads/special-roku-menu-to-see-antenna-ota-signal-strength.3282481/).\n\nOn the Roku remote when on the main default screen, press the following to reach the \"Tuner Secret Screen\":\n```\nHome, Home, Home, Home, up, right, down, up, left, right\n```"},{"metadata":{"title":"Rant about stainless steel pans","publishedAt":"2025-06-11"},"slug":"250611","category":"Cooking","content":"I have done a lot of cooking for a decade now. And recently, I have been trying effortlessly to make stainless steel\npan (chảo inox) work with my egg, i.e. not making eggs stick on my steel pan.\n\nI keep hearing about the Leidenfrost effect. It is characterized by having water contain itself in a form of bubbles\nwhen the pan is heated to 400 degree Farenheit. But my stove takes a long time to heat up. It takes 5 minutes for the Leidenfrost effect to show up when heating up at medium or medium-low temp. And even then, I'm not sure it was that effect since water formed little bubbles and some fizzled out. Even after applying oil, reducing the temperature to low, adding\nan egg in and it would stick. It was hard to pry it off the surface of the pan.\n\nSo I give up on eggs. They do make nice, crunchy steak, so at least there are some benefits to having a stainless steel\npan."},{"metadata":{"title":"Bypass logging in using Microsoft account in Windows 11","publishedAt":"2025-06-10"},"slug":"250610","category":"Tech","content":"This article follows this [article](https://www.windowscentral.com/software-apps/windows-11/an-even-better-microsoft-account-bypass-for-windows-11-has-already-been-discovered).\nA lot of time I install Windows 11, not only do I have to get through the TPM requirement, I also have to find a \nway to get through not logging in to my Microsoft account and set up a local account. Back then, the 'no@thankyou.com' email and whatever password worked. Then when that didn't work, I used\n```\noobe\\bypassnro\n```\nAnd now, those don't work anymore.\n![](/images/blog/Tech/25/250610/1.png)\nSo somebody discovered a new way, or at least it has existed for a while. I just\ncover it here, so I remember. I use this blog as a sort-of notebook to remember things as well.\n```\nstart ms-cxh:localonly\n```\nAnd it launched a Windows 10 style new account screen.\n![](/images/blog/Tech/25/250610/2.png)\nI created a new account and press Next. Everything proceeded as normal."},{"metadata":{"title":"Switch between multiple Java version","publishedAt":"2025-06-09"},"slug":"250609","category":"Tech","content":"$18"},{"metadata":{"title":"Multiprocessing bug in Python","publishedAt":"2025-05-26"},"slug":"250526","category":"Tech","content":"$19"},{"metadata":{"title":"The younger generation is going backward in tech literacy?","publishedAt":"2025-03-21"},"slug":"250321","category":"Tech","content":"$1a"},{"metadata":{"title":"Running Windows games on Linux","publishedAt":"2024-12-21"},"slug":"241221","category":"Tech","content":"$1b"},{"metadata":{"title":"Review: The Wild Robot","publishedAt":"2024-11-12"},"slug":"241112","category":"Film","content":"$1c"},{"metadata":{"title":"Getting into a new hobby: Taking pictures","publishedAt":"2024-11-11"},"slug":"241111","category":"Photography","content":"$1d"},{"metadata":{"title":"Install Windows 11 without the hassle of TPM","publishedAt":"2024-10-22"},"slug":"241022","category":"Tech","content":"These are the little tips I collected from reading various articles online, the Rufus source code, [credit to Pete Batard](https://github.com/pbatard/rufus), and installing Windows 11 more times than I could count.\n- Bypass Windows 11 minimum requirement:  \n*HKEY\\_LOCAL\\_MACHINE\\\\SYSTEM\\\\Setup\\\\*  \nCreate LabConfig key. Go inside, create BypassTPMCheck, BypassSecureBootCheck, BypassRAMCheck, BypassCPUCheck\nDWORD Value, set it to 1.\n- Get local account during initial setup (only for Windows 11 Pro):  \nMake sure to disconnect the machine from Internet (hopefully there is no Wifi onboard or this won't work).\nPress Shift + F10, type in Command Prompt *regedit*.  \n*HKEY\\_LOCAL\\_MACHINE\\\\SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\OOBE\\\\*  \nCreate BypassNRO DWORD Value, set it to 1.\n- Limit the amount of preinstalled apps when installing Windows 11:  \nDuring setup on USB, select region as *English (World)*, **DO NOT SELECT English (United States)**."},{"metadata":{"title":"Virtualization on my server without reinstalling OS","publishedAt":"2024-10-19"},"slug":"241019","category":"Tech","content":"$1e"},{"metadata":{"title":"Disable Intel Turbo Boost to cool my laptop","publishedAt":"2024-10-18"},"slug":"241018","category":"Tech","content":"$1f"},{"metadata":{"title":"Sudo and SMB run slower after changing server name","publishedAt":"2024-10-07"},"slug":"241007","category":"Tech","content":"$20"},{"metadata":{"title":"Rant about cloning Windows disk from SATA to NVMe","publishedAt":"2024-10-05"},"slug":"241005","category":"Tech","content":"$21"},{"metadata":{"title":"Why does it take so long to delete in Lubuntu file explorer (PCManQt)?","publishedAt":"2024-09-29"},"slug":"240929","category":"Tech","content":"$22"},{"metadata":{"title":"How to clear \"Recent Connections\" auto-connect-profiles list in Blueman","publishedAt":"2024-09-26"},"slug":"240926","category":"Tech","content":"This is one of those shorter posts on my blog. Sometimes, you don't feel like \ntalking a whole lot. You'll be seeing many more of these.\n\nAnyway, this post today applies for Blueman, Bluetooth manager on my Linux OS, \nLubuntu. I couldn't find how to remove an option from Recent Connections. That \ngreyed out option kept me up at night, annoying me. I tried uninstalling Blueman, \nthen reinstalled it. THe greyed out option was still there. So a quick bit of \nsearch led me to this [Github Issue](https://github.com/blueman-project/blueman/issues/1450).\n\nThe issue said I had to run this command and it would clear all recent connection from the menu.\n```\ngsettings reset org.blueman.plugins.recentconns recent-connections\n```\nIt did work. And now I'm writing this here to immortalize it."},{"metadata":{"title":"The more things change, ...","publishedAt":"2024-09-07"},"slug":"240907","category":"Tech","content":"... the more they stay the same. Right now, it happens in web technologies. Back in the \nearly days of the Internet, it was static HTML pages, sprinkle a bit of CSS and called it\na day. Then Javascript came along for more interactivity. People wanted more, so came PHP\nfor that dynamic web pages. PHP kickstarted the server-side rendering motive of web for years\nto come. There was also ASPX. When I started working around 2020, it was the time of Javascript\nframeworks. React, Vue, Svelte... you name it. Building Single Page Application was the bee's knee.\nAnd then comes your NextJS, Nuxt, 11ty, Astro... Even PHP-based content management systems (CMS)\nsuch as Wordpress have never left. It seems things a lot of times come full-circle, don't they?\nIt's like trends. Go out of fashion, then give it a decade, and it comes back. The 80s nostalgia\n, big movie franchises, fat vs oil health debacle.\n\n*\"plus ça change, plus c'est la même chose.\"* Jean-Baptiste Alphonse Karr"},{"metadata":{"title":"A different mindset","publishedAt":"2024-09-06"},"slug":"240906","category":"Tech","content":"$23"},{"metadata":{"title":"\"Perhaps I treated you too harshly\". Reflection on .NET as a back end framework","publishedAt":"2024-09-02","order":3},"slug":"240902-3","category":"Tech","content":"$24"},{"metadata":{"title":"Windows S Mode","publishedAt":"2024-09-02","order":2},"slug":"240902-2","category":"Tech","content":"$25"},{"metadata":{"title":"Remote Server behind CGNAT using Wireguard","publishedAt":"2024-09-02","order":1},"slug":"240902-1","category":"Tech","content":"$26"},{"metadata":{"title":"My thought on Chromebook","publishedAt":"2023-10-11"},"slug":"231011","category":"Tech","content":"$27"},{"metadata":{"title":"Convert BIOS to UEFI for Linux (or how to recover GRUB)","publishedAt":"2023-08-23","order":3},"slug":"230823-3","category":"Tech","content":"$28"},{"metadata":{"title":"Fedora: What I learned","publishedAt":"2023-08-23","order":2},"slug":"230823-2","category":"Tech","content":"$29"},{"metadata":{"title":"Trying Windows 11 and other OSes","publishedAt":"2023-08-23","order":1},"slug":"230823-1","category":"Tech","content":"$2a"},{"metadata":{"title":"Cross compiling driver for Raspberry Pi","publishedAt":"2023-07-22"},"slug":"230722","category":"Tech","content":"$2b"},{"metadata":{"title":"Custom resolution for GTX 1060 on Lubuntu","publishedAt":"2023-07-21"},"slug":"230721","category":"Tech","content":"$2c"},{"metadata":{"title":"The times I dealt with phones that have multiple models","publishedAt":"2023-07-07"},"slug":"230707","category":"Tech","content":"$2d"},{"metadata":{"title":"Patching OpenWrt with a new driver","publishedAt":"2023-06-23"},"slug":"230623","category":"Tech","content":"$2e"},{"metadata":{"title":"Trying a new kernel and compiling network driver from it","publishedAt":"2023-06-14"},"slug":"230614","category":"Tech","content":"$2f"},{"metadata":{"title":"Getting my blog on Google Search","publishedAt":"2023-06-10"},"slug":"230610","category":"Tech","content":"$30"},{"metadata":{"title":"Install Firefox as deb instead of snap on Ubuntu","publishedAt":"2023-06-09"},"slug":"230609","category":"Tech","content":"$31"},{"metadata":{"title":"YouTube: The beginning of the end","publishedAt":"2023-05-23"},"slug":"230511","category":"Tech","content":"$32"},{"metadata":{"title":"Compile OpenWrt for Orange Pi R1 Plus LTS","publishedAt":"2023-05-23"},"slug":"230523","category":"Tech","content":"$33"},{"metadata":{"title":"On the proverb \"If it ain't broke don't fix it\"","publishedAt":"2023-05-06"},"slug":"230506","category":"Tech","content":"$34"},{"metadata":{"title":"Auto build driver when updating Linux kernel with dkms","publishedAt":"2023-05-04"},"slug":"230504","category":"Tech","content":"$35"},{"metadata":{"title":"Data plan investigation: Zero-rating","publishedAt":"2023-04-27"},"slug":"230427","category":"Tech","content":"$36"},{"metadata":{"title":"Enhance network performance by bridging my modem to my router","publishedAt":"2023-04-15"},"slug":"230415","category":"Tech","content":"$37"},{"metadata":{"title":"Upgrading Grandparents' Wifi III: Covering the house in new Wifi","publishedAt":"2023-04-13"},"slug":"230413","category":"Tech","content":"$38"},{"metadata":{"title":"Modems, routers and converters","publishedAt":"2023-04-04"},"slug":"230404","category":"Tech","content":"$39"},{"metadata":{"title":"The 4G Router rabbit hole","publishedAt":"2023-03-31"},"slug":"230331","category":"Tech","content":"$3a"},{"metadata":{"title":"Upgrading Grandparents' Wifi II: The slow and the frustrated","publishedAt":"2023-03-30","order":2},"slug":"230330-2","category":"Tech","content":"$3b"},{"metadata":{"title":"Upgrading Grandparents' Wifi I","publishedAt":"2023-03-30","order":1},"slug":"230330-1","category":"Tech","content":"$3c"}],"itemPerPage":3}]]}],null],null],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/4d66c1a699081f75.css","precedence":"next","crossOrigin":"$undefined"}]],["$","html",null,{"lang":"en","className":"text-black bg-white __variable_ac79ff __variable_8a4d12","children":[["$","meta",null,{"name":"msvalidate.01","content":"D1474E050BE527719E98F0704865EEAE"}],["$","$L3d",null,{"gaId":"G-N3J3E2ME0X"}],["$","body",null,{"className":"antialiased max-w-4xl mx-4 mt-8 lg:mx-auto","children":["$","main",null,{"className":"flex-auto min-w-0 mt-6 flex flex-col px-2 md:px-0","children":[["$","$L3e",null,{}],["$","$L3f",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L40",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","section",null,{"children":[["$","h1",null,{"className":"mb-8 text-2xl font-semibold tracking-tighter","children":"404 - Page Not Found"}],["$","p",null,{"className":"mb-4","children":"The page you are looking for does not exist."}]]}],"notFoundStyles":[]}],["$","footer",null,{"className":"mb-16","children":[["$","ul",null,{"className":"font-sm mt-8 flex flex-col space-x-0 space-y-2 text-neutral-600 md:flex-row md:space-x-4 md:space-y-0","children":[["$","li",null,{"children":["$undefined",["$","p",null,{"className":" h-7 flex items-center transition-all hover:text-neutral-800","children":"United States"}]]}],["$","li",null,{"children":["$undefined",["$","p",null,{"className":" h-7 flex items-center transition-all hover:text-neutral-800","children":"Phone: 541-360-9231"}]]}]]}],["$","ul",null,{"className":"font-sm flex flex-col space-x-0 space-y-2 text-neutral-600 md:flex-row md:space-x-4 md:space-y-0","children":[["$","li",null,{"children":["$","a",null,{"className":"flex items-center transition-all hover:text-neutral-800","rel":"noopener noreferrer","target":"_blank","href":"https://github.com/bachsofttrick/","children":[["$","svg",null,{"width":"12","height":"12","viewBox":"0 0 12 12","fill":"none","xmlns":"http://www.w3.org/2000/svg","children":["$","path",null,{"d":"M2.07102 11.3494L0.963068 10.2415L9.2017 1.98864H2.83807L2.85227 0.454545H11.8438V9.46023H10.2955L10.3097 3.09659L2.07102 11.3494Z","fill":"currentColor"}]}],["$","p",null,{"className":"ml-2 h-7","children":"github"}]]}]}],["$","li",null,{"children":["$","a",null,{"className":"flex items-center transition-all hover:text-neutral-800","rel":"noopener noreferrer","target":"_blank","href":"https://linkedin.com/in/brphan/","children":[["$","svg",null,{"width":"12","height":"12","viewBox":"0 0 12 12","fill":"none","xmlns":"http://www.w3.org/2000/svg","children":["$","path",null,{"d":"M2.07102 11.3494L0.963068 10.2415L9.2017 1.98864H2.83807L2.85227 0.454545H11.8438V9.46023H10.2955L10.3097 3.09659L2.07102 11.3494Z","fill":"currentColor"}]}],["$","p",null,{"className":"ml-2 h-7","children":"linkedin"}]]}]}],["$","li",null,{"children":["$","a",null,{"className":"flex items-center transition-all hover:text-neutral-800","rel":"noopener noreferrer","target":"_blank","href":"mailto:xuanbach1307@gmail.com","children":[["$","svg",null,{"width":"12","height":"12","viewBox":"0 0 12 12","fill":"none","xmlns":"http://www.w3.org/2000/svg","children":["$","path",null,{"d":"M2.07102 11.3494L0.963068 10.2415L9.2017 1.98864H2.83807L2.85227 0.454545H11.8438V9.46023H10.2955L10.3097 3.09659L2.07102 11.3494Z","fill":"currentColor"}]}],["$","p",null,{"className":"ml-2 h-7","children":"email"}]]}]}],["$","li",null,{"children":["$","a",null,{"className":"flex items-center transition-all hover:text-neutral-800","rel":"noopener noreferrer","target":"_blank","href":"https://github.com/bachsofttrick/bachsofttrick.github.io/raw/refs/heads/main/resume.docx","children":[["$","svg",null,{"width":"12","height":"12","viewBox":"0 0 12 12","fill":"none","xmlns":"http://www.w3.org/2000/svg","children":["$","path",null,{"d":"M2.07102 11.3494L0.963068 10.2415L9.2017 1.98864H2.83807L2.85227 0.454545H11.8438V9.46023H10.2955L10.3097 3.09659L2.07102 11.3494Z","fill":"currentColor"}]}],["$","p",null,{"className":"ml-2 h-7","children":"get resume"}]]}]}],["$","li",null,{"children":["$","a",null,{"className":"flex items-center transition-all hover:text-neutral-800","rel":"noopener noreferrer","target":"_blank","href":"/rss.xml","children":[["$","svg",null,{"width":"12","height":"12","viewBox":"0 0 12 12","fill":"none","xmlns":"http://www.w3.org/2000/svg","children":["$","path",null,{"d":"M2.07102 11.3494L0.963068 10.2415L9.2017 1.98864H2.83807L2.85227 0.454545H11.8438V9.46023H10.2955L10.3097 3.09659L2.07102 11.3494Z","fill":"currentColor"}]}],["$","p",null,{"className":"ml-2 h-7","children":"rss"}]]}]}]]}],["$","p",null,{"className":"mt-8 text-neutral-600","children":2026}]]}]]}]}]]}]],null],null],["$L41",null]]]]
41:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Brian Phan"}],["$","meta","3",{"name":"description","content":"This is Brian Phan portfolio."}],["$","meta","4",{"name":"robots","content":"index, follow"}],["$","meta","5",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","meta","6",{"property":"og:title","content":"Brian Phan"}],["$","meta","7",{"property":"og:description","content":"This is Brian Phan portfolio."}],["$","meta","8",{"property":"og:url","content":"https://bachsofttrick.github.io"}],["$","meta","9",{"property":"og:site_name","content":"Brian Phan"}],["$","meta","10",{"property":"og:locale","content":"en_US"}],["$","meta","11",{"property":"og:type","content":"website"}],["$","meta","12",{"name":"twitter:card","content":"summary"}],["$","meta","13",{"name":"twitter:title","content":"Brian Phan"}],["$","meta","14",{"name":"twitter:description","content":"This is Brian Phan portfolio."}],["$","meta","15",{"name":"next-size-adjust"}]]
1:null
